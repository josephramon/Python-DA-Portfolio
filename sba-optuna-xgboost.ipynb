{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;a:link{color: white}\">\n",
    "    <h1 style='color:GhostWhite;'>Part 2: Should This Loan be Approved or Denied ?</h1>\n",
    "    This is a continuation of notebook <a style=\"color:yellow\" href=\"https://www.kaggle.com/code/josephramon/sba-xgboost-model\">Part 1: Should This Loan Be Approved or Denied ?</a><br><br>\n",
    "    The topic covered here is :<br>\n",
    "    <p style=\"color:Gold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>XGBoost v1.6+ HyperParameter Tuning using Optuna - Full and Incremental</b></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">  \n",
    "    <b>Dataset Source</b><br><br>\n",
    "    <a href=\"https://www.kaggle.com/mirbektoktogaraev/should-this-loan-be-approved-or-denied\">U.S. Small Business Administration (SBA) Dataset</a> - All information about the dataset can be found here<br><br>    \n",
    "    *<i>Thanks to Hamza for his <a href=\"https://www.kaggle.com/code/hamzaghanmi/xgboost-hyperparameter-tuning-using-optuna/notebook\">Notebook on Optuna</a> which was used as a guide.</i> \n",
    "<br><br>\n",
    "    If interested, Data Exploratory Visualization in Tableau can also be seen at :<br>\n",
    "    <a href= \"https://public.tableau.com/app/profile/joseph8038/viz/SBADatasetVisualizationandAnalysis/SBADatasetVisualizationandAnalysis-StoryBoard\">SBA Data Exploratory Visualization in Tableau</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"color:DarkSlateBlue\">\n",
    "This notebook is divided into 2 main parts:<br>\n",
    "<ul>\n",
    "<li><a style=\"color:DarkSlateGrey;\" href=\"#part1\"><b>1. XGBoost HyperParameter Tuning using Optuna - Full and Incremental</b></a></li><br>\n",
    "<li><a style=\"color:DarkSlateGrey;\" href=\"#part2\"><b>2. Miscellaneous</a></b>  - Early Stopping Rounds, Random Forest Classifier</li>\n",
    "</ul>\n",
    "<br>\n",
    "    <p style=\"color:FireBrick;\"><b>* Output from <a style=\"color:DarkGoldenRod;\" href = \"https://www.kaggle.com/code/josephramon/sba-xgboost-model\">Part 1 notebook</a> are Input to this notebook.</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "<h2>Table Of Contents</h2>\n",
    "<ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#paths_and_flags\">Paths and Flags</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#libraries\">Libraries</a></li>   \n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#functions\">Custom Functions And Classes</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#metrics\">Metrics Function</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#xgboost_class\">XGBoost Class</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#other_models\">Other Models Class</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_class\">Optuna Class - for both full datasets or incremental</a></li>\n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part1\">Part 1. XGBoost HyperParameter Tuning using Optuna</a></li>\n",
    "    <ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#full_df\">Optuna Study : Full Dataset</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#incremental_df\">Optuna Study : Incremental Dataset</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_metrics\">Optuna Study Metrics</a></li>    \n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#try_best_hp\">Model v4 : Try the Optuna Hyperparameters</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_comparison\">Optuna Tuning Comparison</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#cross_validation\">Cross Validation</a></li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part2\">Part 2. Miscellaneous</a></li>\n",
    "    <ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#early_stopping_rounds\">Early Stopping Rounds</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#random_forest_classifier\">Random Forest Classifier</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"paths_and_flags\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Paths and Flags</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:23:48.278041Z",
     "iopub.status.busy": "2022-05-17T07:23:48.277418Z",
     "iopub.status.idle": "2022-05-17T07:23:48.294012Z",
     "shell.execute_reply": "2022-05-17T07:23:48.292268Z",
     "shell.execute_reply.started": "2022-05-17T07:23:48.278002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a Kaggle notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "'''\n",
    "kaggle_flag :\n",
    "   0 - if running outside Kaggle (e.g. Jupyter Notebook), change inputdir & workdir to your \n",
    "       own path\n",
    "   1 - if running as a Kaggle notebook\n",
    "'''\n",
    "# Change this logic to your own if needed\n",
    "if os.path.exists('../usr/lib/myfuncs/myfuncs.py'):\n",
    "    kaggle_flag = 1\n",
    "    print('Running a Kaggle notebook')\n",
    "else:\n",
    "    kaggle_flag = 0\n",
    "    print('Not running a Kaggle notebook')\n",
    "\n",
    "# alert_flag - change to 0 for no sound alert, 1 for sound alert after long running cells\n",
    "alert_flag = 0\n",
    "\n",
    "'''\n",
    "We have two options for running Optuna tuning on XGBoost:  \n",
    "   OptunaStudy() - run Optuna on the full dataset\n",
    "   OptunaStudyChunk() - run in chunks, lighter on memory, but much slower\n",
    "\n",
    "Change flag below as needed:\n",
    "   1 to run OptunaStudy() only\n",
    "   2 to run OptunaStudyChunk() only\n",
    "   3 to run both\n",
    "'''\n",
    "optuna_flag = 1\n",
    "\n",
    "# GPU is automatically detected if activated\n",
    "\n",
    "#---------------------------------------------------------------------------------------#\n",
    "\n",
    "if kaggle_flag == 1:             # Kaggle\n",
    "    # Part 1 Notebook's workdir contents are input for this notebook\n",
    "    inputdir  = \"../input/sba-xgboost-model/\"        \n",
    "    workdir  = \"./\"\n",
    "    final_ds  = f'{inputdir}sba_final.csv.feather'  # imported from Part 1 Notebook\n",
    "    final_csv = f'{inputdir}sba_final.csv'          # imported from Part 1 Notebook\n",
    "    functions_path = \"../usr/lib/myfuncs/myfuncs.py\"\n",
    "else:\n",
    "    inputdir  = \"C:\\\\Python\\\\Python_Data_Science_Exercises\\\\datasets\\\\\"\n",
    "    workdir  = \"C:\\\\Python\\\\Python_Data_Science_Exercises\\\\datasets\\\\\"\n",
    "    final_ds  = f'{inputdir}sba_final.csv.feather'\n",
    "    final_csv = f'{inputdir}sba_final.csv'\n",
    "    functions_path = 'C:\\\\Python\\\\Python_Data_Science_Exercises\\\\mylibs\\\\'\n",
    "\n",
    "audio_path=\"https://www.soundjay.com/misc/sounds/tablet-bottle-1.mp3\" # for alert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"libraries\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Libraries</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:23:48.296588Z",
     "iopub.status.busy": "2022-05-17T07:23:48.295963Z",
     "iopub.status.idle": "2022-05-17T07:24:43.697577Z",
     "shell.execute_reply": "2022-05-17T07:24:43.696477Z",
     "shell.execute_reply.started": "2022-05-17T07:23:48.296542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package installations completed\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output   # to be able to use clear_output(wait=True)\n",
    "def install_packages():\n",
    "    print('Please wait, package installations started, if needed')\n",
    "    libs = ['scikit-learn', 'seaborn', 'numpy','matplotlib', 'tensorflow','torch','joblib',\n",
    "            'psutil','imbalanced-learn','xgboost','optuna','pyarrow','pyttsx3',\n",
    "            'pympler','memory_profiler','line_profiler','sweetviz']\n",
    "    \n",
    "    piplist = !pip list\n",
    "    for i in range(len(libs)):\n",
    "        if not piplist.grep(libs[i]):\n",
    "            !pip3 install {libs[i]}\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print('Package installations completed')\n",
    "\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:24:43.700798Z",
     "iopub.status.busy": "2022-05-17T07:24:43.700491Z",
     "iopub.status.idle": "2022-05-17T07:24:47.741250Z",
     "shell.execute_reply": "2022-05-17T07:24:47.740078Z",
     "shell.execute_reply.started": "2022-05-17T07:24:43.700766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package imports completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pyttsx3\n",
    "from IPython.display import Audio, display\n",
    "from IPython.display import FileLink\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import HTML\n",
    "import hashlib\n",
    "import copy                     # for deepcopy()\n",
    "import datetime as dt\n",
    "import optuna\n",
    "import gc\n",
    "import shutil\n",
    "import psutil\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "import torch                    # for clearing GPU cache\n",
    "from time import sleep\n",
    "import multiprocessing as mp\n",
    "from pympler import muppy       # for memory profiling\n",
    "from pympler import summary     # for memory profiling\n",
    "from pympler.classtracker import ClassTracker\n",
    "import xgboost\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "clear_output(wait=True)\n",
    "print('Package imports completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:24:47.743494Z",
     "iopub.status.busy": "2022-05-17T07:24:47.743076Z",
     "iopub.status.idle": "2022-05-17T07:24:47.756729Z",
     "shell.execute_reply": "2022-05-17T07:24:47.755627Z",
     "shell.execute_reply.started": "2022-05-17T07:24:47.743446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version is already 1.6+\n"
     ]
    }
   ],
   "source": [
    "# Kernel must be restarted if XGBoost is upgraded\n",
    "# importlib.reload and %autoreload do not work, so manually restart \n",
    "# This check is basically for Kaggle which has an older version of XGBoost, at least at this time\n",
    "if xgboost.__version__ < '1.6':\n",
    "    !pip3 install --upgrade xgboost\n",
    "    clear_output(wait=True)\n",
    "    print('XGBoost Package upgrade completed.  KERNEL RESTART NEEDED FOR NOTEBOOK.')\n",
    "else:\n",
    "    print('XGBoost version is already 1.6+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:24:47.760928Z",
     "iopub.status.busy": "2022-05-17T07:24:47.760582Z",
     "iopub.status.idle": "2022-05-17T07:24:58.750437Z",
     "shell.execute_reply": "2022-05-17T07:24:58.749288Z",
     "shell.execute_reply.started": "2022-05-17T07:24:47.760884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost __Version__ : 1.6.1\n",
      "\n",
      "Name: xgboost\n",
      "Version: 1.6.1\n",
      "Summary: XGBoost Python Package\n",
      "Home-page: https://github.com/dmlc/xgboost\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache-2.0\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: numpy, scipy\n",
      "Required-by: TPOT\n"
     ]
    }
   ],
   "source": [
    "# XGBoost version should be 1.6+ and up\n",
    "assert xgboost.__version__ >= '1.6',\\\n",
    "    \"XGBoost version must be 1.6+. RESTART KERNEL if already upgraded.\"\n",
    "\n",
    "print(f'XGBoost __Version__ : {xgboost.__version__}')\n",
    "print()\n",
    "!pip3 show xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:24:58.753095Z",
     "iopub.status.busy": "2022-05-17T07:24:58.752387Z",
     "iopub.status.idle": "2022-05-17T07:24:58.760992Z",
     "shell.execute_reply": "2022-05-17T07:24:58.759812Z",
     "shell.execute_reply.started": "2022-05-17T07:24:58.753045Z"
    }
   },
   "outputs": [],
   "source": [
    "# ensure garbage collector is enabled\n",
    "(gc.isenabled() == False) and gc.enable();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"functions\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Custom Functions and Classes</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:24:58.763097Z",
     "iopub.status.busy": "2022-05-17T07:24:58.762751Z",
     "iopub.status.idle": "2022-05-17T07:24:58.778588Z",
     "shell.execute_reply": "2022-05-17T07:24:58.777533Z",
     "shell.execute_reply.started": "2022-05-17T07:24:58.763050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working',\n",
       " '/kaggle/lib/kagglegym',\n",
       " '/kaggle/lib',\n",
       " '/kaggle/usr/lib',\n",
       " '/kaggle/usr/lib/myfuncs',\n",
       " '/opt/conda/lib/python37.zip',\n",
       " '/opt/conda/lib/python3.7',\n",
       " '/opt/conda/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/root/.local/lib/python3.7/site-packages',\n",
       " '/opt/conda/lib/python3.7/site-packages',\n",
       " '/src/bq-helper',\n",
       " '/opt/conda/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/root/.ipython']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:24:58.781226Z",
     "iopub.status.busy": "2022-05-17T07:24:58.780348Z",
     "iopub.status.idle": "2022-05-17T07:25:04.513412Z",
     "shell.execute_reply": "2022-05-17T07:25:04.512283Z",
     "shell.execute_reply.started": "2022-05-17T07:24:58.781174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom functions import completed\n"
     ]
    }
   ],
   "source": [
    "# import custom functions\n",
    "# RESTART kernel if myfuncs is modified\n",
    "if functions_path not in sys.path:\n",
    "    sys.path.append(functions_path)\n",
    "from myfuncs import *\n",
    "\n",
    "print('Custom functions import completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Custom functions and classes in <a style=\"color:ForestGreen\" href=\"https://www.kaggle.com/code/josephramon/myfuncs\" target=\"_blank\">myfuncs.py</a></b>.<br>  \n",
    "In Kaggle, myfuncs.py is set up as a <b>Utility Script</b> in /usr/lib<br>\n",
    "<ul>\n",
    "    <li>is_kaggle_gpu_enabled()</li>\n",
    "<li>clear_gpu(tree_method='gpu_hist')</li>\n",
    "<li>reduce_mem_usage(df, print_info = True, use_float16=False)</li>\n",
    "<li>runtime(rt1,rt2)</li>\n",
    "<li>create_download_link(title = \"Download \", filename = \"data.csv\")</li>\n",
    "<li>GetRam()</li>\n",
    "<li>convertFloatToDecimal(f=0.0, precision=2)</li>\n",
    "<li>formatFileSize(size, sizeIn, sizeOut, precision=0)</li>\n",
    "<li>check_cols_with_nulls(df)</li>\n",
    "<li>check_infinity_nan(df, dfname)</li>\n",
    "<li>fixvals(val)</li>\n",
    "<li>model_eval(y_valid,predictions, cmDisplay='False')</li>\n",
    "<li>plot_features(booster, figsize)</li>\n",
    "<li>make_mi_scores(X, y)</li>\n",
    "<li>plot_mi_scores(scores)</li>\n",
    "<li>GetSweetVizReport(df, workdir, kaggle_flag)</li>\n",
    "<li>SetVoice(kaggle_flag)</li>\n",
    "<li>class color\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:25:04.516025Z",
     "iopub.status.busy": "2022-05-17T07:25:04.515004Z",
     "iopub.status.idle": "2022-05-17T07:25:15.078122Z",
     "shell.execute_reply": "2022-05-17T07:25:15.077062Z",
     "shell.execute_reply.started": "2022-05-17T07:25:04.515974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpu_hist'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_enabled = is_kaggle_gpu_enabled()\n",
    "\n",
    "if gpu_enabled == False:\n",
    "    tree_method = 'hist'\n",
    "else:\n",
    "    tree_method = 'gpu_hist'\n",
    "\n",
    "del gpu_enabled\n",
    "gc.collect()\n",
    "\n",
    "sleep(5)\n",
    "clear_output(wait=True)\n",
    "tree_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:25:15.080934Z",
     "iopub.status.busy": "2022-05-17T07:25:15.080262Z",
     "iopub.status.idle": "2022-05-17T07:25:15.086281Z",
     "shell.execute_reply": "2022-05-17T07:25:15.085253Z",
     "shell.execute_reply.started": "2022-05-17T07:25:15.080888Z"
    }
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Set up voice object.  Used in different areas of notebook to indicate completion of long processes.\n",
    "'''\n",
    "engine = SetVoice(kaggle_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xgboost_class\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>XGBoost Class</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:25:15.091191Z",
     "iopub.status.busy": "2022-05-17T07:25:15.090397Z",
     "iopub.status.idle": "2022-05-17T07:25:15.223732Z",
     "shell.execute_reply": "2022-05-17T07:25:15.222745Z",
     "shell.execute_reply.started": "2022-05-17T07:25:15.091153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost class initialized\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "class process_model():  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_valid, self.X_test = None, None\n",
    "        self.y_valid, self.y_test = None, None\n",
    "\n",
    "        print(f'MIS_Status Count ->  1 : {Counter(y)[1]}, 0 : {Counter(y)[0]}')\n",
    "    \n",
    "    # oversampling method\n",
    "    def osample(self, print_info = True):\n",
    "        # define oversampling strategy\n",
    "        oversample = RandomOverSampler(sampling_strategy='minority') \n",
    "        if print_info == True:\n",
    "            print('X size : ', len(self.X))\n",
    "            print('y size : ', len(self.y))\n",
    "        # fit and apply the transform\n",
    "        X_over, y_over = oversample.fit_resample(self.X, self.y)\n",
    "\n",
    "        # summarize class distribution\n",
    "        if print_info == True:\n",
    "            print(f'Before Oversampling -> 1 : {Counter(self.y)[1]}, 0 : {Counter(self.y)[0]}')\n",
    "            print(f'After Oversampling  -> 1 : {Counter(y_over)[1]}, 0 : {Counter(y_over)[0]}')\n",
    "        \n",
    "        # update X and y with the oversampled results \n",
    "        self.X = X_over\n",
    "        self.y = y_over\n",
    "        \n",
    "        # return the oversampled results in case they are needed in another module\n",
    "        #return {'X_over':X_over, 'y_over':y_over}\n",
    "    \n",
    "    def split_data(self, X_size = 0.7):   \n",
    "        # Split Data into Train:Validate:Test\n",
    "        \n",
    "        # train_size=X_size\n",
    "        # In the first step, we will split the data in training and remaining dataset\n",
    "        self.X_train, X_rem, self.y_train, y_rem = train_test_split(self.X, self.y,\n",
    "                                stratify=self.y, train_size = X_size, random_state=48) \n",
    "\n",
    "        # Now since we want the valid and test size to be equal,\n",
    "        # we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "        # test_size = 0.5\n",
    "\n",
    "        self.X_valid, self.X_test, self.y_valid, self.y_test = train_test_split(X_rem,y_rem,\n",
    "                                stratify=y_rem, test_size=0.5, random_state=48)\n",
    "        \n",
    "        return {'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                'X_test':self.X_test, 'y_test':self.y_test}\n",
    "    \n",
    "    # Method to run model \n",
    "    # desc - description of metrics report\n",
    "    def prep_run_model(self, desc='Metrics', cmDisplay=False, PipeLine_flag = False,\n",
    "                hyperparams = {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6,\n",
    "                               'tree_method':tree_method, 'early_stopping_rounds':100,\n",
    "                               'eval_metric':['logloss','error']}):\n",
    "\n",
    "        # from XGBoost 1.6, early_stopping_rounds and eval_metric are under parameters,\n",
    "        # and deprecated from fit() method.\n",
    "        # The default hyperparameters are conservative, to help avoid overfitting\n",
    "        \n",
    "        print()\n",
    "        print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")\n",
    "        \n",
    "        '''\n",
    "        XGBRegressor is for continuous target/outcome variables. These are often called \n",
    "        \"regression problems.\"\n",
    "\n",
    "        XGBClassifier is for categorical target/outcome variables. These are often called \n",
    "        \"classification problems.\"\n",
    "        \n",
    "        xg_model = XGBRegressor(n_estimators = self.mn_estimators,\n",
    "                                learning_rate = self.mlearning_rate,\n",
    "                                max_depth = self.mmax_depth,\n",
    "                                n_jobs=4)\n",
    "        \n",
    "        xg_model = XGBClassifier(n_estimators = self.mn_estimators,\n",
    "                                learning_rate = self.mlearning_rate,\n",
    "                                max_depth = self.mmax_depth,\n",
    "                                use_label_encoder =False,\n",
    "                                n_jobs=4)\n",
    "        '''\n",
    "        \n",
    "        if PipeLine_flag == True:\n",
    "            # hyperparams is a result of a previous run of Optuna hyperparameter tuning\n",
    "            # the hyperparameters lean towards being conservative to help avoid overfitting\n",
    "            hyperparams = { 'tree_method': 'gpu_hist',\n",
    "                            'lambda': 0.023437933789759252,\n",
    "                            'alpha': 0.005813454622750776,\n",
    "                            'gamma': 0,\n",
    "                            'colsample_bytree': 0.9,\n",
    "                            'subsample': 1.0,\n",
    "                            'learning_rate': 0.05,\n",
    "                            'n_estimators': 1000,\n",
    "                            'max_depth': 13,\n",
    "                            'random_state': 48,\n",
    "                            'min_child_weight': 1,\n",
    "                            'early_stopping_rounds': 100.0,\n",
    "                            'eval_metric': 'error'\n",
    "                          }\n",
    "            \n",
    "        xg_model = XGBClassifier(**hyperparams,use_label_encoder =False)\n",
    "       \n",
    "        #eval_setparam = [(self.X_train, self.y_train), (self.X_valid, self.y_valid)]\n",
    "        eval_setparam = [(self.X_valid, self.y_valid)]\n",
    "        \n",
    "        xg_model.fit(self.X_train, self.y_train, \n",
    "                     eval_set = eval_setparam,\n",
    "                     verbose=False)\n",
    "        \n",
    "        gc.collect()\n",
    "        clear_gpu()\n",
    " \n",
    "        print(\"Fitting model completed.\")\n",
    "        print()\n",
    "        print('Preparing Predictions')\n",
    "    \n",
    "        # Get predictions\n",
    "        predictions = xg_model.predict(self.X_valid)\n",
    "    \n",
    "        print()\n",
    "        print(f'{color.underline}{desc}{color.end}')\n",
    "\n",
    "        eval_results = model_eval(self.y_valid, predictions, cmDisplay)\n",
    "            \n",
    "        # Return these values as they may be needed for further testing or metrics\n",
    "        # in dictionary form to remember easier \n",
    "        return {'xg_model':xg_model,'predictions':predictions,\n",
    "                    'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                    'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                    'X_test':self.X_test, 'y_test':self.y_test, 'eval_results':eval_results}\n",
    "    \n",
    "print('XGBoost class initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"other_models\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Other Models Class</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:25:15.226877Z",
     "iopub.status.busy": "2022-05-17T07:25:15.226516Z",
     "iopub.status.idle": "2022-05-17T07:25:18.214580Z",
     "shell.execute_reply": "2022-05-17T07:25:18.212789Z",
     "shell.execute_reply.started": "2022-05-17T07:25:15.226829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Models class initialized\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "if tree_method == 'gpu_hist':\n",
    "    import cuml\n",
    "    from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "\n",
    "# inherit from XGBoost class (process_model)\n",
    "class other_models(process_model):  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_valid, self.X_test = None, None\n",
    "        self.y_valid, self.y_test = None, None\n",
    "    \n",
    "    # Method to run model \n",
    "    # desc - description of metrics report\n",
    "    def prep_run_model(self, desc='Metrics', modelname = 'rfc',\n",
    "                       hparams = {'n_estimators':100, 'random_state':48, 'max_depth':10},\n",
    "                       cmDisplay=False):\n",
    "        print()\n",
    "        print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")  \n",
    "\n",
    "        if modelname == 'rfc':\n",
    "            if tree_method == 'gpu_hist':\n",
    "                model = cuRF(**hparams)\n",
    "            else:\n",
    "                model = RandomForestClassifier(**hparams) \n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            \n",
    "        print(\"Fitting model completed.\")\n",
    "        print()\n",
    "        print('Preparing Predictions')\n",
    "    \n",
    "        # Get predictions\n",
    "        predictions = model.predict(self.X_valid)\n",
    "        print(f'{color.underline}{desc}{color.end}')\n",
    "    \n",
    "        if modelname == 'rfc':\n",
    "            if tree_method == 'gpu_hist':\n",
    "                print()\n",
    "                cu_score = cuml.metrics.accuracy_score( self.y_valid, predictions )\n",
    "                print(f'{color.bdgreen}cuml Score : {round(cu_score * 100,2)} %{color.end}')\n",
    "                print()\n",
    "            \n",
    "        eval_results = model_eval(self.y_valid, predictions, cmDisplay)\n",
    "        print()\n",
    "        print\n",
    "        \n",
    "        gc.collect()\n",
    "        clear_gpu()\n",
    "        \n",
    "        # Return these values as they may be needed for further testing or metrics\n",
    "        # in dictionary form to remember easier \n",
    "        return {'model':model,'predictions':predictions,\n",
    "                    'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                    'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                    'X_test':self.X_test, 'y_test':self.y_test, 'eval_results':eval_results}\n",
    "    \n",
    "print('Other Models class initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_class\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Optuna Class</b><br>\n",
    "This is for both XGBoost full dataset (objective function) or incremental dataset (objective_chunk function) trials.  Also included is objective_rf function for Random Forest Classification).  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:25:18.217162Z",
     "iopub.status.busy": "2022-05-17T07:25:18.216786Z",
     "iopub.status.idle": "2022-05-17T07:25:18.284667Z",
     "shell.execute_reply": "2022-05-17T07:25:18.283513Z",
     "shell.execute_reply.started": "2022-05-17T07:25:18.217098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna class initialized\n"
     ]
    }
   ],
   "source": [
    "class optuna_tuning(process_model):  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_valid, self.X_test = None, None\n",
    "        self.y_valid, self.y_test = None, None\n",
    "    \n",
    "    # for printing only the best values, saves memory too\n",
    "    def logging_callback(self, study, frozen_trial):\n",
    "        previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "        if previous_best_value != study.best_value:\n",
    "            study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "            clear_output(wait=True)\n",
    "            self.text_out=\"{}Trial {} done with best value: {}{}{} and parameters: {}{}. \".format(\n",
    "                color.bdblue,\n",
    "                frozen_trial.number,\n",
    "                color.bdgreen,\n",
    "                frozen_trial.value,\n",
    "                color.bdblue,\n",
    "                color.end,\n",
    "                frozen_trial.params\n",
    "                )\n",
    "            print(self.text_out)\n",
    "            \n",
    "            # Writing to file\n",
    "            with open(f\"{workdir}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "                os_log.write('\\n\\n')\n",
    "                os_log.write(f\"Current Ram Used: {GetRam()} %\\n\")\n",
    "                os_log.write(self.text_out)\n",
    "    \n",
    "    # save study\n",
    "    def save_study(self, study, frozen_trial):\n",
    "        joblib.dump(study, f\"{workdir}xgb_optuna_study_callbacks.pkl\")   # save study\n",
    "    \n",
    "    # for tuning full dataset\n",
    "    def objective(self, trial, gt, n_estimators = 1000):        \n",
    "        nn_early_stopping_rounds = n_estimators * 0.1\n",
    "        # the hyperparameters lean towards being conservative to help avoid overfitting\n",
    "        param = {\n",
    "            # tree_method would ideally be gpu_hist for faster speed\n",
    "            'tree_method':trial.suggest_categorical('tree_method', [tree_method]), \n",
    "            # L2 regularization weight, Increasing this value will make model more conservative\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            # L1 regularization weight, Increasing this value will make model more conservative\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            # Min loss reduction for further partition on a leaf node. larger,the more conservative\n",
    "            'gamma':trial.suggest_categorical('gamma', [0,3,6]),\n",
    "            # sampling according to each tree\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree',\n",
    "                            [0.6,0.7,0.8,0.9,1.0]),\n",
    "            #                [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "            # sampling ratio for training data\n",
    "            #'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "            'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,0.9,1.0]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate',\n",
    "                            [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02,0.05]),\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators',[n_estimators]),\n",
    "            # maximum depth of the tree, signifies complexity of the tree\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [9,11,13]),\n",
    "            'random_state': trial.suggest_categorical('random_state', [48]),\n",
    "            # minimum child weight, larger the term more conservative the tree\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'early_stopping_rounds': trial.suggest_categorical('early_stopping_rounds',\n",
    "                                          [nn_early_stopping_rounds]),                     \n",
    "            'eval_metric': trial.suggest_categorical('eval_metric', [['logloss','error']])\n",
    "        }\n",
    "        if GetRam() >= 90:\n",
    "            raise MemoryError('Short On Memory')\n",
    "            \n",
    "        # clear outputs, reprint saved data\n",
    "        if trial.number > 0:\n",
    "            clear_output(wait=True)\n",
    "            gc.collect()\n",
    "            print(self.text_out)\n",
    "            \n",
    "        # print(param)  # for debugging, comment out if desired\n",
    "        model_xgbc = XGBClassifier(**param, use_label_encoder =False)  \n",
    "    \n",
    "        print()\n",
    "        print(f\"Current Ram Used: {GetRam()} %\")\n",
    "        rt2=dt.datetime.now()\n",
    "        print(f'{color.bdgreen}Total Elapsed Time from Training Start: {color.end}', end='')\n",
    "        runtime(gt, rt2)  \n",
    "        print(f'Running Trial {trial.number}')\n",
    "            \n",
    "        model_xgbc.fit(self.X_train, self.y_train, eval_set=[(self.X_valid, self.y_valid)],\n",
    "                    verbose=False)\n",
    "\n",
    "        preds = model_xgbc.predict(self.X_valid)\n",
    "    \n",
    "        rmse = metrics.mean_squared_error(self.y_valid, preds,squared=False)\n",
    " \n",
    "        trial.report(rmse, 1)\n",
    "            \n",
    "        if trial.should_prune():\n",
    "            text_prune = f'{color.bold}Trial {trial.number} pruned{color.end}'\n",
    "            # Writing to file\n",
    "            with open(f\"{workdir}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "                os_log.write('\\n')\n",
    "                os_log.write(text_prune)\n",
    "            del model_xgbc, preds, text_prune\n",
    "            gc.collect()\n",
    "            sleep(3)\n",
    "            clear_gpu()\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        text_dtl = \"Trial {} finished with parameters: {}. \".format(\n",
    "            trial.number,\n",
    "            trial.params\n",
    "            )\n",
    "        # Writing to file\n",
    "        with open(f\"{workdir}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "            os_log.write('\\n\\n')\n",
    "            os_log.write(f\"Current Ram Used: {GetRam()} %\\n\")\n",
    "            os_log.write(text_dtl)\n",
    "            \n",
    "        rt2=dt.datetime.now()\n",
    "\n",
    "        del model_xgbc, preds, text_dtl\n",
    "        gc.collect()\n",
    "        sleep(3)       \n",
    "        clear_gpu()        \n",
    "\n",
    "        return rmse\n",
    " \n",
    "\n",
    "    # for tuning incrementally in chunks\n",
    "    def objective_chunk(self, trial, n_trials, gt,\n",
    "                        n_chunksize = 200000, n_estimators = 1000):\n",
    "        nn_early_stopping_rounds = n_estimators * 0.1\n",
    "        \n",
    "        # the hyperparameters lean towards being conservative to help avoid overfitting\n",
    "        param = {\n",
    "            # tree_method would ideally be gpu_hist for faster speed\n",
    "            'tree_method':trial.suggest_categorical('tree_method', [tree_method]), \n",
    "            # L2 regularization weight, Increasing this value will make model more conservative\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            # L1 regularization weight, Increasing this value will make model more conservative\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            # Min loss reduction for further partition on a leaf node. larger,the more conservative\n",
    "            'gamma':trial.suggest_categorical('gamma', [0,3,6]),\n",
    "            # sampling according to each tree\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree',\n",
    "                                [0.6,0.7,0.8,0.9,1.0]),\n",
    "            #                [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "            # sampling ratio for training data\n",
    "            #'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "            'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,0.9,1.0]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate',\n",
    "                            [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02,0.05]),\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators',[n_estimators]),\n",
    "            # maximum depth of the tree, signifies complexity of the tree\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [9,11,13]),\n",
    "            'random_state': trial.suggest_categorical('random_state', [48]),\n",
    "            # minimum child weight, larger the term more conservative the tree\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'early_stopping_rounds': trial.suggest_categorical('early_stopping_rounds',\n",
    "                                          [nn_early_stopping_rounds]),                     \n",
    "            'eval_metric': trial.suggest_categorical('eval_metric', [['logloss','error']])\n",
    "        }\n",
    "        if GetRam() >= 90:\n",
    "            raise MemoryError('Short On Memory')\n",
    "        \n",
    "        model_xgbc = XGBClassifier(**param,use_label_encoder =False)  \n",
    "    \n",
    "        rt1=dt.datetime.now()\n",
    "               \n",
    "        # clear outputs, reprint saved data\n",
    "        if trial.number > 0:\n",
    "            clear_output(wait=True)\n",
    "            gc.collect()\n",
    "            print(self.text_out)\n",
    "            \n",
    "            if os.path.exists(f'{workdir}model_xgbc.json'):\n",
    "                file_size = os.path.getsize(f'{workdir}model_xgbc.json')\n",
    "                file_size = formatFileSize(file_size,'B','MB',2)\n",
    "                print(f\"Current Model File Size : {file_size}MB\")\n",
    "\n",
    "        '''\n",
    "        For batch, use xgb_model parameter in fit().  There are two ways :\n",
    "           1. save the model to a file, after 1st trial, then give the name to the next trials\n",
    "           2. just give the name of the model object, in this case model_xgbc\n",
    "        '''\n",
    "    \n",
    "        #X_valid_list, y_valid_list = [],[]\n",
    "        # Fit Model\n",
    "        for i, self.X in enumerate(pd.read_csv(final_csv, chunksize = n_chunksize), start = 1):\n",
    "            self.X = reduce_mem_usage(self.X, print_info=False)\n",
    "            self.y = self.X.pop('MIS_Status')\n",
    "\n",
    "            self.osample(print_info = False)\n",
    "            self.split_data(0.7)\n",
    "            \n",
    "            #X_valid_list.append(self.X_valid.copy())\n",
    "            #y_valid_list.append(self.y_valid.copy())\n",
    "            \n",
    "            #X_valid = pd.concat(X_valid_list)\n",
    "            #y_valid = pd.concat(y_valid_list)\n",
    "            X_valid = self.X_valid\n",
    "            y_valid = self.y_valid\n",
    "        \n",
    "            self.X, self.y = None, None\n",
    "            self.X_valid, self.y_valid = None, None\n",
    "            self.X_test, self.y_test = None, None\n",
    "\n",
    "            if i == 1:            \n",
    "                print()\n",
    "                print(f\"Current Ram Used: {GetRam()} %\")\n",
    "                rt2=dt.datetime.now()\n",
    "                print(f'{color.bdgreen}Total Elapsed Time from Training Start: {color.end}', end='')\n",
    "                runtime(gt, rt2)  \n",
    "                print(f'Running Trial {trial.number} Chunk: {i}',end = ' | ')\n",
    "                model_xgbc.fit(self.X_train, self.y_train, eval_set=[(X_valid, y_valid)],\n",
    "                        verbose=False)\n",
    "            else:\n",
    "                print(f'{i}',end = ' | ')\n",
    "                model_xgbc = XGBClassifier(use_label_encoder =False)\n",
    "                model_xgbc.load_model(f'{workdir}model_xgbc.json')\n",
    "                \n",
    "                #if i == 2:\n",
    "                #    param.pop('tree_method')\n",
    "                #    param.update({'updater':'refresh',\n",
    "                #                'process_type': 'update',\n",
    "                #                'refresh_leaf': True})\n",
    "                #    model_xgbc.set_params(**param)\n",
    "                \n",
    "                model_xgbc.fit(self.X_train, self.y_train, eval_set=[(X_valid, y_valid)],\n",
    "                        verbose=False, xgb_model = model_xgbc\n",
    "                        # uncomment below if you want to use a saved file\n",
    "                        #xgb_model = f'{workdir}model_xgbc.json'\n",
    "                        )\n",
    "\n",
    "            '''Auxiliary attributes of the Python Booster object (such as feature_names) will \n",
    "            not be saved when using binary format. To save those attributes, use JSON instead.'''\n",
    "            # uncomment below if using a saved file\n",
    "            #model_xgbc.get_booster().save_model(f'{workdir}model_xgbc.json')\n",
    "            model_xgbc.save_model(f'{workdir}model_xgbc.json')\n",
    "        \n",
    "            #X_valid = pd.concat(X_valid_list)\n",
    "            #y_valid = pd.concat(y_valid_list)\n",
    "        \n",
    "            preds = model_xgbc.predict(X_valid)\n",
    "    \n",
    "            rmse = metrics.mean_squared_error(y_valid, preds,squared=False)\n",
    "        \n",
    "            del model_xgbc\n",
    "            self.X_train, self.y_train = None, None\n",
    "            gc.collect()\n",
    "            sleep(5)\n",
    "            clear_gpu()\n",
    "            \n",
    "            trial.report(rmse, i)\n",
    "            \n",
    "            if trial.should_prune():\n",
    "                # Writing to file\n",
    "                with open(f\"{workdir}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "                    os_log.write('\\n')\n",
    "                    os_log.write(f'{color.bold}Trial {trial.number} pruned{color.end}')\n",
    "                    os_log.write('\\n')\n",
    "                raise optuna.TrialPruned()\n",
    "        \n",
    "        if os.path.exists(f'{workdir}model_xgbc.json'):\n",
    "            file_size = os.path.getsize(f'{workdir}model_xgbc.json')\n",
    "            file_size = formatFileSize(file_size,'B','MB',2)\n",
    "            print(f\"Current Model File Size : {file_size}MB\")\n",
    "                \n",
    "        # Writing to file\n",
    "        with open(f\"{workdir}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "            os_log.write('\\n\\n')\n",
    "            os_log.write(f\"Current Ram Used: {GetRam()} %\")\n",
    "            if os.path.exists(f'{workdir}model_xgbc.json'):\n",
    "                os_log.write(f\" | Current Model File Size : {file_size}MB\\n\")\n",
    "            os_log.write(f\"Trial {trial.number} finished with parameters: {trial.params}.\")\n",
    "            \n",
    "        rt2=dt.datetime.now()\n",
    "\n",
    "        self.X_train, self.y_train = None, None\n",
    "        gc.collect()\n",
    "        sleep(5)\n",
    "        clear_gpu()\n",
    "            \n",
    "        return rmse\n",
    "\n",
    "    # Define an objective function for Random Forest\n",
    "    def objective_rf(self, trial, gt):\n",
    "        hparams = {\n",
    "            'max_features': trial.suggest_uniform('max_features', 0.15, 1.0),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "            'max_samples': trial.suggest_uniform('max_samples', 0.6, 0.99),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [9,11,13]),\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators', [100])\n",
    "            # warm_start = True   # for incremental learning  \n",
    "        }\n",
    " \n",
    "        # clear outputs, reprint saved data\n",
    "        if trial.number > 0:\n",
    "            clear_output(wait=True)\n",
    "            gc.collect()\n",
    "            print(self.text_out)\n",
    "            \n",
    "        if GetRam() >= 90:\n",
    "            raise MemoryError('Short On Memory')\n",
    "            \n",
    "        if tree_method == \"gpu_hist\":\n",
    "            model_rf = cuRF(**hparams)\n",
    "        else:\n",
    "            model_rf = RandomForestClassifier(**hparams)\n",
    "        print()\n",
    "        print(f\"Current Ram Used: {GetRam()} %\")\n",
    "        rt2=dt.datetime.now()\n",
    "        print(f'{color.bdgreen}Total Elapsed Time from Training Start: {color.end}', end='')\n",
    "        runtime(gt, rt2)  \n",
    "        print(f'Running Trial {trial.number}')\n",
    "\n",
    "        ## Fit Model\n",
    "        model_rf.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # Report intermediate objective value\n",
    "        intermediate_value = model_rf.score(self.X_valid, self.y_valid)\n",
    "        trial.report(intermediate_value, 0)\n",
    "            \n",
    "        if trial.should_prune():\n",
    "            text_prune = f'{color.bold}Trial {trial.number} pruned{color.end}'\n",
    "            # Writing to file\n",
    "            with open(f\"{workdir}rfc_optuna_study_log.txt\", \"a\") as os_log:\n",
    "                os_log.write('\\n')\n",
    "                os_log.write(text_prune)\n",
    "            del model_rf, text_prune\n",
    "            gc.collect()\n",
    "            sleep(3)\n",
    "            clear_gpu()\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        text_dtl = \"Trial {} finished with parameters: {}. \".format(\n",
    "            trial.number,\n",
    "            trial.params\n",
    "            )\n",
    "        # Writing to file\n",
    "        with open(f\"{workdir}rfc_optuna_study_log.txt\", \"a\") as os_log:\n",
    "            os_log.write('\\n\\n')\n",
    "            os_log.write(f\"Current Ram Used: {GetRam()} %\\n\")\n",
    "            os_log.write(text_dtl)\n",
    "            \n",
    "        rt2=dt.datetime.now()\n",
    "\n",
    "        del model_rf, text_dtl\n",
    "        gc.collect()\n",
    "        sleep(3)       \n",
    "        clear_gpu()        \n",
    "\n",
    "        return intermediate_value\n",
    "    \n",
    "print('Optuna class initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 style='color:GhostWhite;'>Part 1. XGBoost HyperParameter Tuning using Optuna</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"full_df\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.1 Optuna Study - Full Dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:29:00.226320Z",
     "iopub.status.busy": "2022-05-17T07:29:00.226006Z",
     "iopub.status.idle": "2022-05-17T08:36:37.501175Z",
     "shell.execute_reply": "2022-05-17T08:36:37.500083Z",
     "shell.execute_reply.started": "2022-05-17T07:29:00.226288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mTrial 33 done with best value: \u001b[1m\u001b[92m0.18974275981244534\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 0.001222882589196536, 'alpha': 0.8066599284119552, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 6, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "\u001b[1m\u001b[92mTotal Elapsed Time from Training Start: \u001b[0mRuntime : 1:04:45.660689\n",
      "Running Trial 49\n",
      "\n",
      "Number of finished trials: 50\n",
      "Number of pruned trials: 27\n",
      "Number of completed trials: \u001b[1m\u001b[92m23\u001b[0m\n",
      "\u001b[1m\u001b[94mBest trial: {'tree_method': 'gpu_hist', 'lambda': 0.001222882589196536, 'alpha': 0.8066599284119552, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 6, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}\u001b[0m\n",
      "\n",
      "CPU times: user 1h 4min 26s, sys: 14.7 s, total: 1h 4min 41s\n",
      "Wall time: 1h 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "        \n",
    "# For running Optuna tuning on full dataset.\n",
    "def OptunaStudy():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    # instantiate the optuna_tuning class\n",
    "    ot = optuna_tuning(X, y)\n",
    "    ot.osample()\n",
    "    ot.split_data(0.7)\n",
    "    \n",
    "    ot.X, ot.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    ''' \n",
    "    - Initialize the number of trials and n_estimators.\n",
    "    - Rather than run at a very high n_trials like 100 and above, I prefer to run this function, \n",
    "         with an n_trials like 50, three times to get the best_trial values \n",
    "    - Recommended n_estimators is 100 for really huge datasets, 1000 for medium-sized.\n",
    "    - For our dataset here, 1000 is fine.  Ramping it up to 4000 for example will have no\n",
    "         significant benefits, will be very slow, and a Kaggle notebook will run out of memory often.\n",
    "    '''\n",
    "    \n",
    "    nn_trials = 50\n",
    "    nn_estimators = 1000\n",
    "    \n",
    "    if os.path.exists(f'{workdir}xgb_optuna_study_log.txt'):\n",
    "        os.remove(f'{workdir}xgb_optuna_study_log.txt')\n",
    "\n",
    "    # STUDY\n",
    "    \n",
    "    # Turn off optuna log notes, to use own logging notes\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "\n",
    "    print(f\"{color.bold}Please wait, finding best trial ...{color.end}\")\n",
    "            \n",
    "    gt = dt.datetime.now()\n",
    "        \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    try:\n",
    "        # callbacks [self.save_study] is to save study in case memory fails\n",
    "        study.optimize(lambda trial: ot.objective(trial, gt, n_estimators = nn_estimators), \n",
    "                        n_trials = nn_trials,\n",
    "                        callbacks = [ot.logging_callback, ot.save_study],\n",
    "                        gc_after_trial = True,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "    except MemoryError as e:\n",
    "        print(f'{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}')\n",
    "    \n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    print()\n",
    "    print(f'Number of finished trials: {len(study.trials)}')\n",
    "    print(f'Number of pruned trials: {len(pruned_trials)}')\n",
    "    print(f'Number of completed trials: {color.bdgreen}{len(complete_trials)}{color.end}')\n",
    "    print(f'{color.bdblue}Best trial: {study.best_trial.params}{color.end}')\n",
    "    \n",
    "    joblib.dump(study, f\"{workdir}xgb_optuna_study.pkl\")   # save study\n",
    "    # jl = joblib.load(f\"{workdir}xgb_optuna_study.pkl\")   # load study\n",
    "\n",
    "    print()\n",
    "    return study\n",
    "\n",
    "if optuna_flag == 1 or optuna_flag == 3:\n",
    "    study_results = OptunaStudy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"incremental_df\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.2 Optuna Study - Incremental Dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:37.504512Z",
     "iopub.status.busy": "2022-05-17T08:36:37.503478Z",
     "iopub.status.idle": "2022-05-17T08:36:37.519902Z",
     "shell.execute_reply": "2022-05-17T08:36:37.518854Z",
     "shell.execute_reply.started": "2022-05-17T08:36:37.504462Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 12.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For running Optuna tuning incrementally in batches, much slower, but lighter on memory\n",
    "def OptunaStudyChunk(): \n",
    "    ''' \n",
    "    - Initialize the number of trials and n_estimators.\n",
    "    - Rather than run at a very high n_trials like 100 and above, I prefer to run this function, \n",
    "         with an n_trials like 50 or 70, three times to get the best_trial values \n",
    "    - Recommended n_estimators is 100 for really huge datasets, 1000 for medium-sized.\n",
    "    - For our dataset here, 1000 is fine.  Ramping it up to 4000 for example will have no\n",
    "         significant benefits, will be very slow, and a Kaggle notebook will run out of memory often.\n",
    "    '''\n",
    "\n",
    "    nn_trials = 3               # n_trials\n",
    "    nn_chunksize = 200000\n",
    "    nn_estimators = 1000\n",
    "    \n",
    "    if os.path.exists(f'{workdir}xgb_optuna_study_log.txt'):\n",
    "        os.remove(f'{workdir}xgb_optuna_study_log.txt')\n",
    "\n",
    "    # get full X_valid, y_valid \n",
    "    '''\n",
    "    print(f\"{color.bold}Please wait, getting Validation Data{color.end}\")  \n",
    "    X_valid_list, y_valid_list = [],[]\n",
    "    for i, X in enumerate(pd.read_csv(final_csv, chunksize = nn_chunksize), start = 1):\n",
    "        X = reduce_mem_usage(X, print_info=False)\n",
    "        y = X.pop('MIS_Status')\n",
    "\n",
    "        oso = optuna_tuning(X,y) \n",
    "        oso.osample(print_info = False)\n",
    "        oso.split_data(0.7)\n",
    "            \n",
    "        X_valid_list.append(oso.X_valid.copy())\n",
    "        y_valid_list.append(oso.y_valid.copy())\n",
    "            \n",
    "    X_valid = pd.concat(X_valid_list)\n",
    "    y_valid = pd.concat(y_valid_list)\n",
    "        \n",
    "    del X_valid_list, y_valid_list, oso\n",
    "    gc.collect() \n",
    "    sleep(3)\n",
    "    '''\n",
    "        \n",
    "    # OPTUNA STUDY\n",
    "    \n",
    "    # Turn off optuna log notes, to use own logging notes\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f\"{color.bold}Please wait, finding best trial ...{color.end}\")\n",
    "            \n",
    "    gt = dt.datetime.now()\n",
    "\n",
    "    otb = optuna_tuning(None, None)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    try:\n",
    "        # callbacks [self.save_study] is to save study in case memory fails\n",
    "        '''\n",
    "        study.optimize(lambda trial: otb.objective_chunk(trial, nn_trials, gt, X_valid, y_valid,\n",
    "                                  n_chunksize = nn_chunksize, n_estimators = nn_estimators), \n",
    "                        n_trials = nn_trials,\n",
    "                        callbacks = [otb.logging_callback, otb.save_study],\n",
    "                        gc_after_trial = True,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "        '''\n",
    "        study.optimize(lambda trial: otb.objective_chunk(trial, nn_trials, gt,\n",
    "                                  n_chunksize = nn_chunksize, n_estimators = nn_estimators), \n",
    "                        n_trials = nn_trials,\n",
    "                        callbacks = [otb.logging_callback, otb.save_study],\n",
    "                        gc_after_trial = True,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "    except MemoryError as e:\n",
    "        print(f'\\n\\n{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}\\n\\n')\n",
    " \n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    print()\n",
    "    print(f'Number of finished trials: {len(study.trials)}')\n",
    "    print(f'Number of pruned trials: {len(pruned_trials)}')\n",
    "    print(f'Number of completed trials: {color.bdgreen}{len(complete_trials)}{color.end}')\n",
    "    print(f'{color.bdblue}Best trial: {study.best_trial.params}{color.end}')\n",
    "    \n",
    "    joblib.dump(study, f\"{workdir}xgb_optuna_study.pkl\")   # save study\n",
    "    # jl = joblib.load(f\"{workdir}xgb_optuna_study.pkl\")   # load study\n",
    "\n",
    "    print()\n",
    "    return study\n",
    "\n",
    "if optuna_flag == 2 or optuna_flag == 3:\n",
    "    study_results = OptunaStudyChunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_metrics\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.3 Optuna Study Metrics</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:37.523065Z",
     "iopub.status.busy": "2022-05-17T08:36:37.521419Z",
     "iopub.status.idle": "2022-05-17T08:36:37.535101Z",
     "shell.execute_reply": "2022-05-17T08:36:37.534139Z",
     "shell.execute_reply.started": "2022-05-17T08:36:37.522988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Current Ram Used: 18.2 %\n",
      "Trial 0 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 0.17219440436740166, 'alpha': 0.016477595208979772, 'gamma': 0, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 9, 'random_state': 48, 'min_child_weight': 1, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 18.2 %\n",
      "\u001b[1m\u001b[94mTrial 0 done with best value: \u001b[1m\u001b[92m0.24944399209761087\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 0.17219440436740166, 'alpha': 0.016477595208979772, 'gamma': 0, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 9, 'random_state': 48, 'min_child_weight': 1, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 18.2 %\n",
      "Trial 1 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 0.0010066680900056263, 'alpha': 9.237182742600261, 'gamma': 6, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 1, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 18.4 %\n",
      "Trial 2 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 0.628044905677302, 'alpha': 1.508770786488825, 'gamma': 0, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 11, 'random_state': 48, 'min_child_weight': 5, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 18.4 %\n",
      "\u001b[1m\u001b[94mTrial 2 done with best value: \u001b[1m\u001b[92m0.238804896965954\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 0.628044905677302, 'alpha': 1.508770786488825, 'gamma': 0, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 11, 'random_state': 48, 'min_child_weight': 5, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 18.4 %\n",
      "Trial 3 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 0.10301371540439241, 'alpha': 2.2920209101399913, 'gamma': 6, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.018, 'n_estimators': 1000, 'max_depth': 9, 'random_state': 48, 'min_child_weight': 4, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 18.6 %\n",
      "Trial 4 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 0.05052263807751198, 'alpha': 0.0031750105933764975, 'gamma': 3, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 9, 'random_state': 48, 'min_child_weight': 3, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 18.7 %\n",
      "Trial 5 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 0.23474843914404003, 'alpha': 5.558242198480652, 'gamma': 0, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 5, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 18.7 %\n",
      "\u001b[1m\u001b[94mTrial 5 done with best value: \u001b[1m\u001b[92m0.2326574415770081\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 0.23474843914404003, 'alpha': 5.558242198480652, 'gamma': 0, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 5, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 6 pruned\u001b[0m\n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 7 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 5.410013158573954, 'alpha': 0.06134014052597736, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 1, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "\u001b[1m\u001b[94mTrial 7 done with best value: \u001b[1m\u001b[92m0.22652858526080238\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 5.410013158573954, 'alpha': 0.06134014052597736, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 1, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 8 pruned\u001b[0m\n",
      "\u001b[1mTrial 9 pruned\u001b[0m\n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 10 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 7.81608347580735, 'alpha': 0.09938199328784113, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 10, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 11 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 9.767953803667671, 'alpha': 0.13177225560877837, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "\u001b[1m\u001b[94mTrial 11 done with best value: \u001b[1m\u001b[92m0.2129458343978814\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 9.767953803667671, 'alpha': 0.13177225560877837, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 12 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 7.533128253769075, 'alpha': 0.10478227182743045, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "\u001b[1m\u001b[94mTrial 12 done with best value: \u001b[1m\u001b[92m0.21062089623557223\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 7.533128253769075, 'alpha': 0.10478227182743045, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 13 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 2.2705877142005924, 'alpha': 0.19063858010875087, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "\u001b[1m\u001b[94mTrial 13 done with best value: \u001b[1m\u001b[92m0.20244049214066906\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 2.2705877142005924, 'alpha': 0.19063858010875087, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 14 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 2.1611757500574424, 'alpha': 0.4487036926391837, 'gamma': 0, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "\u001b[1m\u001b[94mTrial 14 done with best value: \u001b[1m\u001b[92m0.1948277351793152\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 2.1611757500574424, 'alpha': 0.4487036926391837, 'gamma': 0, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 15 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 1.752364770024339, 'alpha': 0.521282938276694, 'gamma': 0, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 9, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 16 pruned\u001b[0m\n",
      "\u001b[1mTrial 17 pruned\u001b[0m\n",
      "\u001b[1mTrial 18 pruned\u001b[0m\n",
      "\u001b[1mTrial 19 pruned\u001b[0m\n",
      "\u001b[1mTrial 20 pruned\u001b[0m\n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 21 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 3.353680019992981, 'alpha': 1.117571646333282, 'gamma': 0, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 7, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 22 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 3.1207973814643575, 'alpha': 1.080327524795957, 'gamma': 0, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 6, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "\u001b[1m\u001b[94mTrial 22 done with best value: \u001b[1m\u001b[92m0.1937467517941609\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 3.1207973814643575, 'alpha': 1.080327524795957, 'gamma': 0, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 6, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 23 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 3.6403269842809065, 'alpha': 1.314346977669092, 'gamma': 0, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 6, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 24 pruned\u001b[0m\n",
      "\u001b[1mTrial 25 pruned\u001b[0m\n",
      "\u001b[1mTrial 26 pruned\u001b[0m\n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 27 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 3.7586695036352276, 'alpha': 0.9969255155342691, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 5, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 28 pruned\u001b[0m\n",
      "\u001b[1mTrial 29 pruned\u001b[0m\n",
      "\u001b[1mTrial 30 pruned\u001b[0m\n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 31 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 3.593402338248813, 'alpha': 0.9087955946232311, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 5, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 32 pruned\u001b[0m\n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 33 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 0.001222882589196536, 'alpha': 0.8066599284119552, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 6, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "\u001b[1m\u001b[94mTrial 33 done with best value: \u001b[1m\u001b[92m0.18974275981244534\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'gpu_hist', 'lambda': 0.001222882589196536, 'alpha': 0.8066599284119552, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 6, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 34 pruned\u001b[0m\n",
      "\u001b[1mTrial 35 pruned\u001b[0m\n",
      "\u001b[1mTrial 36 pruned\u001b[0m\n",
      "\u001b[1mTrial 37 pruned\u001b[0m\n",
      "\u001b[1mTrial 38 pruned\u001b[0m\n",
      "\u001b[1mTrial 39 pruned\u001b[0m\n",
      "\u001b[1mTrial 40 pruned\u001b[0m\n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 41 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 6.3802929752185396, 'alpha': 0.9216316514483586, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 5, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 42 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 1.0369953723846221, 'alpha': 4.343028496109168, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 5, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 43 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 2.710506947441455, 'alpha': 1.5765601482001488, 'gamma': 0, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 4, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 44 pruned\u001b[0m\n",
      "\u001b[1mTrial 45 pruned\u001b[0m\n",
      "\n",
      "Current Ram Used: 20.3 %\n",
      "Trial 46 finished with parameters: {'tree_method': 'gpu_hist', 'lambda': 5.4335341908020105, 'alpha': 0.3548170568560932, 'gamma': 0, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.05, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 4, 'early_stopping_rounds': 100.0, 'eval_metric': ['logloss', 'error']}. \n",
      "\u001b[1mTrial 47 pruned\u001b[0m\n",
      "\u001b[1mTrial 48 pruned\u001b[0m\n",
      "\u001b[1mTrial 49 pruned\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# uncomment below if you want to see the trials log \n",
    "with open(f\"{workdir}xgb_optuna_study_log.txt\", \"r+\") as os_log:\n",
    "    print(os_log.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:37.537951Z",
     "iopub.status.busy": "2022-05-17T08:36:37.537669Z",
     "iopub.status.idle": "2022-05-17T08:36:37.582187Z",
     "shell.execute_reply": "2022-05-17T08:36:37.581142Z",
     "shell.execute_reply.started": "2022-05-17T08:36:37.537923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved study ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'gpu_hist',\n",
       " 'lambda': 0.001222882589196536,\n",
       " 'alpha': 0.8066599284119552,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'subsample': 0.9,\n",
       " 'learning_rate': 0.05,\n",
       " 'n_estimators': 1000,\n",
       " 'max_depth': 13,\n",
       " 'random_state': 48,\n",
       " 'min_child_weight': 6,\n",
       " 'early_stopping_rounds': 100.0,\n",
       " 'eval_metric': ['logloss', 'error']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nbest_trial_sorted = {}\\nfor i in sorted (jl) :\\n    best_trial_sorted.update({i:jl[i]})                          \\n\\ndisplay(best_trial_sorted)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment below if you want to load saved study to check, if desired\n",
    "print('Loading saved study ...')\n",
    "print()\n",
    "jl = joblib.load(f\"{workdir}xgb_optuna_study.pkl\")\n",
    "jl = jl.best_trial.params\n",
    "display(jl)\n",
    "# jl.update({'n_estimators': 4000, 'tree_method':tree_method})\n",
    "'''\n",
    "best_trial_sorted = {}\n",
    "for i in sorted (jl) :\n",
    "    best_trial_sorted.update({i:jl[i]})                          \n",
    "\n",
    "display(best_trial_sorted)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:37.584491Z",
     "iopub.status.busy": "2022-05-17T08:36:37.584075Z",
     "iopub.status.idle": "2022-05-17T08:36:37.625107Z",
     "shell.execute_reply": "2022-05-17T08:36:37.624070Z",
     "shell.execute_reply.started": "2022-05-17T08:36:37.584429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'gpu_hist',\n",
       " 'lambda': 0.001222882589196536,\n",
       " 'alpha': 0.8066599284119552,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'subsample': 0.9,\n",
       " 'learning_rate': 0.05,\n",
       " 'n_estimators': 1000,\n",
       " 'max_depth': 13,\n",
       " 'random_state': 48,\n",
       " 'min_child_weight': 6,\n",
       " 'early_stopping_rounds': 100.0,\n",
       " 'eval_metric': ['logloss', 'error']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_results = joblib.load(f\"{workdir}xgb_optuna_study.pkl\")\n",
    "best_trial = study_results.best_trial.params\n",
    "best_trial['tree_method'] = tree_method\n",
    "display(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:37.627380Z",
     "iopub.status.busy": "2022-05-17T08:36:37.626847Z",
     "iopub.status.idle": "2022-05-17T08:36:37.638364Z",
     "shell.execute_reply": "2022-05-17T08:36:37.637342Z",
     "shell.execute_reply.started": "2022-05-17T08:36:37.627335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'gpu_hist',\n",
       " 'lambda': 0.001222882589196536,\n",
       " 'alpha': 0.8066599284119552,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'subsample': 0.9,\n",
       " 'learning_rate': 0.05,\n",
       " 'n_estimators': 1000,\n",
       " 'max_depth': 13,\n",
       " 'random_state': 48,\n",
       " 'min_child_weight': 6,\n",
       " 'early_stopping_rounds': 100.0,\n",
       " 'eval_metric': ['logloss', 'error']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial = study_results.best_trial.params\n",
    "#best_trial.update({'n_estimators': 4000, 'tree_method':tree_method})\n",
    "best_trial['tree_method'] = tree_method\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:37.641282Z",
     "iopub.status.busy": "2022-05-17T08:36:37.640484Z",
     "iopub.status.idle": "2022-05-17T08:36:37.681979Z",
     "shell.execute_reply": "2022-05-17T08:36:37.680878Z",
     "shell.execute_reply.started": "2022-05-17T08:36:37.641234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_alpha</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_early_stopping_rounds</th>\n",
       "      <th>params_eval_metric</th>\n",
       "      <th>params_gamma</th>\n",
       "      <th>params_lambda</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_random_state</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>params_tree_method</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.189743</td>\n",
       "      <td>2022-05-17 08:12:29.776353</td>\n",
       "      <td>2022-05-17 08:14:06.002324</td>\n",
       "      <td>0 days 00:01:36.225971</td>\n",
       "      <td>0.80666</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.05</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>48</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>2022-05-17 08:25:33.651305</td>\n",
       "      <td>2022-05-17 08:27:19.223965</td>\n",
       "      <td>0 days 00:01:45.572660</td>\n",
       "      <td>1.57656</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[logloss, error]</td>\n",
       "      <td>0</td>\n",
       "      <td>2.710507</td>\n",
       "      <td>0.05</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>48</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "33      33  0.189743 2022-05-17 08:12:29.776353 2022-05-17 08:14:06.002324   \n",
       "43      43  0.192817 2022-05-17 08:25:33.651305 2022-05-17 08:27:19.223965   \n",
       "\n",
       "                 duration  params_alpha  params_colsample_bytree  \\\n",
       "33 0 days 00:01:36.225971       0.80666                      0.7   \n",
       "43 0 days 00:01:45.572660       1.57656                      0.7   \n",
       "\n",
       "    params_early_stopping_rounds params_eval_metric  params_gamma  \\\n",
       "33                         100.0   [logloss, error]             0   \n",
       "43                         100.0   [logloss, error]             0   \n",
       "\n",
       "    params_lambda  params_learning_rate  params_max_depth  \\\n",
       "33       0.001223                  0.05                13   \n",
       "43       2.710507                  0.05                13   \n",
       "\n",
       "    params_min_child_weight  params_n_estimators  params_random_state  \\\n",
       "33                        6                 1000                   48   \n",
       "43                        4                 1000                   48   \n",
       "\n",
       "    params_subsample params_tree_method     state  \n",
       "33               0.9           gpu_hist  COMPLETE  \n",
       "43               0.9           gpu_hist  COMPLETE  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trial results dataframe sorted from best value (RMSE) ascending\n",
    "def ViewResultsAsDf():\n",
    "    stdf = study_results.trials_dataframe()\n",
    "    stdf = stdf.sort_values('value',ascending=True)\n",
    "\n",
    "    return stdf.head(2)    # return here is only used for printing output\n",
    "\n",
    "ViewResultsAsDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:37.684625Z",
     "iopub.status.busy": "2022-05-17T08:36:37.683537Z",
     "iopub.status.idle": "2022-05-17T08:36:38.959570Z",
     "shell.execute_reply": "2022-05-17T08:36:38.958596Z",
     "shell.execute_reply.started": "2022-05-17T08:36:37.684575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"eff52f1b-7ba2-4182-babe-7fa98ba38277\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eff52f1b-7ba2-4182-babe-7fa98ba38277\")) {                    Plotly.newPlot(                        \"eff52f1b-7ba2-4182-babe-7fa98ba38277\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"early_stopping_rounds (CategoricalDistribution): 0.0<extra></extra>\",\"eval_metric (CategoricalDistribution): 0.0<extra></extra>\",\"n_estimators (CategoricalDistribution): 0.0<extra></extra>\",\"random_state (CategoricalDistribution): 0.0<extra></extra>\",\"tree_method (CategoricalDistribution): 0.0<extra></extra>\",\"alpha (LogUniformDistribution): 0.007889631163880098<extra></extra>\",\"colsample_bytree (CategoricalDistribution): 0.012610733720363945<extra></extra>\",\"subsample (CategoricalDistribution): 0.017341767998844685<extra></extra>\",\"gamma (CategoricalDistribution): 0.02947771337954888<extra></extra>\",\"min_child_weight (IntUniformDistribution): 0.030399398243637264<extra></extra>\",\"lambda (LogUniformDistribution): 0.03348795715013248<extra></extra>\",\"max_depth (CategoricalDistribution): 0.03614523829913609<extra></extra>\",\"learning_rate (CategoricalDistribution): 0.8326475600444564<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.0\",\"0.0\",\"0.0\",\"0.0\",\"0.0\",\"0.007889631163880098\",\"0.012610733720363945\",\"0.017341767998844685\",\"0.02947771337954888\",\"0.030399398243637264\",\"0.03348795715013248\",\"0.03614523829913609\",\"0.8326475600444564\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.0,0.0,0.0,0.0,0.0,0.007889631163880098,0.012610733720363945,0.017341767998844685,0.02947771337954888,0.030399398243637264,0.03348795715013248,0.03614523829913609,0.8326475600444564],\"y\":[\"early_stopping_rounds\",\"eval_metric\",\"n_estimators\",\"random_state\",\"tree_method\",\"alpha\",\"colsample_bytree\",\"subsample\",\"gamma\",\"min_child_weight\",\"lambda\",\"max_depth\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('eff52f1b-7ba2-4182-babe-7fa98ba38277');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize parameter importance\n",
    "optuna.visualization.plot_param_importances(study_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:38.961699Z",
     "iopub.status.busy": "2022-05-17T08:36:38.961365Z",
     "iopub.status.idle": "2022-05-17T08:36:38.968410Z",
     "shell.execute_reply": "2022-05-17T08:36:38.967438Z",
     "shell.execute_reply.started": "2022-05-17T08:36:38.961652Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"Optuna run completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"try_best_hp\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.4 Model v4 : Try the Optuna Hyperparameters</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:36:38.975237Z",
     "iopub.status.busy": "2022-05-17T08:36:38.973421Z",
     "iopub.status.idle": "2022-05-17T08:38:25.150111Z",
     "shell.execute_reply": "2022-05-17T08:38:25.149064Z",
     "shell.execute_reply.started": "2022-05-17T08:36:38.975180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status Count ->  1 : 714212, 0 : 154451\n",
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n",
      "\n",
      "\u001b[1mPlease wait, Fitting model can take time ...\u001b[0m\n",
      "Fitting model completed.\n",
      "\n",
      "Preparing Predictions\n",
      "\n",
      "\u001b[4mMetrics : After Optuna Tuning\u001b[0m\n",
      "MAE: 0.03636635179031475\n",
      "RMSE: 0.19069963762502212\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    107132\n",
      "           1       0.98      0.95      0.96    107132\n",
      "\n",
      "    accuracy                           0.96    214264\n",
      "   macro avg       0.96      0.96      0.96    214264\n",
      "weighted avg       0.96      0.96      0.96    214264\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 105039 times correctly   (94.85 %)\n",
      "False Negative : CHGOFF (0) was predicted 5699 times incorrectly     (5.15 %)\n",
      "True Positive : P I F (1) was predicted 101433 times correctly     (97.98 %)\n",
      "False Positive : P I F (1) was predicted 2093 times incorrectly     (2.02 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 96.36\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 96.42\n",
      "   P I F (1)  : 96.3\n",
      "RMSE: 0.19069963762502212\n",
      "Total boosted rounds: 1000\n",
      "CPU times: user 1min 41s, sys: 993 ms, total: 1min 42s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv4():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    model4 = process_model(X, y)\n",
    "    model4.osample()\n",
    "    model4.split_data(0.7)\n",
    "    \n",
    "    model4.X, model4.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    model4_results = model4.prep_run_model(\"Metrics : After Optuna Tuning\",\n",
    "                                           hyperparams = best_trial)\n",
    "    \n",
    "    text_boosted = \\\n",
    "        f\"Total boosted rounds: {model4_results['xg_model'].get_booster().num_boosted_rounds()}\"\n",
    "    print(text_boosted)\n",
    "    \n",
    "    # save to files for reuse later\n",
    "    model4_results['xg_model'].save_model(f'{workdir}modelv4.json')\n",
    "    joblib.dump(model4_results, f\"{workdir}model4_results.dict\")   \n",
    "\n",
    "#with warnings.catch_warnings():\n",
    "#    warnings.filterwarnings('ignore')\n",
    "#    warnings.simplefilter(\"ignore\")\n",
    "RunModelv4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_comparison\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.5 Optuna Tuning Comparison</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Compare metrics before and after Optuna tuning.</b><br><br>\n",
    "    Comparison is made between modelv3 results in <a style=\"color:DarkSlateGrey\" href=\"https://www.kaggle.com/code/josephramon/sba-xgboost-model\">Part 1 Notebook</a> and modelv4 results here.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:38:25.152657Z",
     "iopub.status.busy": "2022-05-17T08:38:25.152114Z",
     "iopub.status.idle": "2022-05-17T08:38:26.195140Z",
     "shell.execute_reply": "2022-05-17T08:38:26.194108Z",
     "shell.execute_reply.started": "2022-05-17T08:38:25.152613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mAccuracy Improvement Using Optuna Suggested Parameters:\u001b[0m\n",
      "\u001b[1mImproved by \u001b[1m\u001b[94m3.49        \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model v3 : No Optuna</th>\n",
       "      <th>Model v4 : With Optuna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 : f1_score</th>\n",
       "      <td>92.90</td>\n",
       "      <td>96.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 : f1_score</th>\n",
       "      <td>92.85</td>\n",
       "      <td>96.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>92.87</td>\n",
       "      <td>96.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model v3 : No Optuna  Model v4 : With Optuna\n",
       "0 : f1_score                 92.90                   96.42\n",
       "1 : f1_score                 92.85                   96.30\n",
       "Accuracy                     92.87                   96.36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CompareResults():\n",
    "    model3_results = joblib.load(f\"{inputdir}model3_results.dict\")\n",
    "    model4_results = joblib.load(f\"{workdir}model4_results.dict\")\n",
    "\n",
    "    m3_clf_report = model3_results['eval_results']['ClassificationReport']\n",
    "\n",
    "    m3_0_f1_score = round(m3_clf_report['0']['f1-score'] * 100, 2)\n",
    "    m3_1_f1_score = round(m3_clf_report['1']['f1-score'] * 100, 2)\n",
    "    m3_accuracy   = round(m3_clf_report['accuracy'] * 100, 2)\n",
    "\n",
    "\n",
    "    m4_clf_report = model4_results['eval_results']['ClassificationReport']\n",
    "\n",
    "    m4_0_f1_score = round(m4_clf_report['0']['f1-score'] * 100, 2)\n",
    "    m4_1_f1_score = round(m4_clf_report['1']['f1-score'] * 100, 2)\n",
    "    m4_accuracy   = round(m4_clf_report['accuracy'] * 100, 2)\n",
    "\n",
    "\n",
    "    data = {'Model v3 : No Optuna':[m3_0_f1_score, m3_1_f1_score, m3_accuracy],\n",
    "            'Model v4 : With Optuna':[m4_0_f1_score, m4_1_f1_score, m4_accuracy]}\n",
    " \n",
    "    # Creates pandas DataFrame.\n",
    "    df = pd.DataFrame(data, index =['0 : f1_score',\n",
    "                                    '1 : f1_score',\n",
    "                                    'Accuracy'])\n",
    "    print(f'{color.bdgreen}Accuracy Improvement Using Optuna Suggested Parameters:{color.end}')\n",
    "    print(f'{color.bold}Improved by {color.bdblue}{round(m4_accuracy - m3_accuracy,2)}\\\n",
    "        {color.end}')\n",
    "    return df\n",
    "\n",
    "CompareResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can get either a slightly higher or lower score if we run Optuna again.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Run Modelv4 On Unseen Test Dataset</b>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:38:26.197727Z",
     "iopub.status.busy": "2022-05-17T08:38:26.197093Z",
     "iopub.status.idle": "2022-05-17T08:39:00.569758Z",
     "shell.execute_reply": "2022-05-17T08:39:00.568756Z",
     "shell.execute_reply.started": "2022-05-17T08:38:26.197679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.03645036030317739\n",
      "RMSE: 0.1909197745210731\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    107132\n",
      "           1       0.98      0.95      0.96    107132\n",
      "\n",
      "    accuracy                           0.96    214264\n",
      "   macro avg       0.96      0.96      0.96    214264\n",
      "weighted avg       0.96      0.96      0.96    214264\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 105113 times correctly   (94.78 %)\n",
      "False Negative : CHGOFF (0) was predicted 5791 times incorrectly     (5.22 %)\n",
      "True Positive : P I F (1) was predicted 101341 times correctly     (98.05 %)\n",
      "False Positive : P I F (1) was predicted 2019 times incorrectly     (1.95 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 96.35\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 96.42\n",
      "   P I F (1)  : 96.29\n",
      "RMSE: 0.1909197745210731\n"
     ]
    }
   ],
   "source": [
    "def Modelv4WithTestData():\n",
    "    model4_results = joblib.load(f\"{workdir}model4_results.dict\")\n",
    "    X_test = model4_results['X_test']\n",
    "    y_test = model4_results['y_test']\n",
    "    modelv4 = model4_results['xg_model']\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = modelv4.predict(X_test)\n",
    "    model_eval(y_test, predictions);\n",
    "  \n",
    "Modelv4WithTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:39:00.572161Z",
     "iopub.status.busy": "2022-05-17T08:39:00.571585Z",
     "iopub.status.idle": "2022-05-17T08:39:00.812666Z",
     "shell.execute_reply": "2022-05-17T08:39:00.811519Z",
     "shell.execute_reply.started": "2022-05-17T08:39:00.572110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del best_trial, study_results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Observation:</b><br><br>\n",
    "    <b>The Accuracy and F1 scores after Optuna tuning are improved compared to before tuning;</b> but it all depends on what hyperparameters/values are given.  A few trial sessions may be needed.<br><br>\n",
    "    We have a different score in our <a style=\"color:DarkSlateGrey\" href=\"https://www.kaggle.com/code/josephramon/sba-xgboost-model\">Pipeline</a> as we used an Optuna hyperparameter set that was obtained from another Optuna run.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross_validation\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>Cross Validation</h2><br>\n",
    "Measure our model's quality, in RMSE.  Ideally for small datasets, but included here for reference.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:39:00.815552Z",
     "iopub.status.busy": "2022-05-17T08:39:00.814457Z",
     "iopub.status.idle": "2022-05-17T08:46:28.034624Z",
     "shell.execute_reply": "2022-05-17T08:46:28.033528Z",
     "shell.execute_reply.started": "2022-05-17T08:39:00.815453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPlease wait, this will take some time\u001b[0m\n",
      "\n",
      "MIS_Status Count ->  1 : 714212, 0 : 154451\n",
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'gpu_hist',\n",
       " 'lambda': 0.001222882589196536,\n",
       " 'alpha': 0.8066599284119552,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'subsample': 0.9,\n",
       " 'learning_rate': 0.05,\n",
       " 'n_estimators': 1000,\n",
       " 'max_depth': 13,\n",
       " 'random_state': 48,\n",
       " 'min_child_weight': 6,\n",
       " 'early_stopping_rounds': 100.0,\n",
       " 'eval_metric': ['logloss', 'error']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................... score: (test=-0.197) total time= 1.5min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................... score: (test=-0.199) total time= 1.5min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................... score: (test=-0.198) total time= 1.5min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................... score: (test=-0.201) total time= 1.4min\n",
      "[CV] START .....................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  5.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................... score: (test=-0.199) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  7.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[94mScores: [0.19698701 0.19886969 0.19774758 0.20054731 0.19923395]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mRoot Mean Squared Error (Mean): 0.19867710719002235\u001b[0m\n",
      "\n",
      "CPU times: user 7min 14s, sys: 1.8 s, total: 7min 16s\n",
      "Wall time: 7min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def CrossVal():\n",
    "    print(f'{color.bold}Please wait, this will take some time{color.end}')\n",
    "    print()\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    cvo = process_model(X, y)   # create object from XGBoost class\n",
    "    cvo.osample()               # oversample\n",
    "    cvo.split_data(0.7)\n",
    "\n",
    "    cvo.X, cvo.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # get hyperparams from previous Optuna study's best trial\n",
    "    study_results = joblib.load(f\"{workdir}xgb_optuna_study.pkl\")\n",
    "    hyperparams = study_results.best_trial.params\n",
    "    display(hyperparams)\n",
    "    print()\n",
    "\n",
    "    xgb_model = XGBClassifier(**hyperparams, use_label_encoder = False)\n",
    "\n",
    "    # If we pass a pipeline instead of a model to cross_val_score, fit_params won't be \n",
    "    # recognized\n",
    "    fit_params={'verbose': False,\n",
    "                'eval_set': [(cvo.X_valid, cvo.y_valid)]\n",
    "               }\n",
    "\n",
    "    # Multiply by -1 since sklearn calculates *negative* RMSE\n",
    "    print()\n",
    "    scores = -1 * cross_val_score(xgb_model, cvo.X_train, cvo.y_train,\n",
    "                                  cv=5,\n",
    "                                  scoring='neg_root_mean_squared_error',\n",
    "                                  fit_params = fit_params,\n",
    "                                  verbose=15)\n",
    "    sleep(5)   # allow verbosity to complete\n",
    "    print()\n",
    "    print(f\"{color.bdblue}Scores: {scores}{color.end}\")\n",
    "    print()\n",
    "    print(f\"{color.bdgreen}Root Mean Squared Error (Mean): {scores.mean()}{color.end}\")\n",
    "    print()\n",
    "    \n",
    "CrossVal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:46:28.037125Z",
     "iopub.status.busy": "2022-05-17T08:46:28.036756Z",
     "iopub.status.idle": "2022-05-17T08:46:28.043493Z",
     "shell.execute_reply": "2022-05-17T08:46:28.042318Z",
     "shell.execute_reply.started": "2022-05-17T08:46:28.037076Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"Cross-Validation completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 id=\"part2\" style='color:GhostWhite;'>Part 2. Miscellaneous</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"early_stopping_rounds\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.1 Early Stopping Rounds</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Below is a reference on using plots to get an insight on the value to use for XGBoost's early_ stopping_rounds during fitting.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:46:28.046257Z",
     "iopub.status.busy": "2022-05-17T08:46:28.045561Z",
     "iopub.status.idle": "2022-05-17T08:48:05.884271Z",
     "shell.execute_reply": "2022-05-17T08:48:05.883148Z",
     "shell.execute_reply.started": "2022-05-17T08:46:28.046207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status Count ->  1 : 714212, 0 : 154451\n",
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n",
      "\n",
      "\u001b[1mPlease wait, Fitting model can take time ...\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'gpu_hist',\n",
       " 'lambda': 0.001222882589196536,\n",
       " 'alpha': 0.8066599284119552,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'subsample': 0.9,\n",
       " 'learning_rate': 0.05,\n",
       " 'n_estimators': 1000,\n",
       " 'max_depth': 13,\n",
       " 'random_state': 48,\n",
       " 'min_child_weight': 6,\n",
       " 'eval_metric': ['error', 'logloss']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting model completed.\n",
      "\n",
      "Preparing Predictions\n",
      "\n",
      "\u001b[4mMetrics:\u001b[0m\n",
      "MAE: 0.03626367471903819\n",
      "RMSE: 0.1904302358320185\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    107132\n",
      "           1       0.98      0.95      0.96    107132\n",
      "\n",
      "    accuracy                           0.96    214264\n",
      "   macro avg       0.96      0.96      0.96    214264\n",
      "weighted avg       0.96      0.96      0.96    214264\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 105087 times correctly   (94.83 %)\n",
      "False Negative : CHGOFF (0) was predicted 5725 times incorrectly     (5.17 %)\n",
      "True Positive : P I F (1) was predicted 101407 times correctly     (98.02 %)\n",
      "False Positive : P I F (1) was predicted 2045 times incorrectly     (1.98 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 96.37\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 96.43\n",
      "   P I F (1)  : 96.31\n",
      "RMSE: 0.1904302358320185\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 716 ms, total: 1min 34s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def PlotEarlyStoppingRounds():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    esr = process_model(X, y)\n",
    "    esr.osample()     # oversample\n",
    "    esr.split_data(0.7)\n",
    "    \n",
    "    esr.X, esr.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)   \n",
    "    \n",
    "    print()\n",
    "    print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")\n",
    "    print()\n",
    "    \n",
    "    # get hyperparams from previous Optuna study's best trial\n",
    "    # early_stopping_rounds not included as we are trying to confirm if our value was valid\n",
    "    study_results = joblib.load(f\"{workdir}xgb_optuna_study.pkl\")\n",
    "    hyperparams = study_results.best_trial.params\n",
    "    hyperparams.pop('early_stopping_rounds')\n",
    "    hyperparams['eval_metric'] = ['error','logloss']\n",
    "    display(hyperparams)\n",
    "    print()\n",
    "\n",
    "    xg_model = XGBClassifier(**hyperparams,use_label_encoder =False)\n",
    "       \n",
    "    eval_setparam = [(esr.X_train, esr.y_train),\n",
    "                     (esr.X_valid, esr.y_valid)]\n",
    "       \n",
    "    # fit the model\n",
    "    xg_model.fit(esr.X_train, esr.y_train, \n",
    "                eval_set = eval_setparam,\n",
    "                verbose=False)\n",
    " \n",
    "    print(\"Fitting model completed.\")\n",
    "    print()\n",
    "    print('Preparing Predictions')\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = xg_model.predict(esr.X_valid)\n",
    "    \n",
    "    print()\n",
    "    print(f'{color.underline}Metrics:{color.end}')\n",
    "\n",
    "    eval_results = model_eval(esr.y_valid, predictions)\n",
    "\n",
    "    # retrieve performance metrics\n",
    "    results = xg_model.evals_result()\n",
    "    epochs = len(results['validation_0']['error'])\n",
    "    x_axis = range(0, epochs)\n",
    "\n",
    "    # what we will be looking for are the bottom areas of the plots\n",
    "    \n",
    "    # plot log loss\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Log Loss')\n",
    "    pyplot.title('XGBoost Log Loss')\n",
    "    pyplot.show()\n",
    "\n",
    "    # plot classification error\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Classification Error')\n",
    "    pyplot.title('XGBoost Classification Error')\n",
    "    pyplot.show()\n",
    "    \n",
    "PlotEarlyStoppingRounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    From both plots, we can see that 10% of n_estimator is a good candidate as the early_stopping_rounds parameter.\n",
    "<br><br>\n",
    "    <b>Test Early Stopping Rounds</b>\n",
    "    <br>\n",
    "    Now we test the early_stopping_rounds parameter.  We will test it on imbalanced data, which is our data that is <b>not oversampled</b>, which is skewed heavily toward MIS_Status = 'P I F' as opposed to MIS_Status = 'CHGOFF'.  Furthermore, we use an <b>eval_metric = 'auc'</b>, which is ideal for imbalanced data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:48:05.886953Z",
     "iopub.status.busy": "2022-05-17T08:48:05.886096Z",
     "iopub.status.idle": "2022-05-17T08:48:43.363892Z",
     "shell.execute_reply": "2022-05-17T08:48:43.362893Z",
     "shell.execute_reply.started": "2022-05-17T08:48:05.886891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status Count ->  1 : 714212, 0 : 154451\n",
      "\u001b[1mFit() Iterations:\u001b[0m\n",
      "[0]\tvalidation_0-auc:0.77560\n",
      "[1]\tvalidation_0-auc:0.95466\n",
      "[2]\tvalidation_0-auc:0.96434\n",
      "[3]\tvalidation_0-auc:0.95924\n",
      "[4]\tvalidation_0-auc:0.96480\n",
      "[5]\tvalidation_0-auc:0.96731\n",
      "[6]\tvalidation_0-auc:0.96458\n",
      "[7]\tvalidation_0-auc:0.96681\n",
      "[8]\tvalidation_0-auc:0.96841\n",
      "[9]\tvalidation_0-auc:0.96931\n",
      "[10]\tvalidation_0-auc:0.96998\n",
      "[11]\tvalidation_0-auc:0.97074\n",
      "[12]\tvalidation_0-auc:0.97126\n",
      "[13]\tvalidation_0-auc:0.97140\n",
      "[14]\tvalidation_0-auc:0.97163\n",
      "[15]\tvalidation_0-auc:0.97189\n",
      "[16]\tvalidation_0-auc:0.97214\n",
      "[17]\tvalidation_0-auc:0.97229\n",
      "[18]\tvalidation_0-auc:0.97243\n",
      "[19]\tvalidation_0-auc:0.97251\n",
      "[20]\tvalidation_0-auc:0.97257\n",
      "[21]\tvalidation_0-auc:0.97273\n",
      "[22]\tvalidation_0-auc:0.97288\n",
      "[23]\tvalidation_0-auc:0.97286\n",
      "[24]\tvalidation_0-auc:0.97278\n",
      "[25]\tvalidation_0-auc:0.97291\n",
      "[26]\tvalidation_0-auc:0.97302\n",
      "[27]\tvalidation_0-auc:0.97316\n",
      "[28]\tvalidation_0-auc:0.97323\n",
      "[29]\tvalidation_0-auc:0.97333\n",
      "[30]\tvalidation_0-auc:0.97336\n",
      "[31]\tvalidation_0-auc:0.97334\n",
      "[32]\tvalidation_0-auc:0.97346\n",
      "[33]\tvalidation_0-auc:0.97344\n",
      "[34]\tvalidation_0-auc:0.97353\n",
      "[35]\tvalidation_0-auc:0.97358\n",
      "[36]\tvalidation_0-auc:0.97368\n",
      "[37]\tvalidation_0-auc:0.97375\n",
      "[38]\tvalidation_0-auc:0.97379\n",
      "[39]\tvalidation_0-auc:0.97376\n",
      "[40]\tvalidation_0-auc:0.97385\n",
      "[41]\tvalidation_0-auc:0.97385\n",
      "[42]\tvalidation_0-auc:0.97382\n",
      "[43]\tvalidation_0-auc:0.97392\n",
      "[44]\tvalidation_0-auc:0.97398\n",
      "[45]\tvalidation_0-auc:0.97406\n",
      "[46]\tvalidation_0-auc:0.97410\n",
      "[47]\tvalidation_0-auc:0.97415\n",
      "[48]\tvalidation_0-auc:0.97421\n",
      "[49]\tvalidation_0-auc:0.97427\n",
      "[50]\tvalidation_0-auc:0.97430\n",
      "[51]\tvalidation_0-auc:0.97436\n",
      "[52]\tvalidation_0-auc:0.97440\n",
      "[53]\tvalidation_0-auc:0.97442\n",
      "[54]\tvalidation_0-auc:0.97443\n",
      "[55]\tvalidation_0-auc:0.97448\n",
      "[56]\tvalidation_0-auc:0.97446\n",
      "[57]\tvalidation_0-auc:0.97450\n",
      "[58]\tvalidation_0-auc:0.97459\n",
      "[59]\tvalidation_0-auc:0.97460\n",
      "[60]\tvalidation_0-auc:0.97465\n",
      "[61]\tvalidation_0-auc:0.97470\n",
      "[62]\tvalidation_0-auc:0.97473\n",
      "[63]\tvalidation_0-auc:0.97481\n",
      "[64]\tvalidation_0-auc:0.97486\n",
      "[65]\tvalidation_0-auc:0.97491\n",
      "[66]\tvalidation_0-auc:0.97493\n",
      "[67]\tvalidation_0-auc:0.97497\n",
      "[68]\tvalidation_0-auc:0.97504\n",
      "[69]\tvalidation_0-auc:0.97507\n",
      "[70]\tvalidation_0-auc:0.97512\n",
      "[71]\tvalidation_0-auc:0.97515\n",
      "[72]\tvalidation_0-auc:0.97519\n",
      "[73]\tvalidation_0-auc:0.97523\n",
      "[74]\tvalidation_0-auc:0.97526\n",
      "[75]\tvalidation_0-auc:0.97527\n",
      "[76]\tvalidation_0-auc:0.97530\n",
      "[77]\tvalidation_0-auc:0.97533\n",
      "[78]\tvalidation_0-auc:0.97536\n",
      "[79]\tvalidation_0-auc:0.97536\n",
      "[80]\tvalidation_0-auc:0.97537\n",
      "[81]\tvalidation_0-auc:0.97540\n",
      "[82]\tvalidation_0-auc:0.97541\n",
      "[83]\tvalidation_0-auc:0.97545\n",
      "[84]\tvalidation_0-auc:0.97547\n",
      "[85]\tvalidation_0-auc:0.97550\n",
      "[86]\tvalidation_0-auc:0.97555\n",
      "[87]\tvalidation_0-auc:0.97557\n",
      "[88]\tvalidation_0-auc:0.97559\n",
      "[89]\tvalidation_0-auc:0.97561\n",
      "[90]\tvalidation_0-auc:0.97562\n",
      "[91]\tvalidation_0-auc:0.97564\n",
      "[92]\tvalidation_0-auc:0.97565\n",
      "[93]\tvalidation_0-auc:0.97567\n",
      "[94]\tvalidation_0-auc:0.97569\n",
      "[95]\tvalidation_0-auc:0.97572\n",
      "[96]\tvalidation_0-auc:0.97575\n",
      "[97]\tvalidation_0-auc:0.97577\n",
      "[98]\tvalidation_0-auc:0.97581\n",
      "[99]\tvalidation_0-auc:0.97582\n",
      "[100]\tvalidation_0-auc:0.97583\n",
      "[101]\tvalidation_0-auc:0.97586\n",
      "[102]\tvalidation_0-auc:0.97588\n",
      "[103]\tvalidation_0-auc:0.97590\n",
      "[104]\tvalidation_0-auc:0.97592\n",
      "[105]\tvalidation_0-auc:0.97593\n",
      "[106]\tvalidation_0-auc:0.97595\n",
      "[107]\tvalidation_0-auc:0.97596\n",
      "[108]\tvalidation_0-auc:0.97596\n",
      "[109]\tvalidation_0-auc:0.97598\n",
      "[110]\tvalidation_0-auc:0.97600\n",
      "[111]\tvalidation_0-auc:0.97601\n",
      "[112]\tvalidation_0-auc:0.97602\n",
      "[113]\tvalidation_0-auc:0.97605\n",
      "[114]\tvalidation_0-auc:0.97606\n",
      "[115]\tvalidation_0-auc:0.97608\n",
      "[116]\tvalidation_0-auc:0.97609\n",
      "[117]\tvalidation_0-auc:0.97612\n",
      "[118]\tvalidation_0-auc:0.97614\n",
      "[119]\tvalidation_0-auc:0.97616\n",
      "[120]\tvalidation_0-auc:0.97619\n",
      "[121]\tvalidation_0-auc:0.97621\n",
      "[122]\tvalidation_0-auc:0.97624\n",
      "[123]\tvalidation_0-auc:0.97624\n",
      "[124]\tvalidation_0-auc:0.97625\n",
      "[125]\tvalidation_0-auc:0.97628\n",
      "[126]\tvalidation_0-auc:0.97629\n",
      "[127]\tvalidation_0-auc:0.97629\n",
      "[128]\tvalidation_0-auc:0.97630\n",
      "[129]\tvalidation_0-auc:0.97631\n",
      "[130]\tvalidation_0-auc:0.97633\n",
      "[131]\tvalidation_0-auc:0.97634\n",
      "[132]\tvalidation_0-auc:0.97634\n",
      "[133]\tvalidation_0-auc:0.97635\n",
      "[134]\tvalidation_0-auc:0.97637\n",
      "[135]\tvalidation_0-auc:0.97639\n",
      "[136]\tvalidation_0-auc:0.97640\n",
      "[137]\tvalidation_0-auc:0.97643\n",
      "[138]\tvalidation_0-auc:0.97644\n",
      "[139]\tvalidation_0-auc:0.97646\n",
      "[140]\tvalidation_0-auc:0.97648\n",
      "[141]\tvalidation_0-auc:0.97649\n",
      "[142]\tvalidation_0-auc:0.97650\n",
      "[143]\tvalidation_0-auc:0.97650\n",
      "[144]\tvalidation_0-auc:0.97652\n",
      "[145]\tvalidation_0-auc:0.97653\n",
      "[146]\tvalidation_0-auc:0.97654\n",
      "[147]\tvalidation_0-auc:0.97654\n",
      "[148]\tvalidation_0-auc:0.97654\n",
      "[149]\tvalidation_0-auc:0.97655\n",
      "[150]\tvalidation_0-auc:0.97656\n",
      "[151]\tvalidation_0-auc:0.97657\n",
      "[152]\tvalidation_0-auc:0.97657\n",
      "[153]\tvalidation_0-auc:0.97657\n",
      "[154]\tvalidation_0-auc:0.97658\n",
      "[155]\tvalidation_0-auc:0.97659\n",
      "[156]\tvalidation_0-auc:0.97661\n",
      "[157]\tvalidation_0-auc:0.97661\n",
      "[158]\tvalidation_0-auc:0.97662\n",
      "[159]\tvalidation_0-auc:0.97662\n",
      "[160]\tvalidation_0-auc:0.97663\n",
      "[161]\tvalidation_0-auc:0.97664\n",
      "[162]\tvalidation_0-auc:0.97665\n",
      "[163]\tvalidation_0-auc:0.97665\n",
      "[164]\tvalidation_0-auc:0.97666\n",
      "[165]\tvalidation_0-auc:0.97667\n",
      "[166]\tvalidation_0-auc:0.97667\n",
      "[167]\tvalidation_0-auc:0.97667\n",
      "[168]\tvalidation_0-auc:0.97669\n",
      "[169]\tvalidation_0-auc:0.97669\n",
      "[170]\tvalidation_0-auc:0.97670\n",
      "[171]\tvalidation_0-auc:0.97671\n",
      "[172]\tvalidation_0-auc:0.97671\n",
      "[173]\tvalidation_0-auc:0.97672\n",
      "[174]\tvalidation_0-auc:0.97673\n",
      "[175]\tvalidation_0-auc:0.97673\n",
      "[176]\tvalidation_0-auc:0.97673\n",
      "[177]\tvalidation_0-auc:0.97673\n",
      "[178]\tvalidation_0-auc:0.97673\n",
      "[179]\tvalidation_0-auc:0.97675\n",
      "[180]\tvalidation_0-auc:0.97674\n",
      "[181]\tvalidation_0-auc:0.97675\n",
      "[182]\tvalidation_0-auc:0.97677\n",
      "[183]\tvalidation_0-auc:0.97677\n",
      "[184]\tvalidation_0-auc:0.97677\n",
      "[185]\tvalidation_0-auc:0.97678\n",
      "[186]\tvalidation_0-auc:0.97678\n",
      "[187]\tvalidation_0-auc:0.97678\n",
      "[188]\tvalidation_0-auc:0.97680\n",
      "[189]\tvalidation_0-auc:0.97680\n",
      "[190]\tvalidation_0-auc:0.97680\n",
      "[191]\tvalidation_0-auc:0.97680\n",
      "[192]\tvalidation_0-auc:0.97680\n",
      "[193]\tvalidation_0-auc:0.97681\n",
      "[194]\tvalidation_0-auc:0.97682\n",
      "[195]\tvalidation_0-auc:0.97683\n",
      "[196]\tvalidation_0-auc:0.97683\n",
      "[197]\tvalidation_0-auc:0.97683\n",
      "[198]\tvalidation_0-auc:0.97683\n",
      "[199]\tvalidation_0-auc:0.97684\n",
      "[200]\tvalidation_0-auc:0.97684\n",
      "[201]\tvalidation_0-auc:0.97685\n",
      "[202]\tvalidation_0-auc:0.97686\n",
      "[203]\tvalidation_0-auc:0.97687\n",
      "[204]\tvalidation_0-auc:0.97687\n",
      "[205]\tvalidation_0-auc:0.97688\n",
      "[206]\tvalidation_0-auc:0.97687\n",
      "[207]\tvalidation_0-auc:0.97687\n",
      "[208]\tvalidation_0-auc:0.97688\n",
      "[209]\tvalidation_0-auc:0.97688\n",
      "[210]\tvalidation_0-auc:0.97688\n",
      "[211]\tvalidation_0-auc:0.97689\n",
      "[212]\tvalidation_0-auc:0.97690\n",
      "[213]\tvalidation_0-auc:0.97690\n",
      "[214]\tvalidation_0-auc:0.97691\n",
      "[215]\tvalidation_0-auc:0.97691\n",
      "[216]\tvalidation_0-auc:0.97692\n",
      "[217]\tvalidation_0-auc:0.97692\n",
      "[218]\tvalidation_0-auc:0.97692\n",
      "[219]\tvalidation_0-auc:0.97693\n",
      "[220]\tvalidation_0-auc:0.97693\n",
      "[221]\tvalidation_0-auc:0.97693\n",
      "[222]\tvalidation_0-auc:0.97693\n",
      "[223]\tvalidation_0-auc:0.97694\n",
      "[224]\tvalidation_0-auc:0.97694\n",
      "[225]\tvalidation_0-auc:0.97694\n",
      "[226]\tvalidation_0-auc:0.97695\n",
      "[227]\tvalidation_0-auc:0.97694\n",
      "[228]\tvalidation_0-auc:0.97694\n",
      "[229]\tvalidation_0-auc:0.97694\n",
      "[230]\tvalidation_0-auc:0.97695\n",
      "[231]\tvalidation_0-auc:0.97695\n",
      "[232]\tvalidation_0-auc:0.97695\n",
      "[233]\tvalidation_0-auc:0.97695\n",
      "[234]\tvalidation_0-auc:0.97696\n",
      "[235]\tvalidation_0-auc:0.97696\n",
      "[236]\tvalidation_0-auc:0.97696\n",
      "[237]\tvalidation_0-auc:0.97696\n",
      "[238]\tvalidation_0-auc:0.97697\n",
      "[239]\tvalidation_0-auc:0.97697\n",
      "[240]\tvalidation_0-auc:0.97698\n",
      "[241]\tvalidation_0-auc:0.97699\n",
      "[242]\tvalidation_0-auc:0.97699\n",
      "[243]\tvalidation_0-auc:0.97699\n",
      "[244]\tvalidation_0-auc:0.97700\n",
      "[245]\tvalidation_0-auc:0.97700\n",
      "[246]\tvalidation_0-auc:0.97700\n",
      "[247]\tvalidation_0-auc:0.97700\n",
      "[248]\tvalidation_0-auc:0.97701\n",
      "[249]\tvalidation_0-auc:0.97701\n",
      "[250]\tvalidation_0-auc:0.97702\n",
      "[251]\tvalidation_0-auc:0.97702\n",
      "[252]\tvalidation_0-auc:0.97702\n",
      "[253]\tvalidation_0-auc:0.97702\n",
      "[254]\tvalidation_0-auc:0.97703\n",
      "[255]\tvalidation_0-auc:0.97702\n",
      "[256]\tvalidation_0-auc:0.97703\n",
      "[257]\tvalidation_0-auc:0.97703\n",
      "[258]\tvalidation_0-auc:0.97704\n",
      "[259]\tvalidation_0-auc:0.97704\n",
      "[260]\tvalidation_0-auc:0.97704\n",
      "[261]\tvalidation_0-auc:0.97704\n",
      "[262]\tvalidation_0-auc:0.97704\n",
      "[263]\tvalidation_0-auc:0.97704\n",
      "[264]\tvalidation_0-auc:0.97704\n",
      "[265]\tvalidation_0-auc:0.97704\n",
      "[266]\tvalidation_0-auc:0.97704\n",
      "[267]\tvalidation_0-auc:0.97705\n",
      "[268]\tvalidation_0-auc:0.97705\n",
      "[269]\tvalidation_0-auc:0.97705\n",
      "[270]\tvalidation_0-auc:0.97705\n",
      "[271]\tvalidation_0-auc:0.97705\n",
      "[272]\tvalidation_0-auc:0.97705\n",
      "[273]\tvalidation_0-auc:0.97706\n",
      "[274]\tvalidation_0-auc:0.97706\n",
      "[275]\tvalidation_0-auc:0.97706\n",
      "[276]\tvalidation_0-auc:0.97706\n",
      "[277]\tvalidation_0-auc:0.97706\n",
      "[278]\tvalidation_0-auc:0.97706\n",
      "[279]\tvalidation_0-auc:0.97706\n",
      "[280]\tvalidation_0-auc:0.97706\n",
      "[281]\tvalidation_0-auc:0.97707\n",
      "[282]\tvalidation_0-auc:0.97707\n",
      "[283]\tvalidation_0-auc:0.97707\n",
      "[284]\tvalidation_0-auc:0.97707\n",
      "[285]\tvalidation_0-auc:0.97707\n",
      "[286]\tvalidation_0-auc:0.97708\n",
      "[287]\tvalidation_0-auc:0.97708\n",
      "[288]\tvalidation_0-auc:0.97708\n",
      "[289]\tvalidation_0-auc:0.97709\n",
      "[290]\tvalidation_0-auc:0.97709\n",
      "[291]\tvalidation_0-auc:0.97709\n",
      "[292]\tvalidation_0-auc:0.97709\n",
      "[293]\tvalidation_0-auc:0.97709\n",
      "[294]\tvalidation_0-auc:0.97710\n",
      "[295]\tvalidation_0-auc:0.97710\n",
      "[296]\tvalidation_0-auc:0.97710\n",
      "[297]\tvalidation_0-auc:0.97710\n",
      "[298]\tvalidation_0-auc:0.97711\n",
      "[299]\tvalidation_0-auc:0.97711\n",
      "[300]\tvalidation_0-auc:0.97711\n",
      "[301]\tvalidation_0-auc:0.97711\n",
      "[302]\tvalidation_0-auc:0.97711\n",
      "[303]\tvalidation_0-auc:0.97711\n",
      "[304]\tvalidation_0-auc:0.97711\n",
      "[305]\tvalidation_0-auc:0.97711\n",
      "[306]\tvalidation_0-auc:0.97711\n",
      "[307]\tvalidation_0-auc:0.97711\n",
      "[308]\tvalidation_0-auc:0.97711\n",
      "[309]\tvalidation_0-auc:0.97711\n",
      "[310]\tvalidation_0-auc:0.97711\n",
      "[311]\tvalidation_0-auc:0.97711\n",
      "[312]\tvalidation_0-auc:0.97711\n",
      "[313]\tvalidation_0-auc:0.97711\n",
      "[314]\tvalidation_0-auc:0.97711\n",
      "[315]\tvalidation_0-auc:0.97711\n",
      "[316]\tvalidation_0-auc:0.97711\n",
      "[317]\tvalidation_0-auc:0.97711\n",
      "[318]\tvalidation_0-auc:0.97711\n",
      "[319]\tvalidation_0-auc:0.97711\n",
      "[320]\tvalidation_0-auc:0.97712\n",
      "[321]\tvalidation_0-auc:0.97712\n",
      "[322]\tvalidation_0-auc:0.97712\n",
      "[323]\tvalidation_0-auc:0.97712\n",
      "[324]\tvalidation_0-auc:0.97712\n",
      "[325]\tvalidation_0-auc:0.97712\n",
      "[326]\tvalidation_0-auc:0.97711\n",
      "[327]\tvalidation_0-auc:0.97712\n",
      "[328]\tvalidation_0-auc:0.97712\n",
      "[329]\tvalidation_0-auc:0.97712\n",
      "[330]\tvalidation_0-auc:0.97712\n",
      "[331]\tvalidation_0-auc:0.97712\n",
      "[332]\tvalidation_0-auc:0.97712\n",
      "[333]\tvalidation_0-auc:0.97712\n",
      "[334]\tvalidation_0-auc:0.97712\n",
      "[335]\tvalidation_0-auc:0.97713\n",
      "[336]\tvalidation_0-auc:0.97712\n",
      "[337]\tvalidation_0-auc:0.97712\n",
      "[338]\tvalidation_0-auc:0.97713\n",
      "[339]\tvalidation_0-auc:0.97712\n",
      "[340]\tvalidation_0-auc:0.97712\n",
      "[341]\tvalidation_0-auc:0.97712\n",
      "[342]\tvalidation_0-auc:0.97712\n",
      "[343]\tvalidation_0-auc:0.97712\n",
      "[344]\tvalidation_0-auc:0.97713\n",
      "[345]\tvalidation_0-auc:0.97713\n",
      "[346]\tvalidation_0-auc:0.97713\n",
      "[347]\tvalidation_0-auc:0.97713\n",
      "[348]\tvalidation_0-auc:0.97713\n",
      "[349]\tvalidation_0-auc:0.97713\n",
      "[350]\tvalidation_0-auc:0.97713\n",
      "[351]\tvalidation_0-auc:0.97713\n",
      "[352]\tvalidation_0-auc:0.97714\n",
      "[353]\tvalidation_0-auc:0.97714\n",
      "[354]\tvalidation_0-auc:0.97714\n",
      "[355]\tvalidation_0-auc:0.97714\n",
      "[356]\tvalidation_0-auc:0.97713\n",
      "[357]\tvalidation_0-auc:0.97714\n",
      "[358]\tvalidation_0-auc:0.97714\n",
      "[359]\tvalidation_0-auc:0.97714\n",
      "[360]\tvalidation_0-auc:0.97714\n",
      "[361]\tvalidation_0-auc:0.97714\n",
      "[362]\tvalidation_0-auc:0.97714\n",
      "[363]\tvalidation_0-auc:0.97715\n",
      "[364]\tvalidation_0-auc:0.97714\n",
      "[365]\tvalidation_0-auc:0.97714\n",
      "[366]\tvalidation_0-auc:0.97715\n",
      "[367]\tvalidation_0-auc:0.97715\n",
      "[368]\tvalidation_0-auc:0.97715\n",
      "[369]\tvalidation_0-auc:0.97715\n",
      "[370]\tvalidation_0-auc:0.97714\n",
      "[371]\tvalidation_0-auc:0.97715\n",
      "[372]\tvalidation_0-auc:0.97715\n",
      "[373]\tvalidation_0-auc:0.97715\n",
      "[374]\tvalidation_0-auc:0.97715\n",
      "[375]\tvalidation_0-auc:0.97715\n",
      "[376]\tvalidation_0-auc:0.97715\n",
      "[377]\tvalidation_0-auc:0.97715\n",
      "[378]\tvalidation_0-auc:0.97716\n",
      "[379]\tvalidation_0-auc:0.97716\n",
      "[380]\tvalidation_0-auc:0.97716\n",
      "[381]\tvalidation_0-auc:0.97716\n",
      "[382]\tvalidation_0-auc:0.97716\n",
      "[383]\tvalidation_0-auc:0.97716\n",
      "[384]\tvalidation_0-auc:0.97717\n",
      "[385]\tvalidation_0-auc:0.97716\n",
      "[386]\tvalidation_0-auc:0.97717\n",
      "[387]\tvalidation_0-auc:0.97717\n",
      "[388]\tvalidation_0-auc:0.97717\n",
      "[389]\tvalidation_0-auc:0.97717\n",
      "[390]\tvalidation_0-auc:0.97717\n",
      "[391]\tvalidation_0-auc:0.97717\n",
      "[392]\tvalidation_0-auc:0.97717\n",
      "[393]\tvalidation_0-auc:0.97717\n",
      "[394]\tvalidation_0-auc:0.97717\n",
      "[395]\tvalidation_0-auc:0.97717\n",
      "[396]\tvalidation_0-auc:0.97717\n",
      "[397]\tvalidation_0-auc:0.97717\n",
      "[398]\tvalidation_0-auc:0.97717\n",
      "[399]\tvalidation_0-auc:0.97717\n",
      "[400]\tvalidation_0-auc:0.97716\n",
      "[401]\tvalidation_0-auc:0.97717\n",
      "[402]\tvalidation_0-auc:0.97716\n",
      "[403]\tvalidation_0-auc:0.97717\n",
      "[404]\tvalidation_0-auc:0.97717\n",
      "[405]\tvalidation_0-auc:0.97717\n",
      "[406]\tvalidation_0-auc:0.97717\n",
      "[407]\tvalidation_0-auc:0.97717\n",
      "[408]\tvalidation_0-auc:0.97717\n",
      "[409]\tvalidation_0-auc:0.97718\n",
      "[410]\tvalidation_0-auc:0.97717\n",
      "[411]\tvalidation_0-auc:0.97717\n",
      "[412]\tvalidation_0-auc:0.97717\n",
      "[413]\tvalidation_0-auc:0.97718\n",
      "[414]\tvalidation_0-auc:0.97718\n",
      "[415]\tvalidation_0-auc:0.97718\n",
      "[416]\tvalidation_0-auc:0.97718\n",
      "[417]\tvalidation_0-auc:0.97718\n",
      "[418]\tvalidation_0-auc:0.97718\n",
      "[419]\tvalidation_0-auc:0.97718\n",
      "[420]\tvalidation_0-auc:0.97718\n",
      "[421]\tvalidation_0-auc:0.97718\n",
      "[422]\tvalidation_0-auc:0.97718\n",
      "[423]\tvalidation_0-auc:0.97718\n",
      "[424]\tvalidation_0-auc:0.97717\n",
      "[425]\tvalidation_0-auc:0.97717\n",
      "[426]\tvalidation_0-auc:0.97717\n",
      "[427]\tvalidation_0-auc:0.97717\n",
      "[428]\tvalidation_0-auc:0.97717\n",
      "[429]\tvalidation_0-auc:0.97717\n",
      "[430]\tvalidation_0-auc:0.97718\n",
      "[431]\tvalidation_0-auc:0.97718\n",
      "[432]\tvalidation_0-auc:0.97718\n",
      "[433]\tvalidation_0-auc:0.97718\n",
      "[434]\tvalidation_0-auc:0.97718\n",
      "[435]\tvalidation_0-auc:0.97718\n",
      "[436]\tvalidation_0-auc:0.97718\n",
      "[437]\tvalidation_0-auc:0.97718\n",
      "[438]\tvalidation_0-auc:0.97718\n",
      "[439]\tvalidation_0-auc:0.97718\n",
      "[440]\tvalidation_0-auc:0.97718\n",
      "[441]\tvalidation_0-auc:0.97718\n",
      "[442]\tvalidation_0-auc:0.97718\n",
      "[443]\tvalidation_0-auc:0.97718\n",
      "[444]\tvalidation_0-auc:0.97717\n",
      "[445]\tvalidation_0-auc:0.97717\n",
      "[446]\tvalidation_0-auc:0.97717\n",
      "[447]\tvalidation_0-auc:0.97717\n",
      "[448]\tvalidation_0-auc:0.97717\n",
      "[449]\tvalidation_0-auc:0.97717\n",
      "[450]\tvalidation_0-auc:0.97717\n",
      "[451]\tvalidation_0-auc:0.97717\n",
      "[452]\tvalidation_0-auc:0.97717\n",
      "[453]\tvalidation_0-auc:0.97717\n",
      "[454]\tvalidation_0-auc:0.97717\n",
      "[455]\tvalidation_0-auc:0.97716\n",
      "[456]\tvalidation_0-auc:0.97717\n",
      "[457]\tvalidation_0-auc:0.97717\n",
      "[458]\tvalidation_0-auc:0.97717\n",
      "[459]\tvalidation_0-auc:0.97717\n",
      "[460]\tvalidation_0-auc:0.97716\n",
      "[461]\tvalidation_0-auc:0.97716\n",
      "[462]\tvalidation_0-auc:0.97716\n",
      "[463]\tvalidation_0-auc:0.97716\n",
      "[464]\tvalidation_0-auc:0.97716\n",
      "[465]\tvalidation_0-auc:0.97716\n",
      "[466]\tvalidation_0-auc:0.97716\n",
      "[467]\tvalidation_0-auc:0.97716\n",
      "[468]\tvalidation_0-auc:0.97716\n",
      "[469]\tvalidation_0-auc:0.97716\n",
      "[470]\tvalidation_0-auc:0.97716\n",
      "[471]\tvalidation_0-auc:0.97716\n",
      "[472]\tvalidation_0-auc:0.97717\n",
      "[473]\tvalidation_0-auc:0.97717\n",
      "[474]\tvalidation_0-auc:0.97717\n",
      "[475]\tvalidation_0-auc:0.97717\n",
      "[476]\tvalidation_0-auc:0.97717\n",
      "[477]\tvalidation_0-auc:0.97717\n",
      "[478]\tvalidation_0-auc:0.97717\n",
      "[479]\tvalidation_0-auc:0.97717\n",
      "[480]\tvalidation_0-auc:0.97717\n",
      "[481]\tvalidation_0-auc:0.97717\n",
      "[482]\tvalidation_0-auc:0.97717\n",
      "[483]\tvalidation_0-auc:0.97717\n",
      "[484]\tvalidation_0-auc:0.97717\n",
      "[485]\tvalidation_0-auc:0.97717\n",
      "[486]\tvalidation_0-auc:0.97717\n",
      "[487]\tvalidation_0-auc:0.97716\n",
      "[488]\tvalidation_0-auc:0.97717\n",
      "[489]\tvalidation_0-auc:0.97717\n",
      "[490]\tvalidation_0-auc:0.97717\n",
      "[491]\tvalidation_0-auc:0.97716\n",
      "[492]\tvalidation_0-auc:0.97717\n",
      "[493]\tvalidation_0-auc:0.97717\n",
      "[494]\tvalidation_0-auc:0.97717\n",
      "[495]\tvalidation_0-auc:0.97717\n",
      "[496]\tvalidation_0-auc:0.97717\n",
      "[497]\tvalidation_0-auc:0.97717\n",
      "[498]\tvalidation_0-auc:0.97717\n",
      "[499]\tvalidation_0-auc:0.97716\n",
      "[500]\tvalidation_0-auc:0.97716\n",
      "[501]\tvalidation_0-auc:0.97716\n",
      "[502]\tvalidation_0-auc:0.97716\n",
      "[503]\tvalidation_0-auc:0.97716\n",
      "[504]\tvalidation_0-auc:0.97716\n",
      "[505]\tvalidation_0-auc:0.97715\n",
      "[506]\tvalidation_0-auc:0.97715\n",
      "[507]\tvalidation_0-auc:0.97715\n",
      "[508]\tvalidation_0-auc:0.97715\n",
      "[509]\tvalidation_0-auc:0.97715\n",
      "[510]\tvalidation_0-auc:0.97714\n",
      "[511]\tvalidation_0-auc:0.97714\n",
      "[512]\tvalidation_0-auc:0.97714\n",
      "[513]\tvalidation_0-auc:0.97714\n",
      "[514]\tvalidation_0-auc:0.97714\n",
      "[515]\tvalidation_0-auc:0.97713\n",
      "[516]\tvalidation_0-auc:0.97713\n",
      "[517]\tvalidation_0-auc:0.97713\n",
      "[518]\tvalidation_0-auc:0.97713\n",
      "[519]\tvalidation_0-auc:0.97713\n",
      "\n",
      "MAE: 0.054528430763091044\n",
      "RMSE: 0.23351323466367177\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84     23167\n",
      "           1       0.96      0.97      0.97    107132\n",
      "\n",
      "    accuracy                           0.95    130299\n",
      "   macro avg       0.91      0.90      0.91    130299\n",
      "weighted avg       0.94      0.95      0.94    130299\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 19090 times correctly   (86.31 %)\n",
      "False Negative : CHGOFF (0) was predicted 3028 times incorrectly     (13.69 %)\n",
      "True Positive : P I F (1) was predicted 104104 times correctly     (96.23 %)\n",
      "False Positive : P I F (1) was predicted 4077 times incorrectly     (3.77 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 94.55\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 84.31\n",
      "   P I F (1)  : 96.7\n",
      "RMSE: 0.23351323466367177\n",
      "CPU times: user 34 s, sys: 428 ms, total: 34.5 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv5():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model5 = process_model(X, y)\n",
    "    # model5.osample()     # we comment out the oversampling algorithm\n",
    "    model5.split_data(0.7)\n",
    "    \n",
    "    model5.X, model5.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    # we use the recently saved optuna study to get the hyperparams\n",
    "    study = joblib.load(f\"{workdir}xgb_optuna_study.pkl\")\n",
    "    hyperparams = study.best_trial.params\n",
    "    hyperparams['eval_metric'] = 'auc'      # we change eval_metric to 'auc'\n",
    "                   \n",
    "    model_xg = XGBClassifier(**hyperparams, use_label_encoder =False)\n",
    " \n",
    "    print(f'{color.bold}Fit() Iterations:{color.end}')\n",
    "    eval_set = [(model5.X_valid, model5.y_valid)]\n",
    "    model_xg.fit(model5.X_train, model5.y_train,\n",
    "              eval_set=eval_set, verbose=True)\n",
    " \n",
    "    # Get predictions\n",
    "    predictions = model_xg.predict(model5.X_valid)\n",
    "\n",
    "    print()\n",
    "    eval_results = model_eval(model5.y_valid, predictions)\n",
    "    \n",
    "RunModelv5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Result:</b><br>\n",
    "    As we can see from above, from the verbose results of the fit() method, <b>the training stopped at a certain iteration before it reached 1000</b>, since <b>the auc score was starting to decrease</b>.  In conclusion, the early_stopping_rounds parameter works.  Although it was set at 100, at 100th iteration, the <b>auc score was still increasing</b>, so it didn't stop yet.\n",
    "    <br><br>\n",
    "    If we oversampled the data, the fit() method will complete the entire n_estimators = 1000, as the score is still getting better even at 1000.  In conclusion, oversampling helped get better results without reaching the overfitting threshold yet at the selected n_estimator value.  It's not just blind oversampling of course, it was a technique to solve the imbalance of data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random_forest_classifier\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.2 Random Forest Classifier</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    This is just a reference on using a Random Forest Classifier.<br>\n",
    "    <b>cuml.ensemble RandomForestClassifier</b> is used if GPU is active; otherwise, Scikit-Learn's RandomForestClassifier.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:48:43.366291Z",
     "iopub.status.busy": "2022-05-17T08:48:43.365983Z",
     "iopub.status.idle": "2022-05-17T08:49:28.724217Z",
     "shell.execute_reply": "2022-05-17T08:49:28.723187Z",
     "shell.execute_reply.started": "2022-05-17T08:48:43.366246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n",
      "\n",
      "\u001b[1mPlease wait, Fitting model can take time ...\u001b[0m\n",
      "Fitting model completed.\n",
      "\n",
      "Preparing Predictions\n",
      "\u001b[4mMetrics : Random Forest Classifier\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mcuml Score : 88.67 %\u001b[0m\n",
      "\n",
      "MAE: 15.292993690027256\n",
      "RMSE: 0.33654441593532386\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89    107132\n",
      "           1       0.89      0.88      0.89    107132\n",
      "\n",
      "    accuracy                           0.89    214264\n",
      "   macro avg       0.89      0.89      0.89    214264\n",
      "weighted avg       0.89      0.89      0.89    214264\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 95669 times correctly   (88.2 %)\n",
      "False Negative : CHGOFF (0) was predicted 12805 times incorrectly     (11.8 %)\n",
      "True Positive : P I F (1) was predicted 94327 times correctly     (89.16 %)\n",
      "False Positive : P I F (1) was predicted 11463 times incorrectly     (10.84 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 88.67\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 88.74\n",
      "   P I F (1)  : 88.6\n",
      "RMSE: 0.33654441593532386\n",
      "\n",
      "CPU times: user 38.8 s, sys: 1.22 s, total: 40 s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run before tuning\n",
    "def RunModelrf():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    modelrf = other_models(X, y)\n",
    "    modelrf.osample()\n",
    "    modelrf.split_data(0.7)\n",
    "    \n",
    "    modelrf.X, modelrf.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    modelrf.prep_run_model(\"Metrics : Random Forest Classifier\", modelname='rfc')\n",
    "\n",
    "RunModelrf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Optuna Tuning for Random Forest</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "    This is just a simple sample implementation, for reference.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:49:28.726239Z",
     "iopub.status.busy": "2022-05-17T08:49:28.725951Z",
     "iopub.status.idle": "2022-05-17T08:51:30.728313Z",
     "shell.execute_reply": "2022-05-17T08:51:30.727216Z",
     "shell.execute_reply.started": "2022-05-17T08:49:28.726208Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mTrial 0 done with best value: \u001b[1m\u001b[92m0.920322597026825\u001b[1m\u001b[94m and parameters: \u001b[0m{'max_features': 0.8530100559045777, 'min_samples_split': 11, 'min_samples_leaf': 11, 'max_samples': 0.9708234557877973, 'max_depth': 13, 'n_estimators': 100}. \n",
      "\n",
      "Current Ram Used: 24.2 %\n",
      "\u001b[1m\u001b[92mTotal Elapsed Time from Training Start: \u001b[0mRuntime : 0:01:17.209984\n",
      "Running Trial 2\n",
      "\n",
      "Number of finished trials: 3\n",
      "Number of pruned trials: 0\n",
      "Number of completed trials: \u001b[1m\u001b[92m3\u001b[0m\n",
      "\u001b[1m\u001b[94mBest trial: {'max_features': 0.8530100559045777, 'min_samples_split': 11, 'min_samples_leaf': 11, 'max_samples': 0.9708234557877973, 'max_depth': 13, 'n_estimators': 100}\u001b[0m\n",
      "\n",
      "CPU times: user 1min 48s, sys: 1.23 s, total: 1min 50s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RandomForestOptunaTuning():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    rfo = optuna_tuning(X, y)\n",
    "    rfo.osample()  # oversample\n",
    "    rfo.split_data(0.7)\n",
    "    \n",
    "    rfo.X, rfo.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    print(f'{color.bold}Please wait, this will take time{color.end}')\n",
    "    \n",
    "    nn_trials = 3\n",
    "    \n",
    "    if os.path.exists(f'{workdir}rfc_optuna_study_log.txt'):\n",
    "        os.remove(f'{workdir}rfc_optuna_study_log.txt') \n",
    "    \n",
    "    # STUDY\n",
    "    \n",
    "    # Turn off optuna log notes, to use own logging notes\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "    \n",
    "    # Turn on optuna log notes\n",
    "    #optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "    print(f\"{color.bold}Please wait, finding best trial ...{color.end}\")\n",
    "            \n",
    "    gt = dt.datetime.now()\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    try:\n",
    "        # callbacks [self.save_study] is to save study in case memory fails\n",
    "        study.optimize(lambda trial: rfo.objective_rf(trial, gt), \n",
    "                        n_trials = nn_trials,\n",
    "                        callbacks = [rfo.logging_callback, rfo.save_study],\n",
    "                        gc_after_trial = True,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "    except MemoryError as e:\n",
    "        print(f'{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}')\n",
    "  \n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    print()\n",
    "    print(f'Number of finished trials: {len(study.trials)}')\n",
    "    print(f'Number of pruned trials: {len(pruned_trials)}')\n",
    "    print(f'Number of completed trials: {color.bdgreen}{len(complete_trials)}{color.end}')\n",
    "    print(f'{color.bdblue}Best trial: {study.best_trial.params}{color.end}')\n",
    "    \n",
    "    joblib.dump(study, f\"{workdir}rfc_optuna_study.pkl\")   # save study\n",
    "    # jl = joblib.load(f\"{workdir}rfc_optuna_study.pkl\")   # load study\n",
    "\n",
    "    print()\n",
    "    return study\n",
    "\n",
    "study_results = RandomForestOptunaTuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:51:30.730686Z",
     "iopub.status.busy": "2022-05-17T08:51:30.730146Z",
     "iopub.status.idle": "2022-05-17T08:51:30.747737Z",
     "shell.execute_reply": "2022-05-17T08:51:30.746717Z",
     "shell.execute_reply.started": "2022-05-17T08:51:30.730639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.8530100559045777,\n",
       " 'min_samples_split': 11,\n",
       " 'min_samples_leaf': 11,\n",
       " 'max_samples': 0.9708234557877973,\n",
       " 'max_depth': 13,\n",
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.920322597026825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.920322597026825], datetime_start=datetime.datetime(2022, 5, 17, 8, 49, 34, 760189), datetime_complete=datetime.datetime(2022, 5, 17, 8, 50, 16, 577960), params={'max_features': 0.8530100559045777, 'min_samples_split': 11, 'min_samples_leaf': 11, 'max_samples': 0.9708234557877973, 'max_depth': 13, 'n_estimators': 100}, distributions={'max_features': UniformDistribution(high=1.0, low=0.15), 'min_samples_split': IntUniformDistribution(high=14, low=2, step=1), 'min_samples_leaf': IntUniformDistribution(high=14, low=1, step=1), 'max_samples': UniformDistribution(high=0.99, low=0.6), 'max_depth': CategoricalDistribution(choices=(9, 11, 13)), 'n_estimators': CategoricalDistribution(choices=(100,))}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.920322597026825}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(study_results.best_params) # Get best parameters for the objective function.\n",
    "print()\n",
    "display(study_results.best_value)  # Get best objective value.\n",
    "print()\n",
    "display(study_results.best_trial)  # Get best trial's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:51:30.750371Z",
     "iopub.status.busy": "2022-05-17T08:51:30.749694Z",
     "iopub.status.idle": "2022-05-17T08:51:30.759270Z",
     "shell.execute_reply": "2022-05-17T08:51:30.757995Z",
     "shell.execute_reply.started": "2022-05-17T08:51:30.750321Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.8530100559045777,\n",
       " 'min_samples_split': 11,\n",
       " 'min_samples_leaf': 11,\n",
       " 'max_samples': 0.9708234557877973,\n",
       " 'max_depth': 13,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial = study_results.best_trial.params\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:51:30.761803Z",
     "iopub.status.busy": "2022-05-17T08:51:30.761468Z",
     "iopub.status.idle": "2022-05-17T08:51:30.787243Z",
     "shell.execute_reply": "2022-05-17T08:51:30.786095Z",
     "shell.execute_reply.started": "2022-05-17T08:51:30.761757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_max_features</th>\n",
       "      <th>params_max_samples</th>\n",
       "      <th>params_min_samples_leaf</th>\n",
       "      <th>params_min_samples_split</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.892525</td>\n",
       "      <td>2022-05-17 08:50:51.656660</td>\n",
       "      <td>2022-05-17 08:51:30.488305</td>\n",
       "      <td>0 days 00:00:38.831645</td>\n",
       "      <td>13</td>\n",
       "      <td>0.236539</td>\n",
       "      <td>0.818983</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.907567</td>\n",
       "      <td>2022-05-17 08:50:16.804992</td>\n",
       "      <td>2022-05-17 08:50:51.324161</td>\n",
       "      <td>0 days 00:00:34.519169</td>\n",
       "      <td>11</td>\n",
       "      <td>0.603695</td>\n",
       "      <td>0.659903</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     value             datetime_start          datetime_complete  \\\n",
       "2       2  0.892525 2022-05-17 08:50:51.656660 2022-05-17 08:51:30.488305   \n",
       "1       1  0.907567 2022-05-17 08:50:16.804992 2022-05-17 08:50:51.324161   \n",
       "\n",
       "                duration  params_max_depth  params_max_features  \\\n",
       "2 0 days 00:00:38.831645                13             0.236539   \n",
       "1 0 days 00:00:34.519169                11             0.603695   \n",
       "\n",
       "   params_max_samples  params_min_samples_leaf  params_min_samples_split  \\\n",
       "2            0.818983                       12                        10   \n",
       "1            0.659903                       10                         6   \n",
       "\n",
       "   params_n_estimators     state  \n",
       "2                  100  COMPLETE  \n",
       "1                  100  COMPLETE  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trial results dataframe sorted from best value ascending\n",
    "ViewResultsAsDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:51:30.789445Z",
     "iopub.status.busy": "2022-05-17T08:51:30.788961Z",
     "iopub.status.idle": "2022-05-17T08:51:31.063425Z",
     "shell.execute_reply": "2022-05-17T08:51:31.062464Z",
     "shell.execute_reply.started": "2022-05-17T08:51:30.789388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"a59daef3-d14e-4af9-84f3-f96c19fae2f4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a59daef3-d14e-4af9-84f3-f96c19fae2f4\")) {                    Plotly.newPlot(                        \"a59daef3-d14e-4af9-84f3-f96c19fae2f4\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"n_estimators (CategoricalDistribution): 0.0<extra></extra>\",\"max_depth (CategoricalDistribution): 0.12293595977522567<extra></extra>\",\"max_samples (UniformDistribution): 0.18938648787249418<extra></extra>\",\"min_samples_split (IntUniformDistribution): 0.20450759298175358<extra></extra>\",\"max_features (UniformDistribution): 0.2196035167772516<extra></extra>\",\"min_samples_leaf (IntUniformDistribution): 0.26356644259327494<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.0\",\"0.12293595977522567\",\"0.18938648787249418\",\"0.20450759298175358\",\"0.2196035167772516\",\"0.26356644259327494\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.0,0.12293595977522567,0.18938648787249418,0.20450759298175358,0.2196035167772516,0.26356644259327494],\"y\":[\"n_estimators\",\"max_depth\",\"max_samples\",\"min_samples_split\",\"max_features\",\"min_samples_leaf\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a59daef3-d14e-4af9-84f3-f96c19fae2f4');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize parameter importance\n",
    "optuna.visualization.plot_param_importances(study_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Random Forest Score With Optuna Hyperparameters</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:51:31.065926Z",
     "iopub.status.busy": "2022-05-17T08:51:31.064935Z",
     "iopub.status.idle": "2022-05-17T08:52:17.355500Z",
     "shell.execute_reply": "2022-05-17T08:52:17.350323Z",
     "shell.execute_reply.started": "2022-05-17T08:51:31.065864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n",
      "\n",
      "\u001b[1mPlease wait, Fitting model can take time ...\u001b[0m\n",
      "Fitting model completed.\n",
      "\n",
      "Preparing Predictions\n",
      "\u001b[4mMetrics : Random Forest Classifier\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92mcuml Score : 92.02 %\u001b[0m\n",
      "\n",
      "MAE: 11.739886308479258\n",
      "RMSE: 0.28242889895170714\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92    107132\n",
      "           1       0.93      0.91      0.92    107132\n",
      "\n",
      "    accuracy                           0.92    214264\n",
      "   macro avg       0.92      0.92      0.92    214264\n",
      "weighted avg       0.92      0.92      0.92    214264\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 99877 times correctly   (91.03 %)\n",
      "False Negative : CHGOFF (0) was predicted 9836 times incorrectly     (8.97 %)\n",
      "True Positive : P I F (1) was predicted 97296 times correctly     (93.06 %)\n",
      "False Positive : P I F (1) was predicted 7255 times incorrectly     (6.94 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 92.02\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 92.12\n",
      "   P I F (1)  : 91.93\n",
      "RMSE: 0.28242889895170714\n",
      "\n",
      "CPU times: user 42.6 s, sys: 637 ms, total: 43.3 s\n",
      "Wall time: 46.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelrf2():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    modelrf = other_models(X, y)\n",
    "    modelrf.osample()\n",
    "    modelrf.split_data(0.7)\n",
    "    \n",
    "    modelrf.X, modelrf.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    modelrf.prep_run_model(\"Metrics : Random Forest Classifier\",\n",
    "                            modelname='rfc', hparams = best_trial)\n",
    "\n",
    "RunModelrf2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Once again, Optuna helped us get parameters that improved the score.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:52:17.358100Z",
     "iopub.status.busy": "2022-05-17T08:52:17.357077Z",
     "iopub.status.idle": "2022-05-17T08:52:17.589890Z",
     "shell.execute_reply": "2022-05-17T08:52:17.588811Z",
     "shell.execute_reply.started": "2022-05-17T08:52:17.358044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del study_results, best_trial\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>RandomizedSearchCV</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Below is a reference on using a <b>RandomizedSearchCV</b> first for Random Forest hyperparameter tuning.<br><br>\n",
    "  Once done, one would have randomly narrowed down some parameters which we can base our inputs for a full <b>GridSearchCV</b> (not shown here).\n",
    "    <br><br>\n",
    "    Both approaches take an <b>extremely long time to run</b> using our SBA dataset, and the line to run the task is commented out.  Uncomment if you want to try.  Otherwise, <b>Optuna</b> is a much faster method.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:52:17.591691Z",
     "iopub.status.busy": "2022-05-17T08:52:17.591352Z",
     "iopub.status.idle": "2022-05-17T08:52:17.605388Z",
     "shell.execute_reply": "2022-05-17T08:52:17.604129Z",
     "shell.execute_reply.started": "2022-05-17T08:52:17.591642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters in use:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 48,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ViewDefaultRFCParams():\n",
    "    rf = RandomForestClassifier(random_state = 48)\n",
    "    # Look at parameters used by our current forest\n",
    "    print('Default parameters in use:\\n')\n",
    "    display(rf.get_params())\n",
    "\n",
    "ViewDefaultRFCParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:52:17.608166Z",
     "iopub.status.busy": "2022-05-17T08:52:17.607490Z",
     "iopub.status.idle": "2022-05-17T08:52:17.620610Z",
     "shell.execute_reply": "2022-05-17T08:52:17.619392Z",
     "shell.execute_reply.started": "2022-05-17T08:52:17.608119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [500, 1250, 2000],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [6, 9, 12, 15, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def SuggestRFCParams():\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 500, stop = 2000, num = 3)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(6, 15, num = 4)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    display(random_grid)\n",
    "    return random_grid\n",
    "\n",
    "random_grid = SuggestRFCParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:52:17.627751Z",
     "iopub.status.busy": "2022-05-17T08:52:17.627324Z",
     "iopub.status.idle": "2022-05-17T08:52:17.638540Z",
     "shell.execute_reply": "2022-05-17T08:52:17.637391Z",
     "shell.execute_reply.started": "2022-05-17T08:52:17.627695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RandomSearchCV(random_grid):\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    modelrf = other_models(X, y)\n",
    "    modelrf.osample()\n",
    "    modelrf.split_data(0.7)\n",
    "    \n",
    "    X_train, y_train = modelrf.X_train, modelrf.y_train\n",
    "    \n",
    "    del X, y, modelrf\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
    "                                   n_iter = 5, cv = 3, verbose=10, random_state=48)\n",
    "\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    return rf_random.best_params_\n",
    "\n",
    "#rf_best_params = RandomSearchCV(random_grid)\n",
    "#rf_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T08:52:17.640632Z",
     "iopub.status.busy": "2022-05-17T08:52:17.640266Z",
     "iopub.status.idle": "2022-05-17T08:52:17.881616Z",
     "shell.execute_reply": "2022-05-17T08:52:17.880572Z",
     "shell.execute_reply.started": "2022-05-17T08:52:17.640584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del random_grid #,rf_best_params \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T07:15:49.429758Z",
     "iopub.status.busy": "2022-05-17T07:15:49.429388Z",
     "iopub.status.idle": "2022-05-17T07:15:49.458798Z",
     "shell.execute_reply": "2022-05-17T07:15:49.457385Z",
     "shell.execute_reply.started": "2022-05-17T07:15:49.429667Z"
    }
   },
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
