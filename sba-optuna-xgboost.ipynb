{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;a:link{color: white}\">\n",
    "    <h1 style='color:GhostWhite;'>Part 2: Should This Loan be Approved or Denied ?</h1>\n",
    "    This is a continuation of notebook <a style=\"color:yellow\" href=\"https://www.kaggle.com/code/josephramon/sba-xgboost-model\">Part 1: Should This Loan Be Approved or Denied ?</a><br><br>\n",
    "    The topic covered here is :<br>\n",
    "    <p style=\"color:Gold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>XGBoost v1.6+ HyperParameter Tuning using Optuna - Full and Incremental</b></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">  \n",
    "    <b>Dataset Source</b><br><br>\n",
    "    <a href=\"https://www.kaggle.com/mirbektoktogaraev/should-this-loan-be-approved-or-denied\">U.S. Small Business Administration (SBA) Dataset</a>\n",
    "<br><br>\n",
    "    All information about the dataset can be found at the <b>above link</b><br><br>    \n",
    "    *<i>Thanks to Hamza for his <a href=\"https://www.kaggle.com/code/hamzaghanmi/xgboost-hyperparameter-tuning-using-optuna/notebook\">Notebook on Optuna</a> which was used as a guide.</i> \n",
    "<br><br>\n",
    "    If interested, Data Exploratory Visualization in Tableau can also be seen at :<br>\n",
    "    <a href= \"https://public.tableau.com/app/profile/joseph8038/viz/SBADatasetVisualizationandAnalysis/SBADatasetVisualizationandAnalysis-StoryBoard\">SBA Data Exploratory Visualization in Tableau</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"color:DarkSlateBlue\">\n",
    "This notebook is divided into 2 main parts:<br>\n",
    "<ul>\n",
    "<li><a style=\"color:DarkSlateGrey;\" href=\"#part1\"><b>Part 1: XGBoost HyperParameter Tuning using Optuna - Full and Incremental</b></a></li><br>\n",
    "<li><a style=\"color:DarkSlateGrey;\" href=\"#part2\"><b>Part 2: Miscellaneous</a></b>  - Early Stopping Rounds, Random Forest Classifier</li>\n",
    "</ul>\n",
    "<br>\n",
    "    <p style=\"color:FireBrick;\"><b>* Output from <a style=\"color:DarkGoldenRod;\" href = \"https://www.kaggle.com/code/josephramon/sba-xgboost-model\">Part 1 notebook</a> are Input to this notebook.</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table Of Contents</h2>\n",
    "<ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#paths_and_flags\">Paths and Flags</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#libraries\">Libraries</a></li>   \n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#functions\">Custom Functions And Classes</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#metrics\">Metrics Function</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#xgboost_class\">XGBoost Class</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#other_models\">Other Models Class</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_class\">Optuna Class - for both full datasets or incremental</a></li>\n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part1\">Part 1. XGBoost HyperParameter Tuning using Optuna</a></li>\n",
    "    <ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#full_df\">Optuna Study : Full Dataset</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#incremental_df\">Optuna Study : Incremental Dataset</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_metrics\">Optuna Study Metrics</a></li>    \n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#try_best_hp\">Model v4 : Try the Optuna Hyperparameters</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_comparison\">Optuna Tuning Comparison</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#cross_validation\">Cross Validation</a></li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part2\">Part 2. Miscellaneous</a></li>\n",
    "    <ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#early_stopping_rounds\">Early Stopping Rounds</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#random_forest_classifier\">Random Forest Classifier</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"paths_and_flags\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Paths and Flags</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:35.140717Z",
     "iopub.status.busy": "2022-03-26T06:49:35.140141Z",
     "iopub.status.idle": "2022-03-26T06:49:35.153238Z",
     "shell.execute_reply": "2022-03-26T06:49:35.152367Z",
     "shell.execute_reply.started": "2022-03-26T06:49:35.140613Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "'''\n",
    "kaggle_flag :\n",
    "   0 - if running outside Kaggle (e.g. Jupyter Notebook), change filepath & savepath to your \n",
    "       own path\n",
    "   1 - if running as a Kaggle notebook\n",
    "'''\n",
    "# Change this logic to your own if needed\n",
    "if os.path.exists('../usr/lib/myfuncs/myfuncs.py'):\n",
    "    kaggle_flag = 1\n",
    "    print('Running a Kaggle notebook')\n",
    "else:\n",
    "    kaggle_flag = 0\n",
    "    print('Not running a Kaggle notebook')\n",
    "\n",
    "# alert_flag - change to 0 for no sound alert, 1 for sound alert after long running cells\n",
    "alert_flag = 0\n",
    "\n",
    "'''\n",
    "We have two options for running Optuna tuning on XGBoost:  \n",
    "   OptunaStudy() - run Optuna on the full dataset\n",
    "   OptunaStudyChunk() - run in chunks, lighter on memory, but much slower\n",
    "\n",
    "Change flag below as needed:\n",
    "   1 to run OptunaStudy() only\n",
    "   2 to run OptunaStudyChunk() only\n",
    "   3 to run both\n",
    "'''\n",
    "optuna_flag = 1\n",
    "\n",
    "# GPU is automatically detected if activated\n",
    "\n",
    "#---------------------------------------------------------------------------------------#\n",
    "\n",
    "if kaggle_flag == 1:             # Kaggle\n",
    "    filepath  = \"../input/sba-xgboost-model/\"\n",
    "    savepath  = \"./\"\n",
    "    final_ds  = '../input/sba-xgboost-model/sba_final.csv.feather'  # imported from Part 1 Notebook\n",
    "    final_csv = '../input/sba-xgboost-model/sba_final.csv'          # imported from Part 1 Notebook\n",
    "    functions_path = \"../usr/lib/myfuncs/myfuncs.py\"\n",
    "else:\n",
    "    filepath  = \"C:\\\\Python\\\\Python_Data_Science_Exercises\\\\datasets\\\\\"\n",
    "    savepath  = \"C:\\\\Python\\\\Python_Data_Science_Exercises\\\\datasets\\\\\"\n",
    "    final_ds  = f'{savepath}sba_final.csv.feather'\n",
    "    final_csv = f'{savepath}sba_final.csv'\n",
    "    functions_path = 'C:\\\\Python\\\\Python_Data_Science_Exercises\\\\mylibs\\\\'\n",
    "\n",
    "audio_path=\"https://www.soundjay.com/misc/sounds/tablet-bottle-1.mp3\" # for alert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"libraries\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Libraries</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package installations completed\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output   # to be able to use clear_output(wait=True)\n",
    "def install_packages():\n",
    "    print('Please wait, package installations started, if needed')\n",
    "    libs = ['scikit-learn', 'seaborn', 'numpy','matplotlib', 'tensorflow','torch','joblib',\n",
    "            'psutil','imbalanced-learn','xgboost','optuna','pyarrow','pyttsx3',\n",
    "            'pympler','memory_profiler','line_profiler','sweetviz']\n",
    "    \n",
    "    piplist = !pip list\n",
    "    for i in range(len(libs)):\n",
    "        if not piplist.grep(libs[i]):\n",
    "            !pip3 install {libs[i]}\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print('Package installations completed')\n",
    "\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:37.352654Z",
     "iopub.status.busy": "2022-03-26T06:49:37.352409Z",
     "iopub.status.idle": "2022-03-26T06:49:39.053576Z",
     "shell.execute_reply": "2022-03-26T06:49:39.052631Z",
     "shell.execute_reply.started": "2022-03-26T06:49:37.352624Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpympler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclasstracker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassTracker\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\n\u001b[0;32m     31\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline_profiler\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory_profiler\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pyttsx3\n",
    "from IPython.display import Audio, display\n",
    "from IPython.display import FileLink\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import HTML\n",
    "import hashlib\n",
    "import copy                     # for deepcopy()\n",
    "import datetime as dt\n",
    "import optuna\n",
    "import gc\n",
    "import shutil\n",
    "import psutil\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "import torch                    # for clearing GPU cache\n",
    "from time import sleep\n",
    "import multiprocessing as mp\n",
    "from pympler import muppy       # for memory profiling\n",
    "from pympler import summary     # for memory profiling\n",
    "from pympler.classtracker import ClassTracker\n",
    "import xgboost\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "clear_output(wait=True)\n",
    "print('Package imports completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "XGBoost Package upgrade completed\n"
     ]
    }
   ],
   "source": [
    "# Kernel must be restarted if XGBoost is upgraded\n",
    "# importlib.reload and %autoreload do not work, so manually restart \n",
    "# This check is basically for Kaggle which has an older version of XGBoost, at least at this time\n",
    "if '1.6' not in xgboost.__version__:\n",
    "    !pip3 install --upgrade xgboost\n",
    "    clear_output(wait=True)\n",
    "    print('XGBoost Package upgrade completed.  KERNEL RESTART NEEDED FOR NOTEBOOK.')\n",
    "else:\n",
    "    print('XGBoost version is already 1.6+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost version should be 1.6+ and up\n",
    "assert '1.6' in xgboost.__version__,\\\n",
    "    \"XGBoost version must be 1.6+. RESTART KERNEL if already upgraded.\"\n",
    "\n",
    "print(f'XGBoost __Version__ : {xgboost.__version__}')\n",
    "print()\n",
    "!pip3 show xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure garbage collector is enabled\n",
    "(gc.isenabled() == False) and gc.enable();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"functions\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Custom Functions and Classes</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom functions import completed\n"
     ]
    }
   ],
   "source": [
    "# import custom functions\n",
    "# RESTART kernel if myfuncs is modified\n",
    "if functions_path not in sys.path:\n",
    "    sys.path.append(functions_path)\n",
    "from myfuncs import *\n",
    "\n",
    "print('Custom functions import completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Custom functions and classes in <a style=\"color:ForestGreen\" href=\"https://www.kaggle.com/code/josephramon/myfuncs\" target=\"_blank\">myfuncs.py</a></b>.<br>  \n",
    "In Kaggle, myfuncs.py is set up as a <b>Utility Script</b> in /usr/lib<br>\n",
    "<ul>\n",
    "    <li>is_kaggle_gpu_enabled()</li>\n",
    "<li>clear_gpu(tree_method='gpu_hist')</li>\n",
    "<li>reduce_mem_usage(df, print_info = True, use_float16=False)</li>\n",
    "<li>runtime(rt1,rt2)</li>\n",
    "<li>create_download_link(title = \"Download \", filename = \"data.csv\")</li>\n",
    "<li>GetRam()</li>\n",
    "<li>convertFloatToDecimal(f=0.0, precision=2)</li>\n",
    "<li>formatFileSize(size, sizeIn, sizeOut, precision=0)</li>\n",
    "<li>check_cols_with_nulls(df)</li>\n",
    "<li>check_infinity_nan(df, dfname)</li>\n",
    "<li>fixvals(val)</li>\n",
    "<li>model_eval(y_valid,predictions, cmDisplay='False')</li>\n",
    "<li>plot_features(booster, figsize)</li>\n",
    "<li>make_mi_scores(X, y)</li>\n",
    "<li>plot_mi_scores(scores)</li>\n",
    "<li>GetSweetVizReport(df, savepath, kaggle_flag)</li>\n",
    "<li>class color\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hist'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_enabled = is_kaggle_gpu_enabled()\n",
    "\n",
    "if gpu_enabled == False:\n",
    "    tree_method = 'hist'\n",
    "else:\n",
    "    tree_method = 'gpu_hist'\n",
    "\n",
    "del gpu_enabled\n",
    "gc.collect()\n",
    "\n",
    "sleep(5)\n",
    "clear_output(wait=True)\n",
    "tree_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.055357Z",
     "iopub.status.busy": "2022-03-26T06:49:39.055059Z",
     "iopub.status.idle": "2022-03-26T06:49:39.063894Z",
     "shell.execute_reply": "2022-03-26T06:49:39.062913Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.055318Z"
    }
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Set up voice object.  Used in different areas of notebook to indicate completion of long processes.\n",
    "'''\n",
    "if kaggle_flag == 0:   # not Kaggle\n",
    "    engine = pyttsx3.init()  # object creation\n",
    "\n",
    "    \"\"\" RATE\"\"\"\n",
    "    #rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "    #print (rate)                        #printing current voice rate\n",
    "    engine.setProperty('rate', 175)     # setting up new voice rate\n",
    "\n",
    "    \"\"\"VOLUME\"\"\"\n",
    "    #volume = engine.getProperty('volume')   #getting to know current volume level (min=0 and max=1)\n",
    "    #print (volume)                         #printing current volume level\n",
    "    engine.setProperty('volume',0.7)        # setting up volume level  between 0 and 1\n",
    "\n",
    "    \"\"\"VOICE\"\"\"\n",
    "    voices = engine.getProperty('voices')       #getting details of current voice\n",
    "    #engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "    engine.setProperty('voice', voices[1].id)   #changing index, changes voices. 1 for female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xgboost_class\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>XGBoost Class</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.211021Z",
     "iopub.status.busy": "2022-03-26T06:49:39.210498Z",
     "iopub.status.idle": "2022-03-26T06:49:39.264543Z",
     "shell.execute_reply": "2022-03-26T06:49:39.263710Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.210977Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "class process_model():  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_valid, self.X_test = None, None\n",
    "        self.y_valid, self.y_test = None, None\n",
    "\n",
    "        print(f'MIS_Status Count ->  1 : {Counter(y)[1]}, 0 : {Counter(y)[0]}')\n",
    "    \n",
    "    # oversampling method\n",
    "    def osample(self, print_info = True):\n",
    "        # define oversampling strategy\n",
    "        oversample = RandomOverSampler(sampling_strategy='minority') \n",
    "        if print_info == True:\n",
    "            print('X size : ', len(self.X))\n",
    "            print('y size : ', len(self.y))\n",
    "        # fit and apply the transform\n",
    "        X_over, y_over = oversample.fit_resample(self.X, self.y)\n",
    "\n",
    "        # summarize class distribution\n",
    "        if print_info == True:\n",
    "            print(f'Before Oversampling -> 1 : {Counter(self.y)[1]}, 0 : {Counter(self.y)[0]}')\n",
    "            print(f'After Oversampling  -> 1 : {Counter(y_over)[1]}, 0 : {Counter(y_over)[0]}')\n",
    "        \n",
    "        # update X and y with the oversampled results \n",
    "        self.X = X_over\n",
    "        self.y = y_over\n",
    "        \n",
    "        # return the oversampled results in case they are needed in another module\n",
    "        #return {'X_over':X_over, 'y_over':y_over}\n",
    "    \n",
    "    def split_data(self, X_size = 0.7):   \n",
    "        # Split Data into Train:Validate:Test\n",
    "        \n",
    "        # train_size=X_size\n",
    "        # In the first step, we will split the data in training and remaining dataset\n",
    "        self.X_train, X_rem, self.y_train, y_rem = train_test_split(self.X, self.y,\n",
    "                                                        train_size = X_size, random_state=48) \n",
    "\n",
    "        # Now since we want the valid and test size to be equal,\n",
    "        # we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "        # test_size = 0.5\n",
    "\n",
    "        self.X_valid, self.X_test, self.y_valid, self.y_test = train_test_split(X_rem,y_rem,\n",
    "                                                            test_size=0.5, random_state=48)\n",
    "        \n",
    "        return {'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                'X_test':self.X_test, 'y_test':self.y_test}\n",
    "    \n",
    "    # Method to run model \n",
    "    # desc - description of metrics report\n",
    "    def prep_run_model(self, desc='Metrics', cmDisplay=False, PipeLine_flag = False,\n",
    "                hyperparams = {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6,\n",
    "                               'tree_method':tree_method, 'early_stopping_rounds':100,\n",
    "                               'eval_metric':['logloss','error']}):\n",
    "        # from XGBoost 1.6, early_stopping_rounds and eval_metric are under parameters,\n",
    "        # and deprecated from fit() method.\n",
    "        # The default hyperparameters are conservative, to help avoid overfitting\n",
    "        \n",
    "        print()\n",
    "        print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")\n",
    "        \n",
    "        '''\n",
    "        XGBRegressor is for continuous target/outcome variables. These are often called \n",
    "        \"regression problems.\"\n",
    "\n",
    "        XGBClassifier is for categorical target/outcome variables. These are often called \n",
    "        \"classification problems.\"\n",
    "        \n",
    "        xg_model = XGBRegressor(n_estimators = self.mn_estimators,\n",
    "                                learning_rate = self.mlearning_rate,\n",
    "                                max_depth = self.mmax_depth,\n",
    "                                n_jobs=4)\n",
    "        \n",
    "        xg_model = XGBClassifier(n_estimators = self.mn_estimators,\n",
    "                                learning_rate = self.mlearning_rate,\n",
    "                                max_depth = self.mmax_depth,\n",
    "                                use_label_encoder =False,\n",
    "                                n_jobs=4)\n",
    "        '''\n",
    "        \n",
    "        if PipeLine_flag == True:\n",
    "            # hyperparams is a result of Optuna hyperparameter tuning (Part 3 of this notebook)\n",
    "            # the hyperparameters lean towards being conservative to help avoid overfitting\n",
    "            hyperparams = { 'tree_method': 'gpu_hist',\n",
    "                            'lambda': 0.023437933789759252,\n",
    "                            'alpha': 0.005813454622750776,\n",
    "                            'gamma': 0,\n",
    "                            'colsample_bytree': 0.9,\n",
    "                            'subsample': 1.0,\n",
    "                            'learning_rate': 0.05,\n",
    "                            'n_estimators': 1000,\n",
    "                            'max_depth': 13,\n",
    "                            'random_state': 48,\n",
    "                            'min_child_weight': 1,\n",
    "                            'early_stopping_rounds': 100.0,\n",
    "                            'eval_metric': 'error'\n",
    "                          }\n",
    "            \n",
    "        xg_model = XGBClassifier(**hyperparams,use_label_encoder =False)\n",
    "       \n",
    "        #eval_setparam = [(self.X_train, self.y_train), (self.X_valid, self.y_valid)]\n",
    "        eval_setparam = [(self.X_valid, self.y_valid)]\n",
    "        \n",
    "        xg_model.fit(self.X_train, self.y_train, \n",
    "                     eval_set = eval_setparam,\n",
    "                     verbose=False)\n",
    "        \n",
    "        gc.collect()\n",
    "        clear_gpu()\n",
    " \n",
    "        print(\"Fitting model completed.\")\n",
    "        print()\n",
    "        print('Preparing Predictions')\n",
    "    \n",
    "        # Get predictions\n",
    "        predictions = xg_model.predict(self.X_valid)\n",
    "    \n",
    "        print()\n",
    "        print(f'{color.underline}{desc}{color.end}')\n",
    "\n",
    "        eval_results = model_eval(self.y_valid, predictions, cmDisplay)\n",
    "            \n",
    "        # Return these values as they will be needed for further testing or metrics\n",
    "        # in dictionary form to remember easier \n",
    "        return {'xg_model':xg_model,'predictions':predictions,\n",
    "                    'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                    'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                    'X_test':self.X_test, 'y_test':self.y_test, 'eval_results':eval_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"other_models\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Other Models Class</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "if tree_method == 'gpu_hist':\n",
    "    import cuml\n",
    "    from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "\n",
    "# inherit from XGBoost class (process_model)\n",
    "class other_models(process_model):  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_valid, self.X_test = None, None\n",
    "        self.y_valid, self.y_test = None, None\n",
    "\n",
    "    #    print(f'MIS_Status Count ->  1 : {Counter(y)[1]}, 0 : {Counter(y)[0]}')\n",
    "    \n",
    "    # Method to run model \n",
    "    # desc - description of metrics report\n",
    "    def prep_run_model(self, desc='Metrics', modelname = 'rfc',\n",
    "                       hparams = {'n_estimators':100, 'random_state':48, 'max_depth':10},\n",
    "                       cmDisplay=False):\n",
    "        print()\n",
    "        print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")  \n",
    "\n",
    "        if modelname == 'rfc':\n",
    "            if tree_method == 'gpu_hist':\n",
    "                hparams.update({'max_features':1.0,\n",
    "                                'n_bins':8})\n",
    "                model = cuRF(**hparams)\n",
    "            else:\n",
    "                hparams.update({'max_features':1.0,\n",
    "                                'n_bins':8})\n",
    "                model = RandomForestClassifier(**hparams) \n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            \n",
    "        print(\"Fitting model completed.\")\n",
    "        print()\n",
    "        print('Preparing Predictions')\n",
    "    \n",
    "        # Get predictions\n",
    "        predictions = model.predict(self.X_valid)\n",
    "        print(f'{color.underline}{desc}{color.end}')\n",
    "    \n",
    "        if modelname == 'rfc':\n",
    "            if tree_method == 'gpu_hist':\n",
    "                print()\n",
    "                cu_score = cuml.metrics.accuracy_score( self.y_valid, predictions )\n",
    "                print(f'{color.bdgreen}cuml Score : {round(cu_score * 100,2)} %{color.end}')\n",
    "                print()\n",
    "            \n",
    "        eval_results = model_eval(self.y_valid, predictions, cmDisplay)\n",
    "        print()\n",
    "        print\n",
    "        \n",
    "        gc.collect()\n",
    "        clear_gpu()\n",
    "        \n",
    "        # Return these values as they will be needed for further testing or metrics\n",
    "        # in dictionary form to remember easier \n",
    "        return {'model':model,'predictions':predictions,\n",
    "                    'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                    'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                    'X_test':self.X_test, 'y_test':self.y_test, 'eval_results':eval_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_class\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Optuna Class</b><br>\n",
    "This is for both full dataset or incremental dataset trials.  There are two objective functions here,objective() and objective_batch()</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.268170Z",
     "iopub.status.busy": "2022-03-26T06:49:39.267940Z",
     "iopub.status.idle": "2022-03-26T06:49:39.284793Z",
     "shell.execute_reply": "2022-03-26T06:49:39.283935Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.268144Z"
    }
   },
   "outputs": [],
   "source": [
    "class optuna_tuning(process_model):  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_valid, self.X_test = None, None\n",
    "        self.y_valid, self.y_test = None, None\n",
    "    \n",
    "    # for printing only the best values, saves memory too\n",
    "    def logging_callback(self, study, frozen_trial):\n",
    "        previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "        if previous_best_value != study.best_value:\n",
    "            study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "            clear_output(wait=True)\n",
    "            self.text_out=\"{}Trial {} done with best value: {}{}{} and parameters: {}{}. \".format(\n",
    "                color.bdblue,\n",
    "                frozen_trial.number,\n",
    "                color.bdgreen,\n",
    "                frozen_trial.value,\n",
    "                color.bdblue,\n",
    "                color.end,\n",
    "                frozen_trial.params\n",
    "                )\n",
    "            print(self.text_out)\n",
    "            \n",
    "            # Writing to file\n",
    "            with open(f\"{savepath}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "                os_log.write('\\n\\n')\n",
    "                os_log.write(f\"Current Ram Used: {GetRam()} %\\n\")\n",
    "                os_log.write(self.text_out)\n",
    "    \n",
    "    # save study\n",
    "    def save_study(self, study, frozen_trial):\n",
    "        joblib.dump(study, f\"{savepath}xgb_optuna_study_callbacks.pkl\")   # save study\n",
    "        #print(f'{color.bdblue}Current study saved for Trial {frozen_trial.number}{color.end}')\n",
    "    \n",
    "    # for tuning full dataset\n",
    "    def objective(self, trial, gt, n_estimators = 1000):        \n",
    "        nn_early_stopping_rounds = n_estimators * 0.1\n",
    "        # the hyperparameters lean towards being conservative to help avoid overfitting\n",
    "        param = {\n",
    "            # tree_method would ideally be gpu_hist for faster speed\n",
    "            'tree_method':trial.suggest_categorical('tree_method', [tree_method]), \n",
    "            # L2 regularization weight, Increasing this value will make model more conservative\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            # L1 regularization weight, Increasing this value will make model more conservative\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            # Min loss reduction for further partition on a leaf node. larger,the more conservative\n",
    "            'gamma':trial.suggest_categorical('gamma', [0,3,6]),\n",
    "            # sampling according to each tree\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree',\n",
    "                            [0.6,0.7,0.8,0.9,1.0]),\n",
    "            #                [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "            # sampling ratio for training data\n",
    "            #'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "            'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,0.9,1.0]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate',\n",
    "                            [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02,0.05]),\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators',[n_estimators]),\n",
    "            # maximum depth of the tree, signifies complexity of the tree\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [9,11,13]),\n",
    "            'random_state': trial.suggest_categorical('random_state', [48]),\n",
    "            # minimum child weight, larger the term more conservative the tree\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'early_stopping_rounds': trial.suggest_categorical('early_stopping_rounds',\n",
    "                                          [nn_early_stopping_rounds]),                     \n",
    "            'eval_metric': trial.suggest_categorical('eval_metric', [['logloss','error']])\n",
    "        }\n",
    "        if GetRam() >= 90:\n",
    "            raise MemoryError('Short On Memory')\n",
    "            \n",
    "        # clear outputs, reprint saved data\n",
    "        if trial.number > 0:\n",
    "            clear_output(wait=True)\n",
    "            gc.collect()\n",
    "            print(self.text_out)\n",
    "            \n",
    "        # print(param)  # for debugging, comment out if desired\n",
    "        model_xgbc = XGBClassifier(**param, use_label_encoder =False)  \n",
    "    \n",
    "        print()\n",
    "        print(f\"Current Ram Used: {GetRam()} %\")\n",
    "        rt2=dt.datetime.now()\n",
    "        print(f'{color.bdgreen}Total Elapsed Time from Training Start: {color.end}', end='')\n",
    "        runtime(gt, rt2)  \n",
    "        print(f'Running Trial {trial.number}')\n",
    "            \n",
    "        model_xgbc.fit(self.X_train, self.y_train, eval_set=[(self.X_valid, self.y_valid)],\n",
    "                    verbose=False)\n",
    "\n",
    "        preds = model_xgbc.predict(self.X_valid)\n",
    "    \n",
    "        rmse = metrics.mean_squared_error(self.y_valid, preds,squared=False)\n",
    " \n",
    "        trial.report(rmse, 1)\n",
    "            \n",
    "        if trial.should_prune():\n",
    "            text_prune = f'{color.bold}Trial {trial.number} pruned{color.end}'\n",
    "            # Writing to file\n",
    "            with open(f\"{savepath}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "                os_log.write('\\n')\n",
    "                os_log.write(text_prune)\n",
    "            del model_xgbc, preds, text_prune\n",
    "            gc.collect()\n",
    "            sleep(3)\n",
    "            clear_gpu()\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        text_dtl = \"Trial {} finished with parameters: {}. \".format(\n",
    "            trial.number,\n",
    "            trial.params\n",
    "            )\n",
    "        # Writing to file\n",
    "        with open(f\"{savepath}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "            os_log.write('\\n\\n')\n",
    "            os_log.write(f\"Current Ram Used: {GetRam()} %\\n\")\n",
    "            os_log.write(text_dtl)\n",
    "            \n",
    "        rt2=dt.datetime.now()\n",
    "\n",
    "        del model_xgbc, preds, text_dtl\n",
    "        gc.collect()\n",
    "        sleep(3)       \n",
    "        clear_gpu()        \n",
    "\n",
    "        return rmse\n",
    " \n",
    "\n",
    "    # for tuning incrementally in chunks\n",
    "    def objective_chunk(self, trial, n_trials, gt,\n",
    "                        n_chunksize = 200000, n_estimators = 1000):\n",
    "        nn_early_stopping_rounds = n_estimators * 0.1\n",
    "        \n",
    "        # the hyperparameters lean towards being conservative to help avoid overfitting\n",
    "        param = {\n",
    "            # tree_method would ideally be gpu_hist for faster speed\n",
    "            'tree_method':trial.suggest_categorical('tree_method', [tree_method]), \n",
    "            # L2 regularization weight, Increasing this value will make model more conservative\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            # L1 regularization weight, Increasing this value will make model more conservative\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            # Min loss reduction for further partition on a leaf node. larger,the more conservative\n",
    "            'gamma':trial.suggest_categorical('gamma', [0,3,6]),\n",
    "            # sampling according to each tree\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree',\n",
    "                                [0.6,0.7,0.8,0.9,1.0]),\n",
    "            #                [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "            # sampling ratio for training data\n",
    "            #'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "            'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,0.9,1.0]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate',\n",
    "                            [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02,0.05]),\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators',[n_estimators]),\n",
    "            # maximum depth of the tree, signifies complexity of the tree\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [9,11,13]),\n",
    "            'random_state': trial.suggest_categorical('random_state', [48]),\n",
    "            # minimum child weight, larger the term more conservative the tree\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'early_stopping_rounds': trial.suggest_categorical('early_stopping_rounds',\n",
    "                                          [nn_early_stopping_rounds]),                     \n",
    "            'eval_metric': trial.suggest_categorical('eval_metric', [['logloss','error']])\n",
    "        }\n",
    "        if GetRam() >= 90:\n",
    "            raise MemoryError('Short On Memory')\n",
    "        \n",
    "        model_xgbc = XGBClassifier(**param,use_label_encoder =False)  \n",
    "    \n",
    "        rt1=dt.datetime.now()\n",
    "               \n",
    "        # clear outputs, reprint saved data\n",
    "        if trial.number > 0:\n",
    "            clear_output(wait=True)\n",
    "            gc.collect()\n",
    "            print(self.text_out)\n",
    "            \n",
    "            if os.path.exists(f'{savepath}model_xgbc.json'):\n",
    "                file_size = os.path.getsize(f'{savepath}model_xgbc.json')\n",
    "                file_size = formatFileSize(file_size,'B','MB',2)\n",
    "                print(f\"Current Model File Size : {file_size}MB\")\n",
    "\n",
    "        '''\n",
    "        For batch, use xgb_model parameter in fit().  There are two ways :\n",
    "           1. save the model to a file, after 1st trial, then give the name to the next trials\n",
    "           2. just give the name of the model object, in this case model_xgbc\n",
    "        '''\n",
    "    \n",
    "        #X_valid_list, y_valid_list = [],[]\n",
    "        # Fit Model\n",
    "        for i, self.X in enumerate(pd.read_csv(final_csv, chunksize = n_chunksize), start = 1):\n",
    "            self.X = reduce_mem_usage(self.X, print_info=False)\n",
    "            self.y = self.X.pop('MIS_Status')\n",
    "\n",
    "            self.osample(print_info = False)\n",
    "            self.split_data(0.7)\n",
    "            \n",
    "            #X_valid_list.append(self.X_valid.copy())\n",
    "            #y_valid_list.append(self.y_valid.copy())\n",
    "            \n",
    "            #X_valid = pd.concat(X_valid_list)\n",
    "            #y_valid = pd.concat(y_valid_list)\n",
    "            X_valid = self.X_valid\n",
    "            y_valid = self.y_valid\n",
    "        \n",
    "            self.X, self.y = None, None\n",
    "            self.X_valid, self.y_valid = None, None\n",
    "            self.X_test, self.y_test = None, None\n",
    "\n",
    "            if i == 1:            \n",
    "                print()\n",
    "                print(f\"Current Ram Used: {GetRam()} %\")\n",
    "                rt2=dt.datetime.now()\n",
    "                print(f'{color.bdgreen}Total Elapsed Time from Training Start: {color.end}', end='')\n",
    "                runtime(gt, rt2)  \n",
    "                print(f'Running Trial {trial.number} Chunk: {i}',end = ' | ')\n",
    "                model_xgbc.fit(self.X_train, self.y_train, eval_set=[(X_valid, y_valid)],\n",
    "                        verbose=False)\n",
    "            else:\n",
    "                print(f'{i}',end = ' | ')\n",
    "                model_xgbc = XGBClassifier(use_label_encoder =False)\n",
    "                model_xgbc.load_model(f'{savepath}model_xgbc.json')\n",
    "                \n",
    "                #if i == 2:\n",
    "                #    param.pop('tree_method')\n",
    "                #    param.update({'updater':'refresh',\n",
    "                #                'process_type': 'update',\n",
    "                #                'refresh_leaf': True})\n",
    "                #    model_xgbc.set_params(**param)\n",
    "                \n",
    "                model_xgbc.fit(self.X_train, self.y_train, eval_set=[(X_valid, y_valid)],\n",
    "                        verbose=False, xgb_model = model_xgbc\n",
    "                        # uncomment below if you want to use a saved file\n",
    "                        #xgb_model = f'{savepath}model_xgbc.json'\n",
    "                        )\n",
    "\n",
    "            '''Auxiliary attributes of the Python Booster object (such as feature_names) will \n",
    "            not be saved when using binary format. To save those attributes, use JSON instead.'''\n",
    "            # uncomment below if using a saved file\n",
    "            #model_xgbc.get_booster().save_model(f'{savepath}model_xgbc.json')\n",
    "            model_xgbc.save_model(f'{savepath}model_xgbc.json')\n",
    "        \n",
    "            #X_valid = pd.concat(X_valid_list)\n",
    "            #y_valid = pd.concat(y_valid_list)\n",
    "        \n",
    "            preds = model_xgbc.predict(X_valid)\n",
    "    \n",
    "            rmse = metrics.mean_squared_error(y_valid, preds,squared=False)\n",
    "        \n",
    "            del model_xgbc\n",
    "            self.X_train, self.y_train = None, None\n",
    "            gc.collect()\n",
    "            sleep(5)\n",
    "            clear_gpu()\n",
    "            \n",
    "            trial.report(rmse, i)\n",
    "            \n",
    "            if trial.should_prune():\n",
    "                # Writing to file\n",
    "                with open(f\"{savepath}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "                    os_log.write('\\n')\n",
    "                    os_log.write(f'{color.bold}Trial {trial.number} pruned{color.end}')\n",
    "                    os_log.write('\\n')\n",
    "                raise optuna.TrialPruned()\n",
    "        \n",
    "        if os.path.exists(f'{savepath}model_xgbc.json'):\n",
    "            file_size = os.path.getsize(f'{savepath}model_xgbc.json')\n",
    "            file_size = formatFileSize(file_size,'B','MB',2)\n",
    "            print(f\"Current Model File Size : {file_size}MB\")\n",
    "                \n",
    "        # Writing to file\n",
    "        with open(f\"{savepath}xgb_optuna_study_log.txt\", \"a\") as os_log:\n",
    "            os_log.write('\\n\\n')\n",
    "            os_log.write(f\"Current Ram Used: {GetRam()} %\")\n",
    "            if os.path.exists(f'{savepath}model_xgbc.json'):\n",
    "                os_log.write(f\" | Current Model File Size : {file_size}MB\\n\")\n",
    "            os_log.write(f\"Trial {trial.number} finished with parameters: {trial.params}.\")\n",
    "            \n",
    "        rt2=dt.datetime.now()\n",
    "\n",
    "        self.X_train, self.y_train = None, None\n",
    "        gc.collect()\n",
    "        sleep(5)\n",
    "        clear_gpu()\n",
    "            \n",
    "        return rmse\n",
    "\n",
    "    # Define an objective function for Random Forest\n",
    "    def objective_rf(self, trial, gt):\n",
    "        hparams = {\n",
    "            'max_features': trial.suggest_uniform('max_features', 0.15, 1.0),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "            'max_samples': trial.suggest_uniform('max_samples', 0.6, 0.99),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [5,10,15]),\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators', [100,250,500])\n",
    "            # warm_start = True   # for incremental learning  \n",
    "        }\n",
    " \n",
    "        # clear outputs, reprint saved data\n",
    "        if trial.number > 0:\n",
    "            clear_output(wait=True)\n",
    "            gc.collect()\n",
    "            print(self.text_out)\n",
    "            \n",
    "        if GetRam() >= 90:\n",
    "            raise MemoryError('Short On Memory')\n",
    "            \n",
    "        if tree_method == \"gpu_hist\":\n",
    "            model_rf = cuRF(**hparams)\n",
    "        else:\n",
    "            model_rf = RandomForestClassifier(**hparams)\n",
    "        print()\n",
    "        print(f\"Current Ram Used: {GetRam()} %\")\n",
    "        rt2=dt.datetime.now()\n",
    "        print(f'{color.bdgreen}Total Elapsed Time from Training Start: {color.end}', end='')\n",
    "        runtime(gt, rt2)  \n",
    "        print(f'Running Trial {trial.number}')\n",
    "\n",
    "        ## Fit Model\n",
    "        model_rf.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # Report intermediate objective value\n",
    "        intermediate_value = model_rf.score(self.X_valid, self.y_valid)\n",
    "        trial.report(intermediate_value, 0)\n",
    "            \n",
    "        if trial.should_prune():\n",
    "            text_prune = f'{color.bold}Trial {trial.number} pruned{color.end}'\n",
    "            # Writing to file\n",
    "            with open(f\"{savepath}rfc_optuna_study_log.txt\", \"a\") as os_log:\n",
    "                os_log.write('\\n')\n",
    "                os_log.write(text_prune)\n",
    "            del model_rf, text_prune\n",
    "            gc.collect()\n",
    "            sleep(3)\n",
    "            clear_gpu()\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        text_dtl = \"Trial {} finished with parameters: {}. \".format(\n",
    "            trial.number,\n",
    "            trial.params\n",
    "            )\n",
    "        # Writing to file\n",
    "        with open(f\"{savepath}rfc_optuna_study_log.txt\", \"a\") as os_log:\n",
    "            os_log.write('\\n\\n')\n",
    "            os_log.write(f\"Current Ram Used: {GetRam()} %\\n\")\n",
    "            os_log.write(text_dtl)\n",
    "            \n",
    "        rt2=dt.datetime.now()\n",
    "\n",
    "        del model_rf, text_dtl\n",
    "        gc.collect()\n",
    "        sleep(3)       \n",
    "        clear_gpu()        \n",
    "\n",
    "        return intermediate_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 style='color:GhostWhite;'>Part 1. XGBoost HyperParameter Tuning using Optuna</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"full_df\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.1 Optuna Study - Full Dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mTrial 1 done with best value: \u001b[1m\u001b[92m0.2221388462822118\u001b[1m\u001b[94m and parameters: \u001b[0m{'tree_method': 'hist', 'lambda': 0.004590141566739722, 'alpha': 0.007317728322388094, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.014, 'n_estimators': 1000, 'max_depth': 13, 'random_state': 48, 'min_child_weight': 4, 'early_stopping_rounds': 100.0, 'eval_metric': ['error', 'logloss']}. \n",
      "\n",
      "Current Ram Used: 65.3 %\n",
      "\u001b[1m\u001b[92mTotal Elapsed Time from Training Start: \u001b[0mRuntime : 0:34:46.310128\n",
      "Running Trial 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:62\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32m<timed exec>:43\u001b[0m, in \u001b[0;36mOptunaStudy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis feature will be removed in v4.0.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 400\u001b[0m \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    210\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32m<timed exec>:43\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36moptuna_tuning.objective\u001b[1;34m(self, trial, gt, n_estimators)\u001b[0m\n\u001b[0;32m     85\u001b[0m runtime(gt, rt2)  \n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 88\u001b[0m \u001b[43mmodel_xgbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m preds \u001b[38;5;241m=\u001b[39m model_xgbc\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_valid)\n\u001b[0;32m     93\u001b[0m rmse \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mmean_squared_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_valid, preds,squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    531\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1383\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1384\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1397\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1398\u001b[0m )\n\u001b[1;32m-> 1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:532\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    531\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:1733\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1733\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1737\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "        \n",
    "# For running Optuna tuning on full dataset.\n",
    "def OptunaStudy():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    # instantiate the optuna_tuning class\n",
    "    ot = optuna_tuning(X, y)\n",
    "    ot.osample()\n",
    "    ot.split_data(0.7)\n",
    "    \n",
    "    ot.X, ot.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    ''' \n",
    "    - Initialize the number of trials and n_estimators.\n",
    "    - Rather than run at a very high n_trials like 100 and above, I prefer to run this function, \n",
    "         with an n_trials like 50, three times to get the best_trial values \n",
    "    - Recommended n_estimators is 100 for really huge datasets, 1000 for medium-sized.\n",
    "    - For our dataset here, 1000 is fine.  Ramping it up to 4000 for example will have no\n",
    "         significant benefits, will be very slow, and a Kaggle notebook will run out of memory often.\n",
    "    '''\n",
    "    \n",
    "    nn_trials = 50\n",
    "    nn_estimators = 1000\n",
    "    \n",
    "    if os.path.exists(f'{savepath}xgb_optuna_study_log.txt'):\n",
    "        os.remove(f'{savepath}xgb_optuna_study_log.txt')\n",
    "\n",
    "    # STUDY\n",
    "    \n",
    "    # Turn off optuna log notes, to use own logging notes\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "\n",
    "    print(f\"{color.bold}Please wait, finding best trial ...{color.end}\")\n",
    "            \n",
    "    gt = dt.datetime.now()\n",
    "        \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    try:\n",
    "        # callbacks [self.save_study] is to save study in case memory fails\n",
    "        study.optimize(lambda trial: ot.objective(trial, gt, n_estimators = nn_estimators), \n",
    "                        n_trials = nn_trials,\n",
    "                        callbacks = [ot.logging_callback, ot.save_study],\n",
    "                        gc_after_trial = True,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "    except MemoryError as e:\n",
    "        print(f'{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}')\n",
    "    \n",
    "    print()\n",
    "    print(f'Number of finished trials: {len(study.trials)}')\n",
    "    print(f'Number of pruned trials: {len(pruned_trials)}')\n",
    "    print(f'Number of completed trials: {color.bdgreen}{len(complete_trials)}{color.end}')\n",
    "    print(f'{color.bdblue}Best trial: {study.best_trial.params}{color.end}')\n",
    "    \n",
    "    joblib.dump(study, f\"{savepath}xgb_optuna_study.pkl\")   # save study\n",
    "    # jl = joblib.load(f\"{savepath}xgb_optuna_study.pkl\")   # load study\n",
    "\n",
    "    print()\n",
    "    return study\n",
    "\n",
    "if optuna_flag == 1 or optuna_flag == 3:\n",
    "    study_results = OptunaStudy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"incremental_df\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.2 Optuna Study - Incremental Dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:56.335865Z",
     "iopub.status.busy": "2022-03-26T07:06:56.335510Z",
     "iopub.status.idle": "2022-03-26T08:03:41.820703Z",
     "shell.execute_reply": "2022-03-26T08:03:41.819946Z",
     "shell.execute_reply.started": "2022-03-26T07:06:56.335827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For running Optuna tuning incrementally in batches, much slower, but lighter on memory\n",
    "def OptunaStudyChunk(): \n",
    "    ''' \n",
    "    - Initialize the number of trials and n_estimators.\n",
    "    - Rather than run at a very high n_trials like 100 and above, I prefer to run this function, \n",
    "         with an n_trials like 50 or 70, three times to get the best_trial values \n",
    "    - Recommended n_estimators is 100 for really huge datasets, 1000 for medium-sized.\n",
    "    - For our dataset here, 1000 is fine.  Ramping it up to 4000 for example will have no\n",
    "         significant benefits, will be very slow, and a Kaggle notebook will run out of memory often.\n",
    "    '''\n",
    "\n",
    "    nn_trials = 3               # n_trials\n",
    "    nn_chunksize = 200000\n",
    "    nn_estimators = 1000\n",
    "    \n",
    "    if os.path.exists(f'{savepath}xgb_optuna_study_log.txt'):\n",
    "        os.remove(f'{savepath}xgb_optuna_study_log.txt')\n",
    "\n",
    "    # get full X_valid, y_valid \n",
    "    '''\n",
    "    print(f\"{color.bold}Please wait, getting Validation Data{color.end}\")  \n",
    "    X_valid_list, y_valid_list = [],[]\n",
    "    for i, X in enumerate(pd.read_csv(final_csv, chunksize = nn_chunksize), start = 1):\n",
    "        X = reduce_mem_usage(X, print_info=False)\n",
    "        y = X.pop('MIS_Status')\n",
    "\n",
    "        oso = optuna_tuning(X,y) \n",
    "        oso.osample(print_info = False)\n",
    "        oso.split_data(0.7)\n",
    "            \n",
    "        X_valid_list.append(oso.X_valid.copy())\n",
    "        y_valid_list.append(oso.y_valid.copy())\n",
    "            \n",
    "    X_valid = pd.concat(X_valid_list)\n",
    "    y_valid = pd.concat(y_valid_list)\n",
    "        \n",
    "    del X_valid_list, y_valid_list, oso\n",
    "    gc.collect() \n",
    "    sleep(3)\n",
    "    '''\n",
    "        \n",
    "    # OPTUNA STUDY\n",
    "    \n",
    "    # Turn off optuna log notes, to use own logging notes\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f\"{color.bold}Please wait, finding best trial ...{color.end}\")\n",
    "            \n",
    "    gt = dt.datetime.now()\n",
    "\n",
    "    otb = optuna_tuning(None, None)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    try:\n",
    "        # callbacks [self.save_study] is to save study in case memory fails\n",
    "        '''\n",
    "        study.optimize(lambda trial: otb.objective_chunk(trial, nn_trials, gt, X_valid, y_valid,\n",
    "                                  n_chunksize = nn_chunksize, n_estimators = nn_estimators), \n",
    "                        n_trials = nn_trials,\n",
    "                        callbacks = [otb.logging_callback, otb.save_study],\n",
    "                        gc_after_trial = True,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "        '''\n",
    "        study.optimize(lambda trial: otb.objective_chunk(trial, nn_trials, gt,\n",
    "                                  n_chunksize = nn_chunksize, n_estimators = nn_estimators), \n",
    "                        n_trials = nn_trials,\n",
    "                        callbacks = [otb.logging_callback, otb.save_study],\n",
    "                        gc_after_trial = True,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "    except MemoryError as e:\n",
    "        print(f'\\n\\n{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}\\n\\n')\n",
    "            \n",
    "    print()\n",
    "    print(f'Number of finished trials: {len(study.trials)}')\n",
    "    print(f'Number of pruned trials: {len(pruned_trials)}')\n",
    "    print(f'Number of completed trials: {color.bdgreen}{len(complete_trials)}{color.end}')\n",
    "    print(f'{color.bdblue}Best trial: {study.best_trial.params}{color.end}')\n",
    "    \n",
    "    joblib.dump(study, f\"{savepath}xgb_optuna_study.pkl\")   # save study\n",
    "    # jl = joblib.load(f\"{savepath}xgb_optuna_study.pkl\")   # load study\n",
    "\n",
    "    print()\n",
    "    return study\n",
    "\n",
    "if optuna_flag == 2 or optuna_flag == 3:\n",
    "    study_results = OptunaStudyChunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_metrics\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.3 Optuna Study Metrics</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below if you want to see the trials log \n",
    "with open(f\"{savepath}xgb_optuna_study_log.txt\", \"r+\") as os_log:\n",
    "    print(os_log.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below if you want to load saved study to check, if desired\n",
    "jl = joblib.load(f\"{savepath}xgb_optuna_study.pkl\")\n",
    "jl = jl.best_trial.params\n",
    "pprint(jl)\n",
    "# jl.update({'n_estimators': 4000, 'tree_method':tree_method})\n",
    "'''\n",
    "best_trial_sorted = {}\n",
    "for i in sorted (jl) :\n",
    "    best_trial_sorted.update({i:jl[i]})                          \n",
    "\n",
    "pprint(best_trial_sorted)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_results = joblib.load(f\"{savepath}xgb_optuna_study.pkl\")\n",
    "best_trial = study_results.best_trial.params\n",
    "best_trial['tree_method'] = tree_method\n",
    "pprint(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'hist',\n",
       " 'lambda': 0.1310350301056629,\n",
       " 'alpha': 0.13596726922222288,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'subsample': 0.9,\n",
       " 'learning_rate': 0.05,\n",
       " 'n_estimators': 1000,\n",
       " 'max_depth': 13,\n",
       " 'random_state': 48,\n",
       " 'min_child_weight': 1,\n",
       " 'early_stopping_rounds': 100.0,\n",
       " 'eval_metric': 'logloss'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial = study_results.best_trial.params\n",
    "#best_trial.update({'n_estimators': 4000, 'tree_method':tree_method})\n",
    "best_trial['tree_method'] = tree_method\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.834515Z",
     "iopub.status.busy": "2022-03-26T08:03:41.834060Z",
     "iopub.status.idle": "2022-03-26T08:03:41.859859Z",
     "shell.execute_reply": "2022-03-26T08:03:41.859192Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.834477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trial results dataframe sorted from best value (RMSE) ascending\n",
    "def ViewResultsAsDf():\n",
    "    stdf = study_results.trials_dataframe()\n",
    "    stdf = stdf.sort_values('value',ascending=True)\n",
    "\n",
    "    return stdf.head(2)    # return here is only used for printing output\n",
    "\n",
    "ViewResultsAsDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.861308Z",
     "iopub.status.busy": "2022-03-26T08:03:41.860969Z",
     "iopub.status.idle": "2022-03-26T08:03:44.062901Z",
     "shell.execute_reply": "2022-03-26T08:03:44.062232Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.861270Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualize parameter importance\n",
    "optuna.visualization.plot_param_importances(study_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:44.064544Z",
     "iopub.status.busy": "2022-03-26T08:03:44.064101Z",
     "iopub.status.idle": "2022-03-26T08:03:44.071602Z",
     "shell.execute_reply": "2022-03-26T08:03:44.070934Z",
     "shell.execute_reply.started": "2022-03-26T08:03:44.064505Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"Optuna run completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"try_best_hp\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.4 Model v4 : Try the Optuna Hyperparameters</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:44.073183Z",
     "iopub.status.busy": "2022-03-26T08:03:44.072800Z",
     "iopub.status.idle": "2022-03-26T08:07:48.555184Z",
     "shell.execute_reply": "2022-03-26T08:07:48.554423Z",
     "shell.execute_reply.started": "2022-03-26T08:03:44.073143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status Count ->  1 : 714212, 0 : 154451\n",
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n",
      "\n",
      "\u001b[1mPlease wait, Fitting model can take time ...\u001b[0m\n",
      "Fitting model completed.\n",
      "\n",
      "Preparing Predictions\n",
      "\n",
      "\u001b[4mMetrics : After Optuna Tuning\u001b[0m\n",
      "MAE: 0.026901392674457677\n",
      "RMSE: 0.16401644025663303\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    107165\n",
      "           1       0.99      0.95      0.97    107099\n",
      "\n",
      "    accuracy                           0.97    214264\n",
      "   macro avg       0.97      0.97      0.97    214264\n",
      "weighted avg       0.97      0.97      0.97    214264\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 106332 times correctly   (95.57 %)\n",
      "False Negative : CHGOFF (0) was predicted 4931 times incorrectly     (4.43 %)\n",
      "True Positive : P I F (1) was predicted 102168 times correctly     (99.19 %)\n",
      "False Positive : P I F (1) was predicted 833 times incorrectly     (0.81 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 97.31\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 97.36\n",
      "   P I F (1)  : 97.26\n",
      "RMSE: 0.16401644025663303\n",
      "Total boosted rounds: 1000\n",
      "CPU times: total: 22min 16s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv4():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model4 = process_model(X, y)\n",
    "    model4.osample()\n",
    "    model4.split_data(0.7)\n",
    "    \n",
    "    model4.X, model4.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    model4_results = model4.prep_run_model(\"Metrics : After Optuna Tuning\",\n",
    "                                           hyperparams = best_trial)\n",
    "    \n",
    "    text_boosted = \\\n",
    "        f\"Total boosted rounds: {model4_results['xg_model'].get_booster().num_boosted_rounds()}\"\n",
    "    print(text_boosted)\n",
    "    \n",
    "    # save to files for reuse later\n",
    "    model4_results['xg_model'].save_model(f'{savepath}modelv4.json')\n",
    "    joblib.dump(model4_results, f\"{savepath}model4_results.dict\")   \n",
    "\n",
    "#with warnings.catch_warnings():\n",
    "#    warnings.filterwarnings('ignore')\n",
    "#    warnings.simplefilter(\"ignore\")\n",
    "RunModelv4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:07:48.556949Z",
     "iopub.status.busy": "2022-03-26T08:07:48.556435Z",
     "iopub.status.idle": "2022-03-26T08:07:48.563964Z",
     "shell.execute_reply": "2022-03-26T08:07:48.563172Z",
     "shell.execute_reply.started": "2022-03-26T08:07:48.556902Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"Model Test with Optuna completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_comparison\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>1.5 Optuna Tuning Comparison</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Compare metrics before and after Optuna tuning.</b><br><br>\n",
    "    Comparison is made between modelv3 results in <a style=\"color:DarkSlateGrey\" href=\"https://www.kaggle.com/code/josephramon/sba-xgboost-model\">Part 1 Notebook</a> and modelv4 results here.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:07:48.566044Z",
     "iopub.status.busy": "2022-03-26T08:07:48.565194Z",
     "iopub.status.idle": "2022-03-26T08:07:48.583368Z",
     "shell.execute_reply": "2022-03-26T08:07:48.582657Z",
     "shell.execute_reply.started": "2022-03-26T08:07:48.565947Z"
    }
   },
   "outputs": [],
   "source": [
    "def CompareResults():\n",
    "    model3_results = joblib.load(f\"{filepath}model3_results.dict\")\n",
    "    model4_results = joblib.load(f\"{savepath}model4_results.dict\")\n",
    "\n",
    "    m3_clf_report = model3_results['eval_results']['ClassificationReport']\n",
    "\n",
    "    m3_0_f1_score = round(m3_clf_report['0']['f1-score'] * 100, 2)\n",
    "    m3_1_f1_score = round(m3_clf_report['1']['f1-score'] * 100, 2)\n",
    "    m3_accuracy   = round(m3_clf_report['accuracy'] * 100, 2)\n",
    "\n",
    "\n",
    "    m4_clf_report = model4_results['eval_results']['ClassificationReport']\n",
    "\n",
    "    m4_0_f1_score = round(m4_clf_report['0']['f1-score'] * 100, 2)\n",
    "    m4_1_f1_score = round(m4_clf_report['1']['f1-score'] * 100, 2)\n",
    "    m4_accuracy   = round(m4_clf_report['accuracy'] * 100, 2)\n",
    "\n",
    "\n",
    "    data = {'Model v3 : No Optuna':[m3_0_f1_score, m3_1_f1_score, m3_accuracy],\n",
    "            'Model v4 : With Optuna':[m4_0_f1_score, m4_1_f1_score, m4_accuracy]}\n",
    " \n",
    "    # Creates pandas DataFrame.\n",
    "    df = pd.DataFrame(data, index =['0 : f1_score',\n",
    "                                    '1 : f1_score',\n",
    "                                    'Accuracy'])\n",
    "    print(f'{color.bdgreen}Accuracy Improvement Using Optuna Suggested Parameters:{color.end}')\n",
    "    print(f'{color.bold}Improved by {color.bdblue}{round(m4_accuracy - m3_accuracy,2)}\\\n",
    "        {color.end}')\n",
    "    return df\n",
    "\n",
    "CompareResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Run Modelv4 On Unseen Test Dataset</b>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.026663368554680208\n",
      "RMSE: 0.16328921750893477\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    107332\n",
      "           1       0.99      0.95      0.97    106932\n",
      "\n",
      "    accuracy                           0.97    214264\n",
      "   macro avg       0.97      0.97      0.97    214264\n",
      "weighted avg       0.97      0.97      0.97    214264\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 106565 times correctly   (95.56 %)\n",
      "False Negative : CHGOFF (0) was predicted 4946 times incorrectly     (4.44 %)\n",
      "True Positive : P I F (1) was predicted 101986 times correctly     (99.25 %)\n",
      "False Positive : P I F (1) was predicted 767 times incorrectly     (0.75 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 97.33\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 97.39\n",
      "   P I F (1)  : 97.28\n",
      "RMSE: 0.16328921750893477\n"
     ]
    }
   ],
   "source": [
    "def Modelv4WithTestData():\n",
    "    model4_results = joblib.load(f\"{savepath}model4_results.dict\")\n",
    "    X_test = model4_results['X_test']\n",
    "    y_test = model4_results['y_test']\n",
    "    modelv4 = model4_results['xg_model']\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = modelv4.predict(X_test)\n",
    "    model_eval(y_test, predictions);\n",
    "  \n",
    "Modelv4WithTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:07:48.585169Z",
     "iopub.status.busy": "2022-03-26T08:07:48.584709Z",
     "iopub.status.idle": "2022-03-26T08:07:48.818069Z",
     "shell.execute_reply": "2022-03-26T08:07:48.817400Z",
     "shell.execute_reply.started": "2022-03-26T08:07:48.585132Z"
    }
   },
   "outputs": [],
   "source": [
    "del best_trial, study_results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Observation:</b><br><br>\n",
    "    <b>The Accuracy and F1 scores after Optuna tuning are improved compared to before tuning;</b> but it all depends on what hyperparameters/values are given.  A few trial sessions may be needed.<br><br>\n",
    "    We have a different score in our <a style=\"color:DarkSlateGrey\" href=\"https://www.kaggle.com/code/josephramon/sba-xgboost-model\">Pipeline</a> as we used an Optuna hyperparameter set that was obtained from another Optuna run.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross_validation\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>Cross Validation</h2><br>\n",
    "Measure our model's quality, in RMSE.  Ideally for small datasets, but included here for reference.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def CrossVal():\n",
    "    print(f'{color.bold}Please wait, this will take some time{color.end}')\n",
    "    print()\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    cvo = process_model(X, y)   # create object from XGBoost class\n",
    "    cvo.osample()               # oversample\n",
    "    cvo.split_data(0.7)\n",
    "\n",
    "    cvo.X, cvo.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # get hyperparams from previous Optuna study's best trial\n",
    "    study_results = joblib.load(f\"{savepath}xgb_optuna_study.pkl\")\n",
    "    hyperparams = study_results.best_trial.params\n",
    "    pprint(hyperparams)\n",
    "    print()\n",
    "\n",
    "    xgb_model = XGBClassifier(**hyperparams, use_label_encoder = False)\n",
    "\n",
    "    # If we pass a pipeline instead of a model to cross_val_score, fit_params won't be \n",
    "    # recognized\n",
    "    fit_params={'verbose': False,\n",
    "                'eval_set': [(cvo.X_valid, cvo.y_valid)]\n",
    "               }\n",
    "\n",
    "    # Multiply by -1 since sklearn calculates *negative* RMSE\n",
    "    print()\n",
    "    scores = -1 * cross_val_score(xgb_model, cvo.X_train, cvo.y_train,\n",
    "                                  cv=5,\n",
    "                                  scoring='neg_root_mean_squared_error',\n",
    "                                  fit_params = fit_params,\n",
    "                                  verbose=15)\n",
    "    sleep(5)   # allow verbosity to complete\n",
    "    print()\n",
    "    print(f\"{color.bdblue}Scores: {scores}{color.end}\")\n",
    "    print()\n",
    "    print(f\"{color.bdgreen}Root Mean Squared Error (Mean): {scores.mean()}{color.end}\")\n",
    "    print()\n",
    "    \n",
    "CrossVal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 id=\"part2\" style='color:GhostWhite;'>Part 2. Miscellaneous</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"early_stopping_rounds\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.1 Early Stopping Rounds</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Below is a reference on using plots to get an insight on the value to use for XGBoost's early_ stopping_rounds during fitting.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def PlotEarlyStoppingRounds():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    esr = process_model(X, y)\n",
    "    esr.osample()     # oversample\n",
    "    esr.split_data(0.7)\n",
    "    \n",
    "    esr.X, esr.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)   \n",
    "    \n",
    "    print()\n",
    "    print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")\n",
    "    print()\n",
    "    \n",
    "    # get hyperparams from previous Optuna study's best trial\n",
    "    # early_stopping_rounds not included as we are trying to confirm if our value was valid\n",
    "    study_results = joblib.load(f\"{savepath}xgb_optuna_study.pkl\")\n",
    "    hyperparams = study_results.best_trial.params\n",
    "    hyperparams.pop('early_stopping_rounds')\n",
    "    hyperparams['eval_metric'] = ['error','logloss']\n",
    "    pprint(hyperparams)\n",
    "    print()\n",
    "\n",
    "    xg_model = XGBClassifier(**hyperparams,use_label_encoder =False)\n",
    "       \n",
    "    eval_setparam = [(esr.X_train, esr.y_train),\n",
    "                     (esr.X_valid, esr.y_valid)]\n",
    "       \n",
    "    # fit the model\n",
    "    xg_model.fit(esr.X_train, esr.y_train, \n",
    "                eval_set = eval_setparam,\n",
    "                verbose=False)\n",
    " \n",
    "    print(\"Fitting model completed.\")\n",
    "    print()\n",
    "    print('Preparing Predictions')\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = xg_model.predict(esr.X_valid)\n",
    "    \n",
    "    print()\n",
    "    print(f'{color.underline}Metrics:{color.end}')\n",
    "\n",
    "    eval_results = model_eval(esr.y_valid, predictions)\n",
    "\n",
    "    # retrieve performance metrics\n",
    "    results = xg_model.evals_result()\n",
    "    epochs = len(results['validation_0']['error'])\n",
    "    x_axis = range(0, epochs)\n",
    "\n",
    "    # what we will be looking for are the bottom areas of the plots\n",
    "    \n",
    "    # plot log loss\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Log Loss')\n",
    "    pyplot.title('XGBoost Log Loss')\n",
    "    pyplot.show()\n",
    "\n",
    "    # plot classification error\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Classification Error')\n",
    "    pyplot.title('XGBoost Classification Error')\n",
    "    pyplot.show()\n",
    "    \n",
    "PlotEarlyStoppingRounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    From both plots, we can see that 10% of n_estimator is a good candidate as the early_stopping_rounds parameter.\n",
    "<br><br>\n",
    "    <b>Test Early Stopping Rounds</b>\n",
    "    <br>\n",
    "    Now we test the early_stopping_rounds parameter.  We will test it on imbalanced data, which is our data that is <b>not oversampled</b>, which is skewed heavily toward MIS_Status = 'P I F' as opposed to MIS_Status = 'CHGOFF'.  Furthermore, we use an <b>eval_metric = 'auc'</b>, which is ideal for imbalanced data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:44.073183Z",
     "iopub.status.busy": "2022-03-26T08:03:44.072800Z",
     "iopub.status.idle": "2022-03-26T08:07:48.555184Z",
     "shell.execute_reply": "2022-03-26T08:07:48.554423Z",
     "shell.execute_reply.started": "2022-03-26T08:03:44.073143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status Count ->  1 : 714212, 0 : 154451\n",
      "\u001b[1mFit() Iterations:\u001b[0m\n",
      "[0]\tvalidation_0-auc:0.96545\n",
      "[1]\tvalidation_0-auc:0.96773\n",
      "[2]\tvalidation_0-auc:0.96848\n",
      "[3]\tvalidation_0-auc:0.96479\n",
      "[4]\tvalidation_0-auc:0.96663\n",
      "[5]\tvalidation_0-auc:0.96780\n",
      "[6]\tvalidation_0-auc:0.96846\n",
      "[7]\tvalidation_0-auc:0.96950\n",
      "[8]\tvalidation_0-auc:0.96977\n",
      "[9]\tvalidation_0-auc:0.97004\n",
      "[10]\tvalidation_0-auc:0.97019\n",
      "[11]\tvalidation_0-auc:0.97050\n",
      "[12]\tvalidation_0-auc:0.97063\n",
      "[13]\tvalidation_0-auc:0.97075\n",
      "[14]\tvalidation_0-auc:0.97019\n",
      "[15]\tvalidation_0-auc:0.97035\n",
      "[16]\tvalidation_0-auc:0.96974\n",
      "[17]\tvalidation_0-auc:0.97001\n",
      "[18]\tvalidation_0-auc:0.97023\n",
      "[19]\tvalidation_0-auc:0.97051\n",
      "[20]\tvalidation_0-auc:0.97066\n",
      "[21]\tvalidation_0-auc:0.97030\n",
      "[22]\tvalidation_0-auc:0.97047\n",
      "[23]\tvalidation_0-auc:0.97023\n",
      "[24]\tvalidation_0-auc:0.97043\n",
      "[25]\tvalidation_0-auc:0.97065\n",
      "[26]\tvalidation_0-auc:0.97082\n",
      "[27]\tvalidation_0-auc:0.97095\n",
      "[28]\tvalidation_0-auc:0.97108\n",
      "[29]\tvalidation_0-auc:0.97121\n",
      "[30]\tvalidation_0-auc:0.97133\n",
      "[31]\tvalidation_0-auc:0.97148\n",
      "[32]\tvalidation_0-auc:0.97160\n",
      "[33]\tvalidation_0-auc:0.97168\n",
      "[34]\tvalidation_0-auc:0.97177\n",
      "[35]\tvalidation_0-auc:0.97184\n",
      "[36]\tvalidation_0-auc:0.97190\n",
      "[37]\tvalidation_0-auc:0.97197\n",
      "[38]\tvalidation_0-auc:0.97202\n",
      "[39]\tvalidation_0-auc:0.97204\n",
      "[40]\tvalidation_0-auc:0.97212\n",
      "[41]\tvalidation_0-auc:0.97210\n",
      "[42]\tvalidation_0-auc:0.97216\n",
      "[43]\tvalidation_0-auc:0.97212\n",
      "[44]\tvalidation_0-auc:0.97220\n",
      "[45]\tvalidation_0-auc:0.97225\n",
      "[46]\tvalidation_0-auc:0.97236\n",
      "[47]\tvalidation_0-auc:0.97243\n",
      "[48]\tvalidation_0-auc:0.97251\n",
      "[49]\tvalidation_0-auc:0.97260\n",
      "[50]\tvalidation_0-auc:0.97265\n",
      "[51]\tvalidation_0-auc:0.97271\n",
      "[52]\tvalidation_0-auc:0.97275\n",
      "[53]\tvalidation_0-auc:0.97280\n",
      "[54]\tvalidation_0-auc:0.97286\n",
      "[55]\tvalidation_0-auc:0.97290\n",
      "[56]\tvalidation_0-auc:0.97294\n",
      "[57]\tvalidation_0-auc:0.97297\n",
      "[58]\tvalidation_0-auc:0.97306\n",
      "[59]\tvalidation_0-auc:0.97311\n",
      "[60]\tvalidation_0-auc:0.97314\n",
      "[61]\tvalidation_0-auc:0.97318\n",
      "[62]\tvalidation_0-auc:0.97322\n",
      "[63]\tvalidation_0-auc:0.97324\n",
      "[64]\tvalidation_0-auc:0.97330\n",
      "[65]\tvalidation_0-auc:0.97333\n",
      "[66]\tvalidation_0-auc:0.97337\n",
      "[67]\tvalidation_0-auc:0.97341\n",
      "[68]\tvalidation_0-auc:0.97348\n",
      "[69]\tvalidation_0-auc:0.97350\n",
      "[70]\tvalidation_0-auc:0.97352\n",
      "[71]\tvalidation_0-auc:0.97356\n",
      "[72]\tvalidation_0-auc:0.97359\n",
      "[73]\tvalidation_0-auc:0.97362\n",
      "[74]\tvalidation_0-auc:0.97364\n",
      "[75]\tvalidation_0-auc:0.97367\n",
      "[76]\tvalidation_0-auc:0.97370\n",
      "[77]\tvalidation_0-auc:0.97373\n",
      "[78]\tvalidation_0-auc:0.97374\n",
      "[79]\tvalidation_0-auc:0.97378\n",
      "[80]\tvalidation_0-auc:0.97381\n",
      "[81]\tvalidation_0-auc:0.97382\n",
      "[82]\tvalidation_0-auc:0.97385\n",
      "[83]\tvalidation_0-auc:0.97387\n",
      "[84]\tvalidation_0-auc:0.97389\n",
      "[85]\tvalidation_0-auc:0.97391\n",
      "[86]\tvalidation_0-auc:0.97393\n",
      "[87]\tvalidation_0-auc:0.97396\n",
      "[88]\tvalidation_0-auc:0.97398\n",
      "[89]\tvalidation_0-auc:0.97398\n",
      "[90]\tvalidation_0-auc:0.97399\n",
      "[91]\tvalidation_0-auc:0.97402\n",
      "[92]\tvalidation_0-auc:0.97403\n",
      "[93]\tvalidation_0-auc:0.97405\n",
      "[94]\tvalidation_0-auc:0.97407\n",
      "[95]\tvalidation_0-auc:0.97409\n",
      "[96]\tvalidation_0-auc:0.97409\n",
      "[97]\tvalidation_0-auc:0.97409\n",
      "[98]\tvalidation_0-auc:0.97413\n",
      "[99]\tvalidation_0-auc:0.97415\n",
      "[100]\tvalidation_0-auc:0.97415\n",
      "[101]\tvalidation_0-auc:0.97418\n",
      "[102]\tvalidation_0-auc:0.97419\n",
      "[103]\tvalidation_0-auc:0.97424\n",
      "[104]\tvalidation_0-auc:0.97426\n",
      "[105]\tvalidation_0-auc:0.97426\n",
      "[106]\tvalidation_0-auc:0.97427\n",
      "[107]\tvalidation_0-auc:0.97430\n",
      "[108]\tvalidation_0-auc:0.97432\n",
      "[109]\tvalidation_0-auc:0.97432\n",
      "[110]\tvalidation_0-auc:0.97433\n",
      "[111]\tvalidation_0-auc:0.97434\n",
      "[112]\tvalidation_0-auc:0.97435\n",
      "[113]\tvalidation_0-auc:0.97434\n",
      "[114]\tvalidation_0-auc:0.97434\n",
      "[115]\tvalidation_0-auc:0.97437\n",
      "[116]\tvalidation_0-auc:0.97438\n",
      "[117]\tvalidation_0-auc:0.97440\n",
      "[118]\tvalidation_0-auc:0.97441\n",
      "[119]\tvalidation_0-auc:0.97442\n",
      "[120]\tvalidation_0-auc:0.97442\n",
      "[121]\tvalidation_0-auc:0.97444\n",
      "[122]\tvalidation_0-auc:0.97445\n",
      "[123]\tvalidation_0-auc:0.97446\n",
      "[124]\tvalidation_0-auc:0.97446\n",
      "[125]\tvalidation_0-auc:0.97448\n",
      "[126]\tvalidation_0-auc:0.97451\n",
      "[127]\tvalidation_0-auc:0.97451\n",
      "[128]\tvalidation_0-auc:0.97450\n",
      "[129]\tvalidation_0-auc:0.97452\n",
      "[130]\tvalidation_0-auc:0.97453\n",
      "[131]\tvalidation_0-auc:0.97453\n",
      "[132]\tvalidation_0-auc:0.97455\n",
      "[133]\tvalidation_0-auc:0.97455\n",
      "[134]\tvalidation_0-auc:0.97455\n",
      "[135]\tvalidation_0-auc:0.97455\n",
      "[136]\tvalidation_0-auc:0.97455\n",
      "[137]\tvalidation_0-auc:0.97454\n",
      "[138]\tvalidation_0-auc:0.97455\n",
      "[139]\tvalidation_0-auc:0.97456\n",
      "[140]\tvalidation_0-auc:0.97456\n",
      "[141]\tvalidation_0-auc:0.97456\n",
      "[142]\tvalidation_0-auc:0.97456\n",
      "[143]\tvalidation_0-auc:0.97458\n",
      "[144]\tvalidation_0-auc:0.97457\n",
      "[145]\tvalidation_0-auc:0.97458\n",
      "[146]\tvalidation_0-auc:0.97458\n",
      "[147]\tvalidation_0-auc:0.97458\n",
      "[148]\tvalidation_0-auc:0.97460\n",
      "[149]\tvalidation_0-auc:0.97461\n",
      "[150]\tvalidation_0-auc:0.97461\n",
      "[151]\tvalidation_0-auc:0.97462\n",
      "[152]\tvalidation_0-auc:0.97462\n",
      "[153]\tvalidation_0-auc:0.97464\n",
      "[154]\tvalidation_0-auc:0.97466\n",
      "[155]\tvalidation_0-auc:0.97466\n",
      "[156]\tvalidation_0-auc:0.97467\n",
      "[157]\tvalidation_0-auc:0.97468\n",
      "[158]\tvalidation_0-auc:0.97468\n",
      "[159]\tvalidation_0-auc:0.97469\n",
      "[160]\tvalidation_0-auc:0.97469\n",
      "[161]\tvalidation_0-auc:0.97469\n",
      "[162]\tvalidation_0-auc:0.97470\n",
      "[163]\tvalidation_0-auc:0.97470\n",
      "[164]\tvalidation_0-auc:0.97471\n",
      "[165]\tvalidation_0-auc:0.97471\n",
      "[166]\tvalidation_0-auc:0.97473\n",
      "[167]\tvalidation_0-auc:0.97473\n",
      "[168]\tvalidation_0-auc:0.97473\n",
      "[169]\tvalidation_0-auc:0.97473\n",
      "[170]\tvalidation_0-auc:0.97474\n",
      "[171]\tvalidation_0-auc:0.97473\n",
      "[172]\tvalidation_0-auc:0.97474\n",
      "[173]\tvalidation_0-auc:0.97475\n",
      "[174]\tvalidation_0-auc:0.97475\n",
      "[175]\tvalidation_0-auc:0.97475\n",
      "[176]\tvalidation_0-auc:0.97475\n",
      "[177]\tvalidation_0-auc:0.97476\n",
      "[178]\tvalidation_0-auc:0.97476\n",
      "[179]\tvalidation_0-auc:0.97476\n",
      "[180]\tvalidation_0-auc:0.97476\n",
      "[181]\tvalidation_0-auc:0.97476\n",
      "[182]\tvalidation_0-auc:0.97476\n",
      "[183]\tvalidation_0-auc:0.97477\n",
      "[184]\tvalidation_0-auc:0.97477\n",
      "[185]\tvalidation_0-auc:0.97477\n",
      "[186]\tvalidation_0-auc:0.97477\n",
      "[187]\tvalidation_0-auc:0.97478\n",
      "[188]\tvalidation_0-auc:0.97478\n",
      "[189]\tvalidation_0-auc:0.97479\n",
      "[190]\tvalidation_0-auc:0.97480\n",
      "[191]\tvalidation_0-auc:0.97479\n",
      "[192]\tvalidation_0-auc:0.97479\n",
      "[193]\tvalidation_0-auc:0.97480\n",
      "[194]\tvalidation_0-auc:0.97480\n",
      "[195]\tvalidation_0-auc:0.97480\n",
      "[196]\tvalidation_0-auc:0.97480\n",
      "[197]\tvalidation_0-auc:0.97479\n",
      "[198]\tvalidation_0-auc:0.97479\n",
      "[199]\tvalidation_0-auc:0.97479\n",
      "[200]\tvalidation_0-auc:0.97480\n",
      "[201]\tvalidation_0-auc:0.97480\n",
      "[202]\tvalidation_0-auc:0.97480\n",
      "[203]\tvalidation_0-auc:0.97481\n",
      "[204]\tvalidation_0-auc:0.97480\n",
      "[205]\tvalidation_0-auc:0.97481\n",
      "[206]\tvalidation_0-auc:0.97481\n",
      "[207]\tvalidation_0-auc:0.97480\n",
      "[208]\tvalidation_0-auc:0.97480\n",
      "[209]\tvalidation_0-auc:0.97480\n",
      "[210]\tvalidation_0-auc:0.97480\n",
      "[211]\tvalidation_0-auc:0.97479\n",
      "[212]\tvalidation_0-auc:0.97479\n",
      "[213]\tvalidation_0-auc:0.97480\n",
      "[214]\tvalidation_0-auc:0.97479\n",
      "[215]\tvalidation_0-auc:0.97479\n",
      "[216]\tvalidation_0-auc:0.97479\n",
      "[217]\tvalidation_0-auc:0.97479\n",
      "[218]\tvalidation_0-auc:0.97479\n",
      "[219]\tvalidation_0-auc:0.97479\n",
      "[220]\tvalidation_0-auc:0.97479\n",
      "[221]\tvalidation_0-auc:0.97480\n",
      "[222]\tvalidation_0-auc:0.97480\n",
      "[223]\tvalidation_0-auc:0.97480\n",
      "[224]\tvalidation_0-auc:0.97479\n",
      "[225]\tvalidation_0-auc:0.97480\n",
      "[226]\tvalidation_0-auc:0.97479\n",
      "[227]\tvalidation_0-auc:0.97478\n",
      "[228]\tvalidation_0-auc:0.97478\n",
      "[229]\tvalidation_0-auc:0.97478\n",
      "[230]\tvalidation_0-auc:0.97478\n",
      "[231]\tvalidation_0-auc:0.97478\n",
      "[232]\tvalidation_0-auc:0.97477\n",
      "[233]\tvalidation_0-auc:0.97477\n",
      "[234]\tvalidation_0-auc:0.97478\n",
      "[235]\tvalidation_0-auc:0.97477\n",
      "[236]\tvalidation_0-auc:0.97477\n",
      "[237]\tvalidation_0-auc:0.97477\n",
      "[238]\tvalidation_0-auc:0.97477\n",
      "[239]\tvalidation_0-auc:0.97476\n",
      "[240]\tvalidation_0-auc:0.97476\n",
      "[241]\tvalidation_0-auc:0.97477\n",
      "[242]\tvalidation_0-auc:0.97477\n",
      "[243]\tvalidation_0-auc:0.97477\n",
      "[244]\tvalidation_0-auc:0.97477\n",
      "[245]\tvalidation_0-auc:0.97478\n",
      "[246]\tvalidation_0-auc:0.97478\n",
      "[247]\tvalidation_0-auc:0.97478\n",
      "[248]\tvalidation_0-auc:0.97478\n",
      "[249]\tvalidation_0-auc:0.97478\n",
      "[250]\tvalidation_0-auc:0.97478\n",
      "[251]\tvalidation_0-auc:0.97479\n",
      "[252]\tvalidation_0-auc:0.97479\n",
      "[253]\tvalidation_0-auc:0.97480\n",
      "[254]\tvalidation_0-auc:0.97480\n",
      "[255]\tvalidation_0-auc:0.97479\n",
      "[256]\tvalidation_0-auc:0.97480\n",
      "[257]\tvalidation_0-auc:0.97480\n",
      "[258]\tvalidation_0-auc:0.97481\n",
      "[259]\tvalidation_0-auc:0.97481\n",
      "[260]\tvalidation_0-auc:0.97481\n",
      "[261]\tvalidation_0-auc:0.97481\n",
      "[262]\tvalidation_0-auc:0.97481\n",
      "[263]\tvalidation_0-auc:0.97483\n",
      "[264]\tvalidation_0-auc:0.97481\n",
      "[265]\tvalidation_0-auc:0.97481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266]\tvalidation_0-auc:0.97481\n",
      "[267]\tvalidation_0-auc:0.97481\n",
      "[268]\tvalidation_0-auc:0.97481\n",
      "[269]\tvalidation_0-auc:0.97481\n",
      "[270]\tvalidation_0-auc:0.97481\n",
      "[271]\tvalidation_0-auc:0.97480\n",
      "[272]\tvalidation_0-auc:0.97480\n",
      "[273]\tvalidation_0-auc:0.97481\n",
      "[274]\tvalidation_0-auc:0.97481\n",
      "[275]\tvalidation_0-auc:0.97481\n",
      "[276]\tvalidation_0-auc:0.97480\n",
      "[277]\tvalidation_0-auc:0.97480\n",
      "[278]\tvalidation_0-auc:0.97481\n",
      "[279]\tvalidation_0-auc:0.97480\n",
      "[280]\tvalidation_0-auc:0.97480\n",
      "[281]\tvalidation_0-auc:0.97480\n",
      "[282]\tvalidation_0-auc:0.97480\n",
      "[283]\tvalidation_0-auc:0.97480\n",
      "[284]\tvalidation_0-auc:0.97480\n",
      "[285]\tvalidation_0-auc:0.97480\n",
      "[286]\tvalidation_0-auc:0.97480\n",
      "[287]\tvalidation_0-auc:0.97480\n",
      "[288]\tvalidation_0-auc:0.97481\n",
      "[289]\tvalidation_0-auc:0.97481\n",
      "[290]\tvalidation_0-auc:0.97480\n",
      "[291]\tvalidation_0-auc:0.97481\n",
      "[292]\tvalidation_0-auc:0.97481\n",
      "[293]\tvalidation_0-auc:0.97480\n",
      "[294]\tvalidation_0-auc:0.97480\n",
      "[295]\tvalidation_0-auc:0.97480\n",
      "[296]\tvalidation_0-auc:0.97481\n",
      "[297]\tvalidation_0-auc:0.97481\n",
      "[298]\tvalidation_0-auc:0.97480\n",
      "[299]\tvalidation_0-auc:0.97480\n",
      "[300]\tvalidation_0-auc:0.97480\n",
      "[301]\tvalidation_0-auc:0.97480\n",
      "[302]\tvalidation_0-auc:0.97480\n",
      "[303]\tvalidation_0-auc:0.97480\n",
      "[304]\tvalidation_0-auc:0.97480\n",
      "[305]\tvalidation_0-auc:0.97480\n",
      "[306]\tvalidation_0-auc:0.97480\n",
      "[307]\tvalidation_0-auc:0.97480\n",
      "[308]\tvalidation_0-auc:0.97480\n",
      "[309]\tvalidation_0-auc:0.97479\n",
      "[310]\tvalidation_0-auc:0.97479\n",
      "[311]\tvalidation_0-auc:0.97480\n",
      "[312]\tvalidation_0-auc:0.97480\n",
      "[313]\tvalidation_0-auc:0.97481\n",
      "[314]\tvalidation_0-auc:0.97481\n",
      "[315]\tvalidation_0-auc:0.97481\n",
      "[316]\tvalidation_0-auc:0.97481\n",
      "[317]\tvalidation_0-auc:0.97481\n",
      "[318]\tvalidation_0-auc:0.97480\n",
      "[319]\tvalidation_0-auc:0.97480\n",
      "[320]\tvalidation_0-auc:0.97479\n",
      "[321]\tvalidation_0-auc:0.97480\n",
      "[322]\tvalidation_0-auc:0.97479\n",
      "[323]\tvalidation_0-auc:0.97479\n",
      "[324]\tvalidation_0-auc:0.97478\n",
      "[325]\tvalidation_0-auc:0.97478\n",
      "[326]\tvalidation_0-auc:0.97478\n",
      "[327]\tvalidation_0-auc:0.97478\n",
      "[328]\tvalidation_0-auc:0.97478\n",
      "[329]\tvalidation_0-auc:0.97478\n",
      "[330]\tvalidation_0-auc:0.97478\n",
      "[331]\tvalidation_0-auc:0.97477\n",
      "[332]\tvalidation_0-auc:0.97477\n",
      "[333]\tvalidation_0-auc:0.97477\n",
      "[334]\tvalidation_0-auc:0.97477\n",
      "[335]\tvalidation_0-auc:0.97477\n",
      "[336]\tvalidation_0-auc:0.97477\n",
      "[337]\tvalidation_0-auc:0.97477\n",
      "[338]\tvalidation_0-auc:0.97476\n",
      "[339]\tvalidation_0-auc:0.97476\n",
      "[340]\tvalidation_0-auc:0.97477\n",
      "[341]\tvalidation_0-auc:0.97477\n",
      "[342]\tvalidation_0-auc:0.97476\n",
      "[343]\tvalidation_0-auc:0.97476\n",
      "[344]\tvalidation_0-auc:0.97475\n",
      "[345]\tvalidation_0-auc:0.97475\n",
      "[346]\tvalidation_0-auc:0.97475\n",
      "[347]\tvalidation_0-auc:0.97475\n",
      "[348]\tvalidation_0-auc:0.97476\n",
      "[349]\tvalidation_0-auc:0.97475\n",
      "[350]\tvalidation_0-auc:0.97475\n",
      "[351]\tvalidation_0-auc:0.97475\n",
      "[352]\tvalidation_0-auc:0.97474\n",
      "[353]\tvalidation_0-auc:0.97474\n",
      "[354]\tvalidation_0-auc:0.97473\n",
      "[355]\tvalidation_0-auc:0.97474\n",
      "[356]\tvalidation_0-auc:0.97474\n",
      "[357]\tvalidation_0-auc:0.97474\n",
      "[358]\tvalidation_0-auc:0.97474\n",
      "[359]\tvalidation_0-auc:0.97474\n",
      "[360]\tvalidation_0-auc:0.97474\n",
      "[361]\tvalidation_0-auc:0.97474\n",
      "[362]\tvalidation_0-auc:0.97474\n",
      "[363]\tvalidation_0-auc:0.97473\n",
      "\n",
      "MAE: 0.05622452973545461\n",
      "RMSE: 0.23711712240041757\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84     23047\n",
      "           1       0.96      0.97      0.97    107252\n",
      "\n",
      "    accuracy                           0.94    130299\n",
      "   macro avg       0.91      0.89      0.90    130299\n",
      "weighted avg       0.94      0.94      0.94    130299\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 18806 times correctly   (85.91 %)\n",
      "False Negative : CHGOFF (0) was predicted 3085 times incorrectly     (14.09 %)\n",
      "True Positive : P I F (1) was predicted 104167 times correctly     (96.09 %)\n",
      "False Positive : P I F (1) was predicted 4241 times incorrectly     (3.91 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 94.38\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 83.7\n",
      "   P I F (1)  : 96.6\n",
      "RMSE: 0.23711712240041757\n",
      "CPU times: total: 4min 14s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv5():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model5 = process_model(X, y)\n",
    "    # model5.osample()     # we comment out the oversampling algorithm\n",
    "    model5.split_data(0.7)\n",
    "    \n",
    "    model5.X, model5.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    # we use the recently saved optuna study to get the hyperparams\n",
    "    study = joblib.load(f\"{savepath}xgb_optuna_study.pkl\")\n",
    "    hyperparams = study.best_trial.params\n",
    "    hyperparams['eval_metric'] = 'auc'      # we change eval_metric to 'auc'\n",
    "                   \n",
    "    model_xg = XGBClassifier(**hyperparams, use_label_encoder =False)\n",
    " \n",
    "    print(f'{color.bold}Fit() Iterations:{color.end}')\n",
    "    eval_set = [(model5.X_valid, model5.y_valid)]\n",
    "    model_xg.fit(model5.X_train, model5.y_train,\n",
    "              eval_set=eval_set, verbose=True)\n",
    " \n",
    "    # Get predictions\n",
    "    predictions = model_xg.predict(model5.X_valid)\n",
    "\n",
    "    print()\n",
    "    eval_results = model_eval(model5.y_valid, predictions)\n",
    "    \n",
    "RunModelv5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Result:</b><br>\n",
    "    As we can see from above, from the verbose results of the fit() method, <b>the training stopped at a certain iteration before it reached 1000</b>, since <b>the auc score was starting to decrease</b>.  In conclusion, the early_stopping_rounds parameter works.  Although it was set at 100, at 100th iteration, the <b>auc score was still increasing</b>, so it didn't stop yet.\n",
    "    <br><br>\n",
    "    If we oversampled the data, the fit() method will complete the entire n_estimators = 1000, as the score is still getting better even at 1000.  In conclusion, oversampling helped get better results without reaching the overfitting threshold yet at the selected n_estimator value.  It's not just blind oversampling of course, it was a technique to solve the imbalance of data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random_forest_classifier\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.2 Random Forest Classifier</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    This is just a reference on using a Random Forest Classifier.<br>\n",
    "    <b>cuml.ensemble RandomForestClassifier</b> is used if GPU is active; otherwise, Scikit-Learn's RandomForestClassifier.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n",
      "\n",
      "\u001b[1mPlease wait, Fitting model can take time ...\u001b[0m\n",
      "Fitting model completed.\n",
      "\n",
      "Preparing Predictions\n",
      "\u001b[4mMetrics : Random Forest Classifier\u001b[0m\n",
      "MAE: 15.178788783930106\n",
      "RMSE: 0.3341785696780467\n",
      "\n",
      "\u001b[1mClassification Report:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89    107165\n",
      "           1       0.89      0.88      0.89    107099\n",
      "\n",
      "    accuracy                           0.89    214264\n",
      "   macro avg       0.89      0.89      0.89    214264\n",
      "weighted avg       0.89      0.89      0.89    214264\n",
      "\n",
      "\n",
      "\u001b[1mConfusion Matrix:\u001b[0m\n",
      "\n",
      "True Negative : CHGOFF (0) was predicted 95947 times correctly   (88.3 %)\n",
      "False Negative : CHGOFF (0) was predicted 12710 times incorrectly     (11.7 %)\n",
      "True Positive : P I F (1) was predicted 94389 times correctly     (89.38 %)\n",
      "False Positive : P I F (1) was predicted 11218 times incorrectly     (10.62 %)\n",
      "\n",
      "\u001b[1m\u001b[92mAccuracy for model: 88.83\u001b[0m\n",
      "\u001b[1m\u001b[94mf1-score: \u001b[0m\n",
      "   CHGOFF (0) : 88.91\n",
      "   P I F (1)  : 88.75\n",
      "RMSE: 0.3341785696780467\n",
      "\n",
      "CPU times: total: 1min 50s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run before tuning\n",
    "def RunModelrf():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    modelrf = other_models(X, y)\n",
    "    modelrf.osample()\n",
    "    modelrf.split_data(0.7)\n",
    "    \n",
    "    modelrf.X, modelrf.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    modelrf.prep_run_model(\"Metrics : Random Forest Classifier\", modelname='rfc')\n",
    "\n",
    "RunModelrf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Optuna Tuning for Random Forest</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "    This is just a simple sample implementation, for reference.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mTrial 0 done with best value: \u001b[1m\u001b[92m0.8762274577157152\u001b[1m\u001b[94m and parameters: \u001b[0m{'max_features': 0.660357966635801, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_samples': 0.6606472757270871, 'max_depth': 5, 'n_estimators': 100}. \n",
      "\n",
      "Current Ram Used: 71.4 %\n",
      "\u001b[1m\u001b[92mTotal Elapsed Time from Training Start: \u001b[0mRuntime : 0:03:46.949617\n",
      "Running Trial 2\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def RandomForestOptunaTuning():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    rfo = optuna_tuning(X, y)\n",
    "    rfo.osample()  # oversample\n",
    "    rfo.split_data(0.7)\n",
    "    \n",
    "    rfo.X, rfo.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    print(f'{color.bold}Please wait, this will take time{color.end}')\n",
    "    \n",
    "    nn_trials = 3\n",
    "    \n",
    "    if os.path.exists(f'{savepath}rfc_optuna_study_log.txt'):\n",
    "        os.remove(f'{savepath}rfc_optuna_study_log.txt') \n",
    "    \n",
    "    # STUDY\n",
    "    \n",
    "    # Turn off optuna log notes, to use own logging notes\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARN)\n",
    "    \n",
    "    # Turn on optuna log notes\n",
    "    #optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "    print(f\"{color.bold}Please wait, finding best trial ...{color.end}\")\n",
    "            \n",
    "    gt = dt.datetime.now()\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    try:\n",
    "        # callbacks [self.save_study] is to save study in case memory fails\n",
    "        study.optimize(lambda trial: rfo.objective_rf(trial, gt), \n",
    "                        n_trials = nn_trials,\n",
    "                        callbacks = [rfo.logging_callback, rfo.save_study],\n",
    "                        gc_after_trial = True,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "    except MemoryError as e:\n",
    "        print(f'{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}')\n",
    "  \n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    print()\n",
    "    print(f'Number of finished trials: {len(study.trials)}')\n",
    "    print(f'Number of pruned trials: {len(pruned_trials)}')\n",
    "    print(f'Number of completed trials: {color.bdgreen}{len(complete_trials)}{color.end}')\n",
    "    print(f'{color.bdblue}Best trial: {study.best_trial.params}{color.end}')\n",
    "    \n",
    "    joblib.dump(study, f\"{savepath}rfc_optuna_study.pkl\")   # save study\n",
    "    # jl = joblib.load(f\"{savepath}rfc_optuna_study.pkl\")   # load study\n",
    "\n",
    "    print()\n",
    "    return study\n",
    "\n",
    "study_results = RandomForestOptunaTuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(study_results.best_params) # Get best parameters for the objective function.\n",
    "print()\n",
    "pprint(study_results.best_value)  # Get best objective value.\n",
    "print()\n",
    "pprint(study_results.best_trial)  # Get best trial's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.822297Z",
     "iopub.status.busy": "2022-03-26T08:03:41.822021Z",
     "iopub.status.idle": "2022-03-26T08:03:41.832229Z",
     "shell.execute_reply": "2022-03-26T08:03:41.831237Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.822262Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_trial = study_results.best_trial.params\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.834515Z",
     "iopub.status.busy": "2022-03-26T08:03:41.834060Z",
     "iopub.status.idle": "2022-03-26T08:03:41.859859Z",
     "shell.execute_reply": "2022-03-26T08:03:41.859192Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.834477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trial results dataframe sorted from best value ascending\n",
    "ViewResultsAsDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.861308Z",
     "iopub.status.busy": "2022-03-26T08:03:41.860969Z",
     "iopub.status.idle": "2022-03-26T08:03:44.062901Z",
     "shell.execute_reply": "2022-03-26T08:03:44.062232Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.861270Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualize parameter importance\n",
    "optuna.visualization.plot_param_importances(study_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Random Forest Score With Optuna Hyperparameters</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelrf2():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    modelrf = other_models(X, y)\n",
    "    modelrf.osample()\n",
    "    modelrf.split_data(0.7)\n",
    "    \n",
    "    modelrf.X, modelrf.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    modelrf.prep_run_model(\"Metrics : Random Forest Classifier\",\n",
    "                            modelname='rfc', hparams = best_trial)\n",
    "\n",
    "RunModelrf2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Once again, Optuna helped us get parameters that improved the score.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del study_results, best_trial\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>RandomizedSearchCV</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Below is a reference on using a <b>RandomizedSearchCV</b> first for Random Forest hyperparameter tuning.<br><br>\n",
    "  Once done, one would have randomly narrowed down some parameters which we can base our inputs for a full <b>GridSearchCV</b> (not shown here).\n",
    "    <br><br>\n",
    "    Both approaches take an <b>extremely long time to run</b> using our SBA dataset, and the line to run the task is commented out.  Uncomment if you want to try.  Otherwise, <b>Optuna</b> is a much faster method.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ViewDefaultRFCParams():\n",
    "    rf = RandomForestClassifier(random_state = 48)\n",
    "    # Look at parameters used by our current forest\n",
    "    print('Default parameters in use:\\n')\n",
    "    pprint(rf.get_params())\n",
    "\n",
    "ViewDefaultRFCParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def SuggestRFCParams():\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 500, stop = 2000, num = 3)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(6, 15, num = 4)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    pprint(random_grid)\n",
    "    return random_grid\n",
    "\n",
    "random_grid = SuggestRFCParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RandomSearchCV(random_grid):\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    modelrf = other_models(X, y)\n",
    "    modelrf.osample()\n",
    "    modelrf.split_data(0.7)\n",
    "    \n",
    "    X_train, y_train = modelrf.X_train, modelrf.y_train\n",
    "    \n",
    "    del X, y, modelrf\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
    "                                   n_iter = 5, cv = 3, verbose=10, random_state=48)\n",
    "\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    return rf_random.best_params_\n",
    "\n",
    "#rf_best_params = RandomSearchCV(random_grid)\n",
    "#rf_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del random_grid #,rf_best_params \n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
