{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;a:link{color: white}\">\n",
    "    <h1 style='color:GhostWhite;'>Part 1: Should This Loan be Approved or Denied ?</h1>\n",
    "\n",
    "An XGBoost v1.6+ data model to predict whether a loan can be approved or denied.\n",
    "\n",
    "Optuna hyperparameter tuning for the XGBoost model is in Part 2 => <a style=\"color:yellow\" href=\"https://www.kaggle.com/code/josephramon/sba-optuna-xgboost-random-forest\">Part 2</a><br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">  \n",
    "    <b>Dataset Source</b><br>\n",
    "    <a href=\"https://www.kaggle.com/mirbektoktogaraev/should-this-loan-be-approved-or-denied\">U.S. Small Business Administration (SBA) Dataset</a> - all information about the dataset can be found at this link<br><br>    \n",
    "\n",
    "<b>Related Notebooks:</b><br>\n",
    "    <a href= \"https://www.kaggle.com/code/josephramon/sba-optuna-xgboost-random-forest\">Part 2: SBA Optuna XGBoost, Random Forest</a><br>\n",
    "    <a href= \"https://www.kaggle.com/code/josephramon/sba-keras-binary-classification-and-optuna\">Part 3: SBA Keras Binary Classification, Optuna, Keras Tuner</a><br><br>\n",
    "If interested, Data Exploratory Visualization in Tableau for this dataset can also be seen at :<br>\n",
    "    <a href= \"https://public.tableau.com/app/profile/joseph8038/viz/SBADatasetVisualizationandAnalysis/SBADatasetVisualizationandAnalysis-StoryBoard\">SBA Data Exploratory Visualization in Tableau</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"color:DarkSlateBlue\">\n",
    "This notebook is divided into 2 main parts:<br>\n",
    "<ul>\n",
    "<li><a style=\"color:DarkSlateGrey;\" href=\"#part1\"><b>1. Pipeline</b></a> - this is the end result encapsulated into a pipeline</li><br>\n",
    "<li><a style=\"color:DarkSlateGrey\" href=\"#part2\"><b>2. Data Exploration (EDA) and Preparation, Modeling, Metrics</b></a> - from start to end, with some notes</li>\n",
    "</ul>\n",
    "\"Our model results are way more dependent on how well feature engineering is performed than on the model itself. Machine Learning models are like very skilled linguists that can decipher any text in any language. However, it will not be helpful if they are handed a bunch of scribbles or blurred out text. EDA should not be skipped, as a thorough EDA and feature engineering process accounts for 90% of the results of a good model.\"<br><br>\n",
    "One method of avoiding memory leaks is doing processing inside a function. It creates a new scope for the intermediate variables and removes them automatically when the interpreter exits the function; hence, most of the code below are encapsulated into functions for this purpose. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"color:DarkSlateBlue\">\n",
    "<b>Evaluation Metrics:</b><br><br>\n",
    "<b>Our dataset is imbalanced</b> with regards to the target feature, a ratio of about 4.6:1.  One approach to correct this is to resample data, either undersample or oversample.  We will demonstate an example using undersampling where the metric we will evaluate is <b>accuracy</b>, but most of the rest will be oversampling.<br><br>\n",
    "    When we oversample, the main metric that we will evaluate is the <b>f1_score</b>, and look into <b>precision, recall sensitivity, and recall specificity</b> as well.<br><br>\n",
    "What costs more for the business, the model being wrong about granting loans, or wrong about denying loans ?<br><br>\n",
    "I think it would be more preferable to have a <b>high precision and recall sensitivity, and consequently a high f1_score</b>, where the <b>model predicts a loan to be approved</b> (positive class).  There will be false positives of course, but it will be minimized to a small percentage, and confidence that the model is correct is higher.\n",
    "<br><br>\n",
    "When the model flags a loan as \"deny\", whether a valid prediction or a false negative, it will be reviewed further anyway.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "<h2>Table Of Contents</h2>\n",
    "<ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#paths_and_flags\">Paths and Flags</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#libraries\">Libraries</a></li>   \n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#custom_functions\">Custom Functions</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#custom_classes\">Custom Classes</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#xgboost_class\">XGBoost Class</a></li>\n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part1\">Part 1. PipeLine</a></li>\n",
    "    <ul>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#pl_classes\">Pipeline Classes</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#load_pl_df\">Load Dataset for PipeLine</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#pl_run\">Run the pipeline</a></li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part2\">Part 2. Data Exploration and Preparation, Modeling, Metrics</a></li>\n",
    "    <ul>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#de_load_df\">Load Dataset</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#dep\">Data Exploration / Preparation</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#build_model\">Build Model Using XGBoost</a></li>\n",
    "        <ul>\n",
    "            <li><a style=\"color:DarkSlateGrey\" href=\"#model1\">Model v1</a></li>\n",
    "            <li><a style=\"color:DarkSlateGrey\" href=\"#model2\">Model v2 : Undersample</a></li>\n",
    "            <li><a style=\"color:DarkSlateGrey\" href=\"#model3\">Model v3 : Oversample</a></li>\n",
    "        </ul>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#test_model\">Test Model</a></li>\n",
    "        <ul>\n",
    "            <li><a style=\"color:DarkSlateGrey\" href=\"#test_test_dataset\">Test Model With Test Dataset</a></li>\n",
    "           <li><a style=\"color:DarkSlateGrey\" href=\"#test_user_input\">Test Model With User Input</a></li>\n",
    "        </ul>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#mutual_info\">Mutual Information Scores</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#trim_datasets\">Trim Datasets</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#results1\">Full or Trimmed Dataset</a></li>\n",
    "    </ul>  \n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey;font-size:18px\" href=\"https://www.kaggle.com/code/josephramon/sba-optuna-xgboost-random-forest\" target=\"_blank\">Optuna Hyperparameter Tuning - <i style='font-size:13px'>this will open a new browser tab</i></a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"paths_and_flags\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Paths and Flags</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:52:36.016235Z",
     "iopub.status.busy": "2022-06-06T17:52:36.015882Z",
     "iopub.status.idle": "2022-06-06T17:52:36.031905Z",
     "shell.execute_reply": "2022-06-06T17:52:36.030679Z",
     "shell.execute_reply.started": "2022-06-06T17:52:36.016206Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "'''\n",
    "kaggle_flag :\n",
    "   0 - if running outside Kaggle (e.g. Jupyter Notebook), change inputdir & workdir to your \n",
    "       own path\n",
    "   1 - if running as a Kaggle notebook\n",
    "'''\n",
    "# Change this logic to your own if needed\n",
    "if os.path.exists('../usr/lib/myfuncs/myfuncs.py'):\n",
    "    kaggle_flag = 1\n",
    "    print('Running a Kaggle notebook')\n",
    "else:\n",
    "    kaggle_flag = 0\n",
    "    print('Not running a Kaggle notebook')\n",
    "    \n",
    "# alert_flag - change to 0 for no sound alert, 1 for sound alert after long running cells\n",
    "alert_flag = 0\n",
    "\n",
    "# GPU is automatically detected if activated\n",
    "\n",
    "#---------------------------------------------------------------------------------------#\n",
    "\n",
    "if kaggle_flag == 1:             # Kaggle\n",
    "    inputdir  = \"../input/should-this-loan-be-approved-or-denied/\"\n",
    "    workdir  = \"./\"\n",
    "    final_ds  = '../input/sba-xgboost-model/sba_final.csv.feather'  \n",
    "    final_csv = '../input/sba-xgboost-model/sba_final.csv'          \n",
    "    functions_path = \"../usr/lib/myfuncs/myfuncs.py\"\n",
    "else:\n",
    "    inputdir  = \"C:\\\\Python\\\\Python_Data_Science_Exercises\\\\datasets\\\\\"\n",
    "    workdir  = \"C:\\\\Python\\\\Python_Data_Science_Exercises\\\\datasets\\\\\"\n",
    "    final_ds  = f'{workdir}sba_final.csv.feather'\n",
    "    final_csv = f'{workdir}sba_final.csv'\n",
    "    functions_path = 'C:\\\\Python\\\\Python_Data_Science_Exercises\\\\mylibs\\\\'\n",
    "\n",
    "audio_path=\"https://www.soundjay.com/misc/sounds/tablet-bottle-1.mp3\" # for alert\n",
    "\n",
    "print(f'kaggle_flag : {kaggle_flag}')\n",
    "print(f'alert_flag  : {alert_flag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"libraries\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Libraries</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:52:36.036933Z",
     "iopub.status.busy": "2022-06-06T17:52:36.034488Z",
     "iopub.status.idle": "2022-06-06T17:53:23.021806Z",
     "shell.execute_reply": "2022-06-06T17:53:23.020873Z",
     "shell.execute_reply.started": "2022-06-06T17:52:36.036867Z"
    }
   },
   "outputs": [],
   "source": [
    "# to be able to use clear_output(wait=True)\n",
    "from IPython.display import clear_output \n",
    "\n",
    "def install_packages():\n",
    "    print('Please wait, package installations started, if needed')\n",
    "    libs = ['scikit-learn', 'seaborn', 'numpy','matplotlib', 'tensorflow','torch','joblib',\n",
    "            'psutil','imbalanced-learn','xgboost','pyttsx3', 'pandas-profiling','sweetviz']\n",
    "    \n",
    "    piplist = !pip3 list\n",
    "    for i in range(len(libs)):\n",
    "        if not piplist.grep(libs[i]):\n",
    "            !pip3 install {libs[i]}\n",
    "        #\n",
    "        # Since XGBoost version must be at least 1.6 for our code to work properly, \n",
    "        # we upgrade it here if needed, before we import it\n",
    "        #\n",
    "        elif libs[i] == 'xgboost':\n",
    "            s = (piplist.grep('xgboost'))[0]\n",
    "            s = \" \".join(s.split())\n",
    "            ver = s.split(\" \")\n",
    "            if ver[1] < '1.6':\n",
    "                !pip3 install --upgrade xgboost\n",
    "            \n",
    "    clear_output(wait=True)\n",
    "    print('Package installations completed')\n",
    "\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:23.023945Z",
     "iopub.status.busy": "2022-06-06T17:53:23.023636Z",
     "iopub.status.idle": "2022-06-06T17:53:26.578996Z",
     "shell.execute_reply": "2022-06-06T17:53:26.577991Z",
     "shell.execute_reply.started": "2022-06-06T17:53:23.023883Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pyttsx3\n",
    "from IPython.display import Audio, display\n",
    "from IPython.display import FileLink\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import HTML\n",
    "import hashlib\n",
    "import copy                     # for deepcopy()\n",
    "import datetime as dt\n",
    "import gc\n",
    "from pandas_profiling import ProfileReport\n",
    "import sweetviz as sv\n",
    "import shutil\n",
    "import psutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import torch             # for clearing GPU cache\n",
    "from time import sleep\n",
    "import importlib\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "'''\n",
    "We can use these other packages for oversampling, or combined over/under sampling, \n",
    "but they are super slow with large datasets.  It will take 7 to 8 hours just for our \n",
    "X_train dataset\n",
    "''' \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "#from imblearn.over_sampling import ADASYN\n",
    "#from imblearn.combine import SMOTETomek\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "clear_output(wait=True)\n",
    "print('Package imports completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:26.581599Z",
     "iopub.status.busy": "2022-06-06T17:53:26.580778Z",
     "iopub.status.idle": "2022-06-06T17:53:35.433332Z",
     "shell.execute_reply": "2022-06-06T17:53:35.432218Z",
     "shell.execute_reply.started": "2022-06-06T17:53:26.581547Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This check is mainly for Kaggle which has an older version of XGBoost, as at Apr 2022\n",
    "\n",
    "XGBoost version should be at least 1.6.  From XGBoost 1.6, early_stopping_rounds and \n",
    "eval_metric are now under hyperparameters, and deprecated from fit() method.\n",
    "'''\n",
    "assert xgboost.__version__ >= '1.6',\\\n",
    "    \"XGBoost version must be at least 1.6. RESTART KERNEL if already upgraded.\"\n",
    "\n",
    "print(f'XGBoost __Version__ : {xgboost.__version__} is good.')\n",
    "print()\n",
    "!pip3 show xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"custom_functions\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Custom Functions</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:35.438693Z",
     "iopub.status.busy": "2022-06-06T17:53:35.438428Z",
     "iopub.status.idle": "2022-06-06T17:53:35.449552Z",
     "shell.execute_reply": "2022-06-06T17:53:35.448603Z",
     "shell.execute_reply.started": "2022-06-06T17:53:35.438654Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:35.452507Z",
     "iopub.status.busy": "2022-06-06T17:53:35.451275Z",
     "iopub.status.idle": "2022-06-06T17:53:40.684853Z",
     "shell.execute_reply": "2022-06-06T17:53:40.683893Z",
     "shell.execute_reply.started": "2022-06-06T17:53:35.452462Z"
    }
   },
   "outputs": [],
   "source": [
    "# import custom functions\n",
    "# rerun this cell if any changes are made to myfuncs.py during the current session\n",
    "\n",
    "if functions_path not in sys.path:\n",
    "    sys.path.append(functions_path)\n",
    "import myfuncs as mf\n",
    "importlib.reload(mf)      # in case changes were made to myfuncs during current session\n",
    "print('Custom functions import completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Some custom functions and classes in <a style=\"color:ForestGreen\" href=\"https://www.kaggle.com/code/josephramon/myfuncs\" target=\"_blank\">myfuncs.py</a></b>.  Not all are used in this notebook; and those used are called with a qualification \"<b>mf.</b>\".<br>  \n",
    "In Kaggle, myfuncs.py is set up as a <b>Utility Script</b> in /usr/lib<br>\n",
    "<ul>\n",
    "    <li>is_kaggle_gpu_enabled()</li>\n",
    "<li>clear_gpu(tree_method='gpu_hist')</li>\n",
    "<li>reduce_mem_usage(df, print_info = True, use_float16=False)</li>\n",
    "<li>runtime(rt1,rt2)</li>\n",
    "<li>create_download_link(title = \"Download \", filename = \"data.csv\")</li>\n",
    "<li>GetRam()</li>\n",
    "<li>convertFloatToDecimal(f=0.0, precision=2)</li>\n",
    "<li>formatFileSize(size, sizeIn, sizeOut, precision=0)</li>\n",
    "<li>check_cols_with_nulls(df)</li>\n",
    "<li>check_infinity_nan(df, dfname)</li>\n",
    "<li>fixvals(val)</li>\n",
    "<li>model_eval(y_valid,predictions, cmDisplay=False)</li>\n",
    "<li>model_eval2(model, X_train, y_train, X_testdata, y_testdata,\n",
    "    cmDisplay=False, prtstr = 'y_valid', multi_label = False)</li>\n",
    "<li>plot_features(booster, figsize)</li>\n",
    "<li>make_mi_scores(X, y)</li>\n",
    "<li>plot_mi_scores(scores)</li>\n",
    "<li>GetSweetVizReport(df, workdir, kaggle_flag)</li>\n",
    "<li>SetVoice(kaggle_flag)</li>\n",
    "<li>InitTPUStrategy()</li>\n",
    "<li>ZipDir(zippath)</li>\n",
    "<li>GetTimeZone()</li>\n",
    "<li>GetRatio(num1, num2)</li>\n",
    "<li>class color</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:40.686721Z",
     "iopub.status.busy": "2022-06-06T17:53:40.686397Z",
     "iopub.status.idle": "2022-06-06T17:53:40.693694Z",
     "shell.execute_reply": "2022-06-06T17:53:40.692232Z",
     "shell.execute_reply.started": "2022-06-06T17:53:40.686654Z"
    }
   },
   "outputs": [],
   "source": [
    "# ensure garbage collector is enabled\n",
    "(gc.isenabled() == False) and gc.enable();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:40.695730Z",
     "iopub.status.busy": "2022-06-06T17:53:40.694959Z",
     "iopub.status.idle": "2022-06-06T17:53:51.704232Z",
     "shell.execute_reply": "2022-06-06T17:53:51.703274Z",
     "shell.execute_reply.started": "2022-06-06T17:53:40.695683Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu_enabled = mf.is_kaggle_gpu_enabled()\n",
    "\n",
    "if gpu_enabled == False:\n",
    "    tree_method = 'hist'\n",
    "else:\n",
    "    tree_method = 'gpu_hist'\n",
    "\n",
    "del gpu_enabled\n",
    "gc.collect()\n",
    "\n",
    "sleep(5)\n",
    "clear_output(wait=True)\n",
    "tree_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:51.706324Z",
     "iopub.status.busy": "2022-06-06T17:53:51.705764Z",
     "iopub.status.idle": "2022-06-06T17:53:51.711372Z",
     "shell.execute_reply": "2022-06-06T17:53:51.710193Z",
     "shell.execute_reply.started": "2022-06-06T17:53:51.706263Z"
    }
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Set up voice object.  Used in different areas of notebook to indicate completion of long processes.\n",
    "'''\n",
    "engine = mf.SetVoice(kaggle_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rapids\n",
    "%time\n",
    "print('Please wait ... it takes time to set up rapids')\n",
    "!cp ../input/rapids/rapids.21.06 /opt/conda/envs/rapids.tar.gz\n",
    "!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n",
    "!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n",
    "clear_output(wait=True)\n",
    "print 'rapids environment has been set'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"custom_classes\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:PowderBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Custom Classes</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xgboost_class\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>XGBoost Class</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:51.714216Z",
     "iopub.status.busy": "2022-06-06T17:53:51.713596Z",
     "iopub.status.idle": "2022-06-06T17:53:51.759531Z",
     "shell.execute_reply": "2022-06-06T17:53:51.758079Z",
     "shell.execute_reply.started": "2022-06-06T17:53:51.714170Z"
    }
   },
   "outputs": [],
   "source": [
    "class process_model():  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_valid, self.X_test = None, None\n",
    "        self.y_valid, self.y_test = None, None\n",
    "        \n",
    "        self.xg_model = None\n",
    "\n",
    "        print(f'MIS_Status Count ->  1 : {Counter(y)[1]}, 0 : {Counter(y)[0]}')\n",
    "\n",
    "    def osample(self, print_info = True, os_data = [1,0,0], os_class = 'ros'):\n",
    "        '''\n",
    "        #Resampling method\n",
    "        os_data:\n",
    "            os_data[0] : 1 to resample train data; otherwise, 0 \n",
    "            os_data[1] : 1 to resample valid data; otherwise, 0\n",
    "            os_data[2] : 1 to resample test data; otherwise, 0\n",
    "        ''' \n",
    "        # oversample\n",
    "        if os_class == 'sm':\n",
    "            resample = SMOTE(sampling_strategy='minority', n_jobs = -1, random_state=48)\n",
    "        # combined over and under sampling\n",
    "        elif os_class == 'sme':\n",
    "            resample = SMOTEENN(sampling_strategy='minority', n_jobs = -1, random_state=48)\n",
    "        # undersample\n",
    "        elif os_class == 'rus':\n",
    "            resample = RandomUnderSampler(sampling_strategy='majority', random_state=48)\n",
    "        # oversample\n",
    "        else:\n",
    "            resample = RandomOverSampler(sampling_strategy='minority', random_state=48) \n",
    "        \n",
    "        rt1=dt.datetime.now()\n",
    "            \n",
    "        if print_info == True:\n",
    "            print()\n",
    "            print('X_train size : ', len(self.X_train))\n",
    "            print('X_valid size : ', len(self.X_valid))\n",
    "            print('X_test size  : ', len(self.X_test))\n",
    "            \n",
    "        # fit and apply the transform\n",
    "        print()\n",
    "        if os_data[0] == 1:\n",
    "            print(f'{mf.color.bdgreen}Please wait, resampling train data{mf.color.end}')\n",
    "            X_train_over, y_train_over = resample.fit_resample(self.X_train, self.y_train)\n",
    "            \n",
    "        if os_data[1] == 1:\n",
    "            print(f'{mf.color.bdgreen}Please wait, resampling valid data{mf.color.end}')\n",
    "            X_valid_over, y_valid_over = resample.fit_resample(self.X_valid, self.y_valid)\n",
    "            \n",
    "        if os_data[2] == 1:\n",
    "            print(f'{mf.color.bdgreen}Please wait, resampling test data{mf.color.end}')\n",
    "            X_test_over, y_test_over   = resample.fit_resample(self.X_test, self.y_test)\n",
    "\n",
    "        # summarize class distribution\n",
    "        if print_info == True:\n",
    "            if os_data[0] == 1:\n",
    "                print('\\nBefore Resampling train -> 1 : {}, 0 : {}'.format(\n",
    "                    Counter(self.y_train)[1], Counter(self.y_train)[0]))\n",
    "\n",
    "                print('After Resampling  train -> 1 : {}, 0 : {}'.format(\n",
    "                    Counter(y_train_over)[1], Counter(y_train_over)[0]))\n",
    "            if os_data[1] == 1:\n",
    "                print('\\nBefore Resampling valid -> 1 : {}, 0 : {}'.format(\n",
    "                    Counter(self.y_valid)[1], Counter(self.y_valid)[0]))\n",
    "\n",
    "                print('After Resampling  valid -> 1 : {}, 0 : {}'.format(\n",
    "                    Counter(y_valid_over)[1], Counter(y_valid_over)[0]))\n",
    "            if os_data[2] == 1:\n",
    "                print('\\nBefore Resampling test -> 1 : {}, 0 : {}'.format(\n",
    "                    Counter(self.y_test)[1], Counter(self.y_test)[0]))\n",
    "\n",
    "                print('After Resampling  test -> 1 : {}, 0 : {}'.format(\n",
    "                    Counter(y_test_over)[1], Counter(y_test_over)[0]))\n",
    "  \n",
    "        if os_data[0] == 1:\n",
    "            self.X_train, self.y_train = X_train_over, y_train_over\n",
    "            \n",
    "        if os_data[1] == 1:\n",
    "            self.X_valid, self.y_valid = X_valid_over, y_valid_over\n",
    "            \n",
    "        if os_data[2] == 1:\n",
    "            self.X_test, self.y_test   = X_test_over, y_test_over\n",
    "            \n",
    "        print(f'\\n{mf.color.bdblue}Resampling {mf.color.end}', end = '')\n",
    "        rt2=dt.datetime.now()\n",
    "        mf.runtime(rt1,rt2)\n",
    "        \n",
    "    # oversampling method\n",
    "    def osample_Xy(self, print_info = True, os_class = 'ros'):\n",
    "        print(f'{mf.color.bdgreen}Please wait, resampling data{mf.color.end}\\n')\n",
    "        # define oversampling strategy\n",
    "        if os_class == 'ros':\n",
    "            oversample = RandomOverSampler(sampling_strategy='minority') \n",
    "        else:\n",
    "            oversample = RandomUnderSampler(sampling_strategy='majority')\n",
    "            \n",
    "        if print_info == True:\n",
    "            print('X size : ', len(self.X))\n",
    "            print('y size : ', len(self.y))\n",
    "            \n",
    "        # fit and apply the transform\n",
    "        X_over, y_over = oversample.fit_resample(self.X, self.y)\n",
    "\n",
    "        # summarize class distribution\n",
    "        if print_info == True:\n",
    "            print(f'Before Resampling -> 1 : {Counter(self.y)[1]}, 0 : {Counter(self.y)[0]}')\n",
    "            print(f'After Resampling  -> 1 : {Counter(y_over)[1]}, 0 : {Counter(y_over)[0]}')\n",
    "        \n",
    "        # update X and y with the oversampled results \n",
    "        self.X = X_over\n",
    "        self.y = y_over\n",
    "    \n",
    "    def split_data(self, X_size = 0.7):   \n",
    "        # Split Data into Train:Validate:Test\n",
    "        \n",
    "        # train_size=X_size\n",
    "        # In the first step, we will split the data in training and remaining dataset\n",
    "        self.X_train, X_rem, self.y_train, y_rem = train_test_split(self.X, self.y,\n",
    "                                        stratify=self.y, train_size = X_size, random_state=48) \n",
    "\n",
    "        # Now since we want the valid and test size to be equal,\n",
    "        # we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "        # test_size = 0.5\n",
    "\n",
    "        self.X_valid, self.X_test, self.y_valid, self.y_test = train_test_split(X_rem,y_rem,\n",
    "                                        stratify=y_rem, test_size=0.5, random_state=48)\n",
    "        \n",
    "        return {'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                'X_test':self.X_test, 'y_test':self.y_test}\n",
    "    \n",
    "    def split_data2(self, X_size = 0.8):   \n",
    "        # Split Data into Train:Validate only\n",
    "        \n",
    "        # train_size=X_size\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(\n",
    "                self.X, self.y, stratify=self.y, train_size = X_size, random_state=48) \n",
    "        self.X_test, self.y_test = None, None\n",
    "\n",
    "        return {'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                'X_test':self.X_test, 'y_test':self.y_test}\n",
    "        \n",
    "    # Method to run model \n",
    "    # desc - description of metrics report\n",
    "    def prep_run_model(self, desc='Metrics', cmDisplay=False, PipeLine_flag = False,\n",
    "                hyperparams = {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6,\n",
    "                               'tree_method':tree_method, 'early_stopping_rounds':100,\n",
    "                               'eval_metric':['auc','error']},\n",
    "                               prt_acc = False):\n",
    "        \n",
    "        # from XGBoost 1.6, early_stopping_rounds and eval_metric are now under parameters,\n",
    "        # and deprecated from fit() method.\n",
    "        # The default hyperparameters are conservative, to help avoid overfitting\n",
    "        \n",
    "        print()\n",
    "        print(f\"{mf.color.bold}Please wait, Fitting model can take time ...{mf.color.end}\")\n",
    "        \n",
    "        '''\n",
    "        XGBRegressor is for continuous target/outcome variables. These are often called \n",
    "        \"regression problems.\"\n",
    "\n",
    "        XGBClassifier is for categorical target/outcome variables. These are often called \n",
    "        \"classification problems.\"\n",
    "        '''\n",
    "        \n",
    "        if PipeLine_flag == True:\n",
    "            # hyperparams is a result of Optuna hyperparameter tuning\n",
    "            # the hyperparameters lean towards being conservative to help avoid overfitting   \n",
    "            hyperparams = {  'tree_method': 'hist',\n",
    "                             'lambda': 0.0015806212781916517,\n",
    "                             'alpha': 0.02036885802457707,\n",
    "                             'gamma': 0,\n",
    "                             'colsample_bytree': 0.6,\n",
    "                             'subsample': 0.7,\n",
    "                             'learning_rate': 0.1,\n",
    "                             'n_estimators': 1000,\n",
    "                             'max_depth': 13,\n",
    "                             'random_state': 48,\n",
    "                             'min_child_weight': 1,\n",
    "                             'early_stopping_rounds': 100.0,\n",
    "                             'eval_metric': ['auc', 'error']}\n",
    "            \n",
    "        self.xg_model = XGBClassifier(**hyperparams,use_label_encoder =False)\n",
    "       \n",
    "        #eval_setparam = [(self.X_train, self.y_train), (self.X_valid, self.y_valid)]\n",
    "        eval_setparam = [(self.X_valid, self.y_valid)]\n",
    "        \n",
    "        self.xg_model.fit(self.X_train, self.y_train,  \n",
    "                     eval_set = eval_setparam,\n",
    "                     verbose=False)\n",
    "        \n",
    "        gc.collect()\n",
    "        mf.clear_gpu()\n",
    " \n",
    "        print(\"Fitting model completed.\")\n",
    "        print()\n",
    "        print('Preparing Predictions')\n",
    "    \n",
    "        # Get predictions\n",
    "        predictions = self.xg_model.predict(self.X_valid)\n",
    "    \n",
    "        print()\n",
    "        print(f'{mf.color.bdblue}{mf.color.underline}{desc}{mf.color.end}')\n",
    "\n",
    "        #eval_results = mf.model_eval(self.y_valid, predictions, cmDisplay)\n",
    "        eval_results = mf.model_eval2(self.xg_model,\n",
    "                                      self.X_train, self.y_train,\n",
    "                                      self.X_valid, self.y_valid,\n",
    "                                      cmDisplay=True, prt_acc = prt_acc)\n",
    "            \n",
    "        # Return these values as they may be needed for further testing or metrics\n",
    "        # in dictionary form to remember easier \n",
    "        return {'xg_model':self.xg_model,'predictions':predictions,\n",
    "                'X_train':self.X_train, 'y_train':self.y_train,\n",
    "                'X_valid':self.X_valid, 'y_valid':self.y_valid,\n",
    "                'X_test':self.X_test, 'y_test':self.y_test, 'eval_results':eval_results}\n",
    "    \n",
    "print('class process_model initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:51.762997Z",
     "iopub.status.busy": "2022-06-06T17:53:51.762226Z",
     "iopub.status.idle": "2022-06-06T17:53:51.784944Z",
     "shell.execute_reply": "2022-06-06T17:53:51.783464Z",
     "shell.execute_reply.started": "2022-06-06T17:53:51.762936Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('animation', html='html5')\n",
    "plt.figure(dpi=300)\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "print('Plotting defaults set up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 id=\"part1\" style='color:GhostWhite;'>Part 1. Pipeline</h1>\n",
    "This pipeline handles both X and y\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pl_classes\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>PipeLine Classes</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:51.787129Z",
     "iopub.status.busy": "2022-06-06T17:53:51.786768Z",
     "iopub.status.idle": "2022-06-06T17:53:51.831806Z",
     "shell.execute_reply": "2022-06-06T17:53:51.830564Z",
     "shell.execute_reply.started": "2022-06-06T17:53:51.787088Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "  \n",
    "class PL_Object():\n",
    "    def __init__(self,X,y):\n",
    "        #store X and Y\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "\n",
    "class PreProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,operation= 'X'):\n",
    "        self.operation=operation\n",
    "    @staticmethod\n",
    "    def enabled(**kwargs):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # check the parameters and return X and y inside the object\n",
    "        X_data=X.X\n",
    "        y_data=X.y\n",
    "        \n",
    "        print()\n",
    "        print(f'{mf.color.bdunl}PreProcessor initiated for {self.operation}{mf.color.end}')\n",
    "        \n",
    "        #  do some work and assign it back to the X object which contains both X and y data\n",
    "        if self.operation=='X':\n",
    "            '''\n",
    "            # NOTE: 'MIS_Status' is the target (y), but still in X, as we need to drop rows\n",
    "                    with NaNs. We cannot do it separately, as there will be a mismatch in count \n",
    "                    of rows.  At the end of this procedure, we separate the new target data from X \n",
    "                    and update y.\n",
    "            '''\n",
    "            \n",
    "            # Drop Na from rows\n",
    "            #---------------------\n",
    "            print(f'{mf.color.bdblue}Drop Na{mf.color.end}')\n",
    "            X_data.dropna(subset=['DisbursementDate', 'NewExist', 'City', 'State',\n",
    "                        'LowDoc', 'Name', 'NAICS', 'CreateJob', 'RetainedJob', 'FranchiseCode',\n",
    "                        'UrbanRural', 'NoEmp', 'Term', 'MIS_Status'], how='any', inplace=True)\n",
    "            \n",
    "            # drop invalid classifications\n",
    "            print('   Drop invalid classifications')\n",
    "            X_data = X_data[(X_data['LowDoc'] == 'Y') | (X_data['LowDoc'] == 'N')]\n",
    "            \n",
    "            X_data = X_data[(X_data['NewExist'] == 1) | (X_data['NewExist'] == 2)]   \n",
    "            \n",
    "            # Trim leading and trailing spaces\n",
    "            #---------------------------------\n",
    "            print('   Trim leading and trailing spaces, if any')\n",
    "            X_data['City'] = X_data['City'].str.strip()\n",
    "            \n",
    "            # Change dtype for columns needed for calculation or string extraction \n",
    "            #------------------------------------------------------------------------\n",
    "            print('{}Change dtype of columns used for calculation or string extraction{}'.format(\n",
    "                    mf.color.bdgreen, mf.color.end)\n",
    "                 )\n",
    "\n",
    "            X_data = X_data.astype({'DisbursementGross':np.float64,'SBA_Appv':np.float64,\n",
    "                              'GrAppv':np.float64, 'ChgOffPrinGr':np.float64,\n",
    "                              'NAICS':np.str_, 'NewExist':np.int8})\n",
    "            \n",
    "            # Drop Duplicate Rows\n",
    "            #------------------------------------------------------------------------\n",
    "            print(f'{mf.color.bdblue}Drop Duplicate Rows{mf.color.end}')\n",
    "            dupl_series = X_data.duplicated()\n",
    "            num_of_dupl = len(X_data[dupl_series == True])\n",
    "            if num_of_dupl > 0:\n",
    "                X_data.drop_duplicates(inplace=True)\n",
    "        \n",
    "            # Create New Features\n",
    "            #-----------------------\n",
    "            print(f'{mf.color.bdblue}Create New Features{mf.color.end}')\n",
    "            X_data['Industry'] = X_data['NAICS'].str[0:2]\n",
    "            X_data = X_data.astype({'Industry':np.int8})\n",
    "            \n",
    "            X_data['Recession'] = np.where((X_data['DisbursementDate'] >= '2007-09-01')\\\n",
    "                     & (X_data['DisbursementDate'] <= '2009-06-30'), 1, 0)\n",
    "            \n",
    "            X_data['RealEstate'] = np.where(X_data['Term'] >= 240, 1, 0)\n",
    "            \n",
    "            X_data['SBA_Portion']=(X_data['SBA_Appv']/X_data['GrAppv']) * 100\n",
    "            \n",
    "            X_data[\"CityState\"] = X_data[\"City\"] + \"_\" + X_data[\"State\"]\n",
    "            \n",
    "            print()\n",
    "            print(f\"X length = {len(X_data)}\")\n",
    "            print(f\"Y length = {len(X_data['MIS_Status'])}\")\n",
    "            \n",
    "            # Update X object\n",
    "            X.X = X_data                      # type DataFrame\n",
    "            X.y = X_data.pop('MIS_Status')    # type series\n",
    "            \n",
    "        elif self.operation=='y':\n",
    "            pass                      \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        #return modified X object\n",
    "        return X\n",
    "    \n",
    "\n",
    "class EncodeCategorical(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,operation= 'X'):\n",
    "        self.operation=operation\n",
    "    @staticmethod\n",
    "    def enabled(**kwargs):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # encode categorical features and return X and y inside the object\n",
    "        X_data=X.X\n",
    "        y_data=X.y\n",
    "        \n",
    "        print()\n",
    "        print('{}Encode Categorical Features initiated for {}{}'.format(\n",
    "                mf.color.bdunl, self.operation, mf.color.end)\n",
    "             )\n",
    "        \n",
    "        #  do some work and assign it back to the X object\n",
    "        if self.operation=='X':         \n",
    "            X_data['LowDoc'] = np.where((X_data['LowDoc'] == 'Y'), 1, 0)\n",
    "            \n",
    "            len_data=len(X_data)\n",
    "            #cols_to_drop = []\n",
    "            hash_constant = 900000   # fixed value so we can programmatically reproduce the hash\n",
    "            #for col in X_data.columns:\n",
    "            for col in X_data[['State','CityState']]:\n",
    "                if X_data[col].dtype == 'object':\n",
    "                    print(f'Column {col} has {X_data[col].nunique()} values among {len_data}')\n",
    "\n",
    "                    if X_data[col].nunique() < 25:\n",
    "                        print(f'One-hot encoding of {col}')\n",
    "                        one_hot_cols = pd.get_dummies(X_data[col])\n",
    "                        for ohc in one_hot_cols.columns:\n",
    "                            X_data[col + '_' + ohc] = one_hot_cols[ohc]\n",
    "                    else:\n",
    "                      print(f'Hashing of {col}')\n",
    "                      X_data[col + '_hash'] = X_data[col].apply(lambda row: int(hashlib.sha1((col +\\\n",
    "                                \"_\" + str(row)).encode('utf-8')).hexdigest(), 16) % hash_constant)\n",
    "\n",
    "            X.X = X_data\n",
    "            \n",
    "        elif self.operation=='y':\n",
    "            y_data = np.where(y_data == 'P I F', 1, 0)\n",
    "            \n",
    "            y_data = y_data.astype(np.int8)\n",
    "            \n",
    "            # convert back to series\n",
    "            y_data = pd.Series(y_data)\n",
    "\n",
    "            X.y = y_data                      \n",
    "        else:\n",
    "            pass\n",
    "        #return modified X\n",
    "        return X    \n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,operation= 'X'):\n",
    "        self.operation=operation\n",
    "    @staticmethod\n",
    "    def enabled(**kwargs):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_data=X.X\n",
    "        \n",
    "        print()\n",
    "        print(f'{mf.color.bdunl}Drop Columns initiated for {self.operation}{mf.color.end}')\n",
    "        \n",
    "        #  do some work and assign it back to the X object\n",
    " \n",
    "        # Dropping 'City' as 'CityState_hash' is more ideal\n",
    "        # Zip code has invalid values like 1, 2.  If we pad 0000 to 1, it's still not correct,\n",
    "        # as state should be Alaska. Zip code 1 is different states in the dataset\n",
    "        cols_to_drop = ['LoanNr_ChkDgt', 'Zip', 'Bank', 'BankState', 'ApprovalDate',\n",
    "                        'ApprovalFY', 'ChgOffDate', 'BalanceGross', 'NAICS', 'ChgOffPrinGr',\n",
    "                        'Name', 'RevLineCr', 'DisbursementDate', 'City', 'State', 'CityState',\n",
    "                        'GrAppv']\n",
    "\n",
    "        X_data.drop(columns=cols_to_drop, inplace=True)\n",
    "            \n",
    "        print()\n",
    "        print('Unneeded Columns Dropped')\n",
    "        \n",
    "        # reduce mem usage of X_data as final step\n",
    "        X_data = mf.reduce_mem_usage(X_data)\n",
    "        \n",
    "        print()\n",
    "        print(X_data.info())\n",
    "\n",
    "        X.X = X_data\n",
    "            \n",
    "        #return modified X\n",
    "        return X    \n",
    "\n",
    "class XGBoost(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,operation= 'X'):\n",
    "        self.operation=operation\n",
    "    @staticmethod\n",
    "    def enabled(**kwargs):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_data=X.X\n",
    "        y_data=X.y\n",
    "        \n",
    "        print(f'\\n{mf.color.bdunl}XGBoost initiated{mf.color.end}')\n",
    "        \n",
    "        # Get predictions using training and validation data\n",
    "        xgp = process_model(X_data, y_data)\n",
    "        xgp.split_data(0.7)\n",
    "        xgp.osample(os_data=[1,0,0])\n",
    "        \n",
    "        xgp_results = xgp.prep_run_model(\"Train/Valid Data Metrics\",\n",
    "                                        cmDisplay=True, PipeLine_flag = True)   \n",
    "        \n",
    "        #Test with unseen data\n",
    "        print('\\n\\n{}{}Test With Unseen Data X_test and y_test{}'.format(\n",
    "                mf.color.bdblue, mf.color.bdunl, mf.color.end))\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = xgp.xg_model.predict(xgp.X_test)\n",
    "        #cmv = mf.model_eval(xgp.y_test, predictions)\n",
    "        cmv = mf.model_eval2(xgp.xg_model,\n",
    "                             xgp.X_train, xgp.y_train,\n",
    "                             xgp.X_test, xgp.y_test,\n",
    "                             cmDisplay=True, prtstr = 'y_test')\n",
    "            \n",
    "        '''\n",
    "        A dictionary is returned, and its values can be used outside the pipeline if needed\n",
    "        \n",
    "        {'xg_model':xg_model,'predictions':predictions,\n",
    "                    'X_train':X_train, 'y_train':y_train,\n",
    "                    'X_valid':X_valid, 'y_valid':y_valid,\n",
    "                    'X_test':X_test, 'y_test':y_test, 'cmv':cmv}\n",
    "        '''\n",
    "        joblib.dump(xgp_results, f\"{workdir}pipeline_results.dict\")   \n",
    "        \n",
    "        return xgp_results\n",
    "\n",
    "print('Pipeline classes initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_pl_df\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Load Dataset for PipeLine</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:53:51.834459Z",
     "iopub.status.busy": "2022-06-06T17:53:51.833783Z",
     "iopub.status.idle": "2022-06-06T17:54:06.932829Z",
     "shell.execute_reply": "2022-06-06T17:54:06.931963Z",
     "shell.execute_reply.started": "2022-06-06T17:53:51.834381Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Loading dataset ...')\n",
    "X = pd.read_csv(f'{inputdir}SBAnational.csv',\n",
    "                 converters = {'DisbursementGross':mf.fixvals,'SBA_Appv':mf.fixvals,\n",
    "                              'GrAppv':mf.fixvals, 'ChgOffPrinGr':mf.fixvals},\n",
    "                              parse_dates=['DisbursementDate'], low_memory=False)\n",
    "#X = X.head(500)      # uncomment for testing\n",
    "print(\"Shape of original SBA dataset : \", X.shape)\n",
    "print()\n",
    "display(X.info(memory_usage = 'deep'))\n",
    "print()\n",
    "display(X[['DisbursementGross','SBA_Appv','GrAppv','ChgOffPrinGr','DisbursementDate']].head(2))\n",
    "\n",
    "# Filter data to before 2011\n",
    "X = X[X['DisbursementDate'] <= '2010-12-31']\n",
    "\n",
    "print()\n",
    "print(f\"Size of data after 2010-12-31 : \\\n",
    "    {len(X[X['DisbursementDate'] > '2010-12-31'])}\")\n",
    "print()\n",
    "print(f\"Size of data before 2011 : \\\n",
    "    {len(X[X['DisbursementDate'] < '2011-01-01'])}\")\n",
    "\n",
    "'''\n",
    "X still contains the target 'MIS_Status', as we have to drop rows \n",
    "with NaNs in the pipeline. \"MIS_Status\" will be separated from X later in the pipeline\n",
    "\n",
    "Select target - y is initialized as it goes into the pipeline, but will be updated in the pipeline \n",
    "after preprocessing.  Others preprocess y outside the pipeline; here, y will be preprocessed in\n",
    "the pipeline.\n",
    "'''\n",
    "y = X['MIS_Status']\n",
    "\n",
    "print(f\"MIS_Status Count ->  P I F: {Counter(y)['P I F']}, CHGOFF: {Counter(y)['CHGOFF']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pl_run\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Run the pipeline</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T17:54:06.943836Z",
     "iopub.status.busy": "2022-06-06T17:54:06.941278Z",
     "iopub.status.idle": "2022-06-06T18:00:49.932279Z",
     "shell.execute_reply": "2022-06-06T18:00:49.931131Z",
     "shell.execute_reply.started": "2022-06-06T17:54:06.943793Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunPipeLine():\n",
    "    rt1=dt.datetime.now()\n",
    "    #Assign X and y to the object\n",
    "    My_Object=PL_Object(X,y)\n",
    "\n",
    "    #Build a simple pipeline\n",
    "    My_Pipeline=Pipeline([('X Prep',PreProcessor('X')),\n",
    "                          ('X EnCat',EncodeCategorical('X')),\n",
    "                          ('y EnCat',EncodeCategorical('y')),\n",
    "                          ('DropCols',DropColumns()),\n",
    "                          ('XGBoost',XGBoost())\n",
    "                         ])\n",
    "\n",
    "    My_Object=My_Pipeline.transform(My_Object)\n",
    "\n",
    "    print()\n",
    "    print('{}These results were obtained using hyperparameters from Optuna tuning{}'.format(\n",
    "            mf.color.bdred, mf.color.end))\n",
    "    \n",
    "    print()\n",
    "    print(f'{mf.color.bold}Pipeline Process Completed.{mf.color.end}')\n",
    "\n",
    "    rt2=dt.datetime.now()\n",
    "    mf.runtime(rt1,rt2)\n",
    "    print()\n",
    "    \n",
    "    del My_Pipeline\n",
    "    gc.collect()\n",
    "    \n",
    "    return My_Object        # for further usage below\n",
    "    \n",
    "MyObject = RunPipeLine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"color:DarkSlateBlue\">\n",
    "    <b>Just for informative reasons</b>, below shows how we can use data (dictionary) passed back by the pipeline to My_Object\n",
    "    </div>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:00:49.942351Z",
     "iopub.status.busy": "2022-06-06T18:00:49.938959Z",
     "iopub.status.idle": "2022-06-06T18:00:51.378786Z",
     "shell.execute_reply": "2022-06-06T18:00:51.377935Z",
     "shell.execute_reply.started": "2022-06-06T18:00:49.942299Z"
    }
   },
   "outputs": [],
   "source": [
    "def obj_sample_usage():\n",
    "    # here, you can load the saved results too\n",
    "    #MyObject = joblib.load(f\"{workdir}pipeline_results.dict\")\n",
    "    print(MyObject.keys())\n",
    "    pl_model = MyObject['xg_model']\n",
    "    x=mf.plot_features(pl_model, (8,7))\n",
    "    print()\n",
    "    MyObject['X_train'].info()\n",
    "    \n",
    "obj_sample_usage()\n",
    "\n",
    "# clear some variables from memory\n",
    "del X, y\n",
    "del MyObject\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:00:51.381303Z",
     "iopub.status.busy": "2022-06-06T18:00:51.380133Z",
     "iopub.status.idle": "2022-06-06T18:00:51.387446Z",
     "shell.execute_reply": "2022-06-06T18:00:51.386504Z",
     "shell.execute_reply.started": "2022-06-06T18:00:51.381241Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"SBA Machine Learning PipeLine completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 style='color:GhostWhite;'>Part 2 : Data Exploration and Preparation, Modeling, Metrics</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"de_load_df\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h3 style='color:GhostWhite;'>1. Load Dataset</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:00:51.390983Z",
     "iopub.status.busy": "2022-06-06T18:00:51.389783Z",
     "iopub.status.idle": "2022-06-06T18:01:01.108622Z",
     "shell.execute_reply": "2022-06-06T18:01:01.107651Z",
     "shell.execute_reply.started": "2022-06-06T18:00:51.390810Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Loading dataset ...')\n",
    "sba = pd.read_csv(f'{inputdir}SBAnational.csv', low_memory=False)\n",
    "\n",
    "display(sba.info(memory_usage = 'deep'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dep\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2. Data Exploration / Preparation</h2><br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Reload dataset with some conversion</b><br>\n",
    "    After review, decided to reload dataset with conversion of some features that may be needed for calculation.  It could be done after loading, but this is for instructive purposes on how it's done.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:01:01.111031Z",
     "iopub.status.busy": "2022-06-06T18:01:01.110413Z",
     "iopub.status.idle": "2022-06-06T18:01:14.249687Z",
     "shell.execute_reply": "2022-06-06T18:01:14.248538Z",
     "shell.execute_reply.started": "2022-06-06T18:01:01.110957Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Loading dataset ...')\n",
    "sba = pd.read_csv(inputdir + 'SBAnational.csv',\n",
    "                 converters = {'DisbursementGross':mf.fixvals,'SBA_Appv':mf.fixvals,\n",
    "                              'GrAppv':mf.fixvals, 'ChgOffPrinGr':mf.fixvals},\n",
    "                              parse_dates=['DisbursementDate'],\n",
    "                              low_memory=False)\n",
    "\n",
    "# Convert dtype of some columns that will be used in calculation or string extraction\n",
    "sba = sba.astype({'DisbursementGross':np.float64,'SBA_Appv':np.float64,\n",
    "                              'GrAppv':np.float64, 'ChgOffPrinGr':np.float64, 'NAICS':np.str_})\n",
    "\n",
    "print(sba.info(memory_usage = 'deep'))\n",
    "sba.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conv_dtype\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.1 EDA Tools</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SweetViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:01:14.252201Z",
     "iopub.status.busy": "2022-06-06T18:01:14.251364Z",
     "iopub.status.idle": "2022-06-06T18:04:35.051295Z",
     "shell.execute_reply": "2022-06-06T18:04:35.050203Z",
     "shell.execute_reply.started": "2022-06-06T18:01:14.252148Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "htmlpath = f'{workdir}SBA_sweetviz_report_before.html'\n",
    "mf.GetSweetVizReport(sba,htmlpath,kaggle_flag)\n",
    "\n",
    "print()\n",
    "(kaggle_flag == 1) and mf.create_download_link('Open SweetViz Report in browser ---> ',\\\n",
    "                                            f'{htmlpath}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Profiler\n",
    "- this seems to be buggy as at Apr 2022.  It may get fixed later, so run it anyway if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:04:35.053594Z",
     "iopub.status.busy": "2022-06-06T18:04:35.053145Z",
     "iopub.status.idle": "2022-06-06T18:18:33.185388Z",
     "shell.execute_reply": "2022-06-06T18:18:33.184278Z",
     "shell.execute_reply.started": "2022-06-06T18:04:35.053553Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For a better experience, the report is created as an html file that can be opened in a browser,\n",
    "and downloaded from there  (Save As ..., html)\n",
    "'''\n",
    "def GetPandasProfiling():\n",
    "    print(f'{mf.color.bdblue}Please wait ... Profiling Report will take some time.{mf.color.end}')\n",
    "\n",
    "    # uncomment if one wants to see the report in a cell below\n",
    "    # df.profile_report(title='SBA Pandas Profiling Report')\n",
    "\n",
    "    try:\n",
    "        df = sba.copy()\n",
    "        profile = df.profile_report(title='SBA Pandas Profiling Report', progress_bar=True,\n",
    "                                    correlations={\n",
    "                                        \"pearson\": {\"calculate\": True},\n",
    "                                        \"spearman\": {\"calculate\": True},\n",
    "                                        \"kendall\": {\"calculate\": False},\n",
    "                                        \"phi_k\": {\"calculate\": True}\n",
    "                                        })\n",
    "        profile.to_file(output_file = f'{workdir}SBA_Profiling_Report.html')\n",
    "        print(f'{mf.color.bdblue}Profiling Report completed.{mf.color.end}')\n",
    "        print()\n",
    "        print(f'SBA Profiling Report has been downloaded to path {workdir}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "\n",
    "GetPandasProfiling()\n",
    "\n",
    "#clear_output(wait=True)\n",
    "gc.collect()\n",
    "print()\n",
    "(kaggle_flag == 1) and mf.create_download_link('Open SBA Profiling Report in browser ---> ', \\\n",
    "                           f'{workdir}SBA_Profiling_Report.html');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"drop_rows_cols\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.2 Drop rows or columns if needed</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Check for na's in all columns, as well as invalid categories</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:18:33.188157Z",
     "iopub.status.busy": "2022-06-06T18:18:33.187493Z",
     "iopub.status.idle": "2022-06-06T18:19:06.362731Z",
     "shell.execute_reply": "2022-06-06T18:19:06.361794Z",
     "shell.execute_reply.started": "2022-06-06T18:18:33.188113Z"
    }
   },
   "outputs": [],
   "source": [
    "mf.check_cols_with_nulls(sba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:06.365484Z",
     "iopub.status.busy": "2022-06-06T18:19:06.364455Z",
     "iopub.status.idle": "2022-06-06T18:19:07.357779Z",
     "shell.execute_reply": "2022-06-06T18:19:07.356823Z",
     "shell.execute_reply.started": "2022-06-06T18:19:06.365439Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'{mf.color.bdunl}Features with NA values{mf.color.end}')\n",
    "sba.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The number of Na's in rows for the following features, with respect to the size of the database, are not many and can be dropped.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:07.360215Z",
     "iopub.status.busy": "2022-06-06T18:19:07.359689Z",
     "iopub.status.idle": "2022-06-06T18:19:08.565454Z",
     "shell.execute_reply": "2022-06-06T18:19:08.564457Z",
     "shell.execute_reply.started": "2022-06-06T18:19:07.360174Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.dropna(subset=['DisbursementDate', 'NewExist', 'City', 'State',\n",
    "                        'LowDoc', 'Name', 'NAICS', 'CreateJob', 'RetainedJob', 'FranchiseCode',\n",
    "                        'UrbanRural', 'NoEmp', 'Term', 'MIS_Status'], how='any', inplace=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:08.567294Z",
     "iopub.status.busy": "2022-06-06T18:19:08.566980Z",
     "iopub.status.idle": "2022-06-06T18:19:09.543866Z",
     "shell.execute_reply": "2022-06-06T18:19:09.542829Z",
     "shell.execute_reply.started": "2022-06-06T18:19:08.567254Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>RevLineCr</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:09.546084Z",
     "iopub.status.busy": "2022-06-06T18:19:09.545743Z",
     "iopub.status.idle": "2022-06-06T18:19:09.850105Z",
     "shell.execute_reply": "2022-06-06T18:19:09.848930Z",
     "shell.execute_reply.started": "2022-06-06T18:19:09.546043Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba[(sba['RevLineCr'] != 'Y') & (sba['RevLineCr'] != 'N')])\n",
    "# too many unknowns, we will drop 'RevlineCr' later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>LowDoc</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:09.852456Z",
     "iopub.status.busy": "2022-06-06T18:19:09.852139Z",
     "iopub.status.idle": "2022-06-06T18:19:10.078394Z",
     "shell.execute_reply": "2022-06-06T18:19:10.077076Z",
     "shell.execute_reply.started": "2022-06-06T18:19:09.852413Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba[(sba['LowDoc'] != 'Y') & (sba['LowDoc'] != 'N')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:10.080974Z",
     "iopub.status.busy": "2022-06-06T18:19:10.080083Z",
     "iopub.status.idle": "2022-06-06T18:19:11.243094Z",
     "shell.execute_reply": "2022-06-06T18:19:11.242170Z",
     "shell.execute_reply.started": "2022-06-06T18:19:10.080923Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='LowDoc',data=sba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **LowDoc seems to have a bearing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:11.246961Z",
     "iopub.status.busy": "2022-06-06T18:19:11.246057Z",
     "iopub.status.idle": "2022-06-06T18:19:11.875910Z",
     "shell.execute_reply": "2022-06-06T18:19:11.874919Z",
     "shell.execute_reply.started": "2022-06-06T18:19:11.246916Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can drop rows that are not 'Y' or 'N'\n",
    "sba = sba[(sba['LowDoc'] == 'Y') | (sba['LowDoc'] == 'N')]\n",
    "len(sba[(sba['LowDoc'] != 'Y') & (sba['LowDoc'] != 'N')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>NewExist</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:11.879067Z",
     "iopub.status.busy": "2022-06-06T18:19:11.877693Z",
     "iopub.status.idle": "2022-06-06T18:19:11.894941Z",
     "shell.execute_reply": "2022-06-06T18:19:11.893577Z",
     "shell.execute_reply.started": "2022-06-06T18:19:11.879007Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba[(sba['NewExist'] != 1) & (sba['NewExist'] != 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:11.897006Z",
     "iopub.status.busy": "2022-06-06T18:19:11.896658Z",
     "iopub.status.idle": "2022-06-06T18:19:12.276716Z",
     "shell.execute_reply": "2022-06-06T18:19:12.275833Z",
     "shell.execute_reply.started": "2022-06-06T18:19:11.896965Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='NewExist',data=sba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:12.278492Z",
     "iopub.status.busy": "2022-06-06T18:19:12.278179Z",
     "iopub.status.idle": "2022-06-06T18:19:12.506544Z",
     "shell.execute_reply": "2022-06-06T18:19:12.505189Z",
     "shell.execute_reply.started": "2022-06-06T18:19:12.278451Z"
    }
   },
   "outputs": [],
   "source": [
    "# records that are not 1 or 2, we can drop these rows as NewExist seems to have a bearing\n",
    "sba = sba[(sba['NewExist'] == 1) | (sba['NewExist'] == 2)]\n",
    "len(sba[(sba['NewExist'] != 1) & (sba['NewExist'] != 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:12.508826Z",
     "iopub.status.busy": "2022-06-06T18:19:12.508517Z",
     "iopub.status.idle": "2022-06-06T18:19:12.647397Z",
     "shell.execute_reply": "2022-06-06T18:19:12.646392Z",
     "shell.execute_reply.started": "2022-06-06T18:19:12.508783Z"
    }
   },
   "outputs": [],
   "source": [
    "sba = sba.astype({'NewExist':np.int8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>FranchiseCode</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:12.649712Z",
     "iopub.status.busy": "2022-06-06T18:19:12.649335Z",
     "iopub.status.idle": "2022-06-06T18:19:12.669382Z",
     "shell.execute_reply": "2022-06-06T18:19:12.668478Z",
     "shell.execute_reply.started": "2022-06-06T18:19:12.649637Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['FranchiseCode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>UrbanRural</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:12.671637Z",
     "iopub.status.busy": "2022-06-06T18:19:12.670691Z",
     "iopub.status.idle": "2022-06-06T18:19:12.687863Z",
     "shell.execute_reply": "2022-06-06T18:19:12.686953Z",
     "shell.execute_reply.started": "2022-06-06T18:19:12.671589Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['UrbanRural'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Term</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:12.690318Z",
     "iopub.status.busy": "2022-06-06T18:19:12.689191Z",
     "iopub.status.idle": "2022-06-06T18:19:13.128371Z",
     "shell.execute_reply": "2022-06-06T18:19:13.127492Z",
     "shell.execute_reply.started": "2022-06-06T18:19:12.690256Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sba[sba['Term'].isna()]))\n",
    "print(len(sba[sba['Term']==0]))\n",
    "print(len(sba[sba['Term']<0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:13.132247Z",
     "iopub.status.busy": "2022-06-06T18:19:13.131549Z",
     "iopub.status.idle": "2022-06-06T18:19:13.167554Z",
     "shell.execute_reply": "2022-06-06T18:19:13.166645Z",
     "shell.execute_reply.started": "2022-06-06T18:19:13.132199Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:13.170282Z",
     "iopub.status.busy": "2022-06-06T18:19:13.169762Z",
     "iopub.status.idle": "2022-06-06T18:19:13.539695Z",
     "shell.execute_reply": "2022-06-06T18:19:13.538740Z",
     "shell.execute_reply.started": "2022-06-06T18:19:13.170241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trim leading and trailing spaces\n",
    "sba['City'] = sba['City'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Check for na's in all columns</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:13.541631Z",
     "iopub.status.busy": "2022-06-06T18:19:13.541325Z",
     "iopub.status.idle": "2022-06-06T18:19:47.564754Z",
     "shell.execute_reply": "2022-06-06T18:19:47.563806Z",
     "shell.execute_reply.started": "2022-06-06T18:19:13.541591Z"
    }
   },
   "outputs": [],
   "source": [
    "mf.check_cols_with_nulls(sba)\n",
    "\n",
    "# We can ignore these, features to be dropped later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:47.567315Z",
     "iopub.status.busy": "2022-06-06T18:19:47.566478Z",
     "iopub.status.idle": "2022-06-06T18:19:47.575932Z",
     "shell.execute_reply": "2022-06-06T18:19:47.574864Z",
     "shell.execute_reply.started": "2022-06-06T18:19:47.567270Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:47.578475Z",
     "iopub.status.busy": "2022-06-06T18:19:47.577814Z",
     "iopub.status.idle": "2022-06-06T18:19:49.259874Z",
     "shell.execute_reply": "2022-06-06T18:19:49.259018Z",
     "shell.execute_reply.started": "2022-06-06T18:19:47.578432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save 2\n",
    "def Save2():\n",
    "    # for feather format, reset_index(drop=True) to prevent \"Unnamed column\" being created\n",
    "    sdf = sba.copy().reset_index(drop=True)\n",
    "    sdf.to_feather(f'{workdir}sba_save2.csv.feather')\n",
    "\n",
    "    # index=False to prevent \"Unnamed Column\" being created\n",
    "    #sba.to_csv(f'{workdir}sba_save2.csv', index=False)\n",
    "    \n",
    "    print(f'Saved to {workdir}sba_save2.csv.feather')\n",
    "\n",
    "Save2()\n",
    "\n",
    "# Short circuiting\n",
    "(kaggle_flag == 1) and FileLink(r'sba_save2.csv.feather');  # Kaggle only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"drop_duplicates\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.3 Drop Duplicate Rows</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:49.275209Z",
     "iopub.status.busy": "2022-06-06T18:19:49.272917Z",
     "iopub.status.idle": "2022-06-06T18:19:51.594155Z",
     "shell.execute_reply": "2022-06-06T18:19:51.592050Z",
     "shell.execute_reply.started": "2022-06-06T18:19:49.275154Z"
    }
   },
   "outputs": [],
   "source": [
    "def DropDuplicates():\n",
    "    dupl_series = sba.duplicated()\n",
    "    num_of_dupl = len(sba[dupl_series == True])\n",
    "    if num_of_dupl > 0:\n",
    "        print(f'Number of Duplicates : {mf.color.bold}{num_of_dupl}{mf.color.end}')\n",
    "        print()\n",
    "        print(sba[dupl_series].head(5))\n",
    "        sba.drop_duplicates(inplace=True)\n",
    "        print()\n",
    "        print(f'{mf.color.bold}{num_of_dupl}{mf.color.end} duplicate rows were dropped.')\n",
    "    else:\n",
    "        print(f'Duplicate rows found: {mf.color.bold}None{mf.color.end}')\n",
    "\n",
    "DropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_new_features\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.4 Create New Features</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Industry</b> - The industry sector is the 1st 2 digits of NAICS\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:51.596412Z",
     "iopub.status.busy": "2022-06-06T18:19:51.596090Z",
     "iopub.status.idle": "2022-06-06T18:19:52.286989Z",
     "shell.execute_reply": "2022-06-06T18:19:52.285958Z",
     "shell.execute_reply.started": "2022-06-06T18:19:51.596371Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['Industry'] = sba['NAICS'].str[0:2]\n",
    "sba = sba.astype({'Industry':np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:52.289043Z",
     "iopub.status.busy": "2022-06-06T18:19:52.288701Z",
     "iopub.status.idle": "2022-06-06T18:19:52.299676Z",
     "shell.execute_reply": "2022-06-06T18:19:52.298540Z",
     "shell.execute_reply.started": "2022-06-06T18:19:52.288986Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['Industry'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:52.302513Z",
     "iopub.status.busy": "2022-06-06T18:19:52.301553Z",
     "iopub.status.idle": "2022-06-06T18:19:52.318631Z",
     "shell.execute_reply": "2022-06-06T18:19:52.317592Z",
     "shell.execute_reply.started": "2022-06-06T18:19:52.302470Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['Industry'].unique()\n",
    "# There is an invalid industry shown which is '0', caused by blank NAICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:52.320387Z",
     "iopub.status.busy": "2022-06-06T18:19:52.319947Z",
     "iopub.status.idle": "2022-06-06T18:19:52.825959Z",
     "shell.execute_reply": "2022-06-06T18:19:52.824969Z",
     "shell.execute_reply.started": "2022-06-06T18:19:52.320341Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba[sba['Industry'] == 0])\n",
    "# This is a bummer, as industry sector has a big effect on a business, speaking as a business \n",
    "# domain expert.  Do we drop those with NAICS = 0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:52.827762Z",
     "iopub.status.busy": "2022-06-06T18:19:52.827384Z",
     "iopub.status.idle": "2022-06-06T18:19:52.859925Z",
     "shell.execute_reply": "2022-06-06T18:19:52.858836Z",
     "shell.execute_reply.started": "2022-06-06T18:19:52.827720Z"
    }
   },
   "outputs": [],
   "source": [
    "# At this stage, we leave it as is and treat it as unknown industry\n",
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:52.863072Z",
     "iopub.status.busy": "2022-06-06T18:19:52.862138Z",
     "iopub.status.idle": "2022-06-06T18:19:53.822559Z",
     "shell.execute_reply": "2022-06-06T18:19:53.821466Z",
     "shell.execute_reply.started": "2022-06-06T18:19:52.863029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if we can impute from the name.  For example, a bar (or similar) business\n",
    "sba[(sba['Name'].str.contains('bar',case=False)) & (sba['Industry'] == 0)]\\\n",
    "    [['Name','Industry']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's not feasible to impute missing Industry codes efficiently, so we abandon the idea.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Recession</b><br>\n",
    "We want to account for variation due to the Great Recession (December 2007 to June 2009). Should we separate the datasets into different time periods ? Before, During, and After ?  Let's check how large the sets are later.  In the meantime, we create a new feature, Recession, with 1 for 'Y' and 0 for 'N' depending on the DisbursementDate. \n",
    "<br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:53.830717Z",
     "iopub.status.busy": "2022-06-06T18:19:53.828221Z",
     "iopub.status.idle": "2022-06-06T18:19:53.835544Z",
     "shell.execute_reply": "2022-06-06T18:19:53.834408Z",
     "shell.execute_reply.started": "2022-06-06T18:19:53.830671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert \"DisbursementDate\" to datetime\n",
    "\n",
    "# sba['DisbursementDate'] = pd.to_datetime(sba['DisbursementDate'], format='%d-%b-%y')\n",
    "\n",
    "# sba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:53.837883Z",
     "iopub.status.busy": "2022-06-06T18:19:53.837473Z",
     "iopub.status.idle": "2022-06-06T18:19:53.857271Z",
     "shell.execute_reply": "2022-06-06T18:19:53.856292Z",
     "shell.execute_reply.started": "2022-06-06T18:19:53.837836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new column based on condition\n",
    "sba['Recession'] = np.where((sba['DisbursementDate'] >= '2007-09-01')\\\n",
    "                     & (sba['DisbursementDate'] <= '2009-06-30'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:53.859272Z",
     "iopub.status.busy": "2022-06-06T18:19:53.858907Z",
     "iopub.status.idle": "2022-06-06T18:19:54.170424Z",
     "shell.execute_reply": "2022-06-06T18:19:54.168515Z",
     "shell.execute_reply.started": "2022-06-06T18:19:53.859229Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Total - {len(sba)}')\n",
    "y = len(sba[sba['Recession'] == 1])\n",
    "n = len(sba[sba['Recession'] == 0])\n",
    "print(f'Recession - {y}')\n",
    "print(f'Not Recession - {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Real Estate</b><br>\n",
    "Loans backed by real estate will have terms 20 years or greater (≥240 months) and are the only loans granted for such a long term, whereas loans not backed by real estate will have terms less than 20 years ( < 240 months).<br><br>\n",
    "1 - Backed By Real Estate<br>\n",
    "0 - Not Backed By Real Estate<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:54.172442Z",
     "iopub.status.busy": "2022-06-06T18:19:54.172194Z",
     "iopub.status.idle": "2022-06-06T18:19:54.185179Z",
     "shell.execute_reply": "2022-06-06T18:19:54.183661Z",
     "shell.execute_reply.started": "2022-06-06T18:19:54.172410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new column based on condition\n",
    "sba['RealEstate'] = np.where(sba['Term'] >= 240, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:54.187715Z",
     "iopub.status.busy": "2022-06-06T18:19:54.187129Z",
     "iopub.status.idle": "2022-06-06T18:19:54.522717Z",
     "shell.execute_reply": "2022-06-06T18:19:54.521613Z",
     "shell.execute_reply.started": "2022-06-06T18:19:54.187669Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Total - {len(sba)}')\n",
    "y = len(sba[sba['RealEstate'] == 1])\n",
    "n = len(sba[sba['RealEstate'] == 0])\n",
    "print(f'Yes - {y}')\n",
    "print(f'No - {n}')\n",
    "print(f'Yes and No - {y+n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>SBA_Portion</b><br>\n",
    "The portion which is the percentage of the loan that is guaranteed by SBA. This is derived by calculating the ratio of the amount of the loan SBA guarantees and the gross amount approved by the bank (SBA_Appv/GrAppv) * 100.<br><br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:54.525308Z",
     "iopub.status.busy": "2022-06-06T18:19:54.524314Z",
     "iopub.status.idle": "2022-06-06T18:19:54.560325Z",
     "shell.execute_reply": "2022-06-06T18:19:54.559232Z",
     "shell.execute_reply.started": "2022-06-06T18:19:54.525262Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['SBA_Portion']=(sba['SBA_Appv']/sba['GrAppv']) * 100\n",
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CityState**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:54.562602Z",
     "iopub.status.busy": "2022-06-06T18:19:54.562251Z",
     "iopub.status.idle": "2022-06-06T18:19:55.211705Z",
     "shell.execute_reply": "2022-06-06T18:19:55.210801Z",
     "shell.execute_reply.started": "2022-06-06T18:19:54.562560Z"
    }
   },
   "outputs": [],
   "source": [
    "sba[\"CityState\"] = sba[\"City\"] + \"_\" + sba[\"State\"]\n",
    "sba[[\"CityState\", \"City\", \"State\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:55.213777Z",
     "iopub.status.busy": "2022-06-06T18:19:55.213440Z",
     "iopub.status.idle": "2022-06-06T18:19:55.242815Z",
     "shell.execute_reply": "2022-06-06T18:19:55.241405Z",
     "shell.execute_reply.started": "2022-06-06T18:19:55.213720Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:55.245688Z",
     "iopub.status.busy": "2022-06-06T18:19:55.244715Z",
     "iopub.status.idle": "2022-06-06T18:19:56.878843Z",
     "shell.execute_reply": "2022-06-06T18:19:56.877926Z",
     "shell.execute_reply.started": "2022-06-06T18:19:55.245624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save 3\n",
    "def Save3():\n",
    "    sdf = sba.copy().reset_index(drop=True)\n",
    "    sdf.to_feather(f'{workdir}sba_save3.csv.feather')\n",
    "\n",
    "    print(f'Saved to {workdir}sba_save3.csv.feather')\n",
    "    \n",
    "Save3()\n",
    "\n",
    "(kaggle_flag == 1) and FileLink(r'sba_save3.csv.feather');  # Kaggle only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"encode_cat\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.5 Encode Categorical Features</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:56.881076Z",
     "iopub.status.busy": "2022-06-06T18:19:56.880756Z",
     "iopub.status.idle": "2022-06-06T18:19:58.225992Z",
     "shell.execute_reply": "2022-06-06T18:19:58.224940Z",
     "shell.execute_reply.started": "2022-06-06T18:19:56.881048Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.select_dtypes([\"object\"]).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:Chocolate;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>MIS_Status</b><br>\n",
    "    This will be the <b>target</b> variable</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:58.228238Z",
     "iopub.status.busy": "2022-06-06T18:19:58.227395Z",
     "iopub.status.idle": "2022-06-06T18:19:59.499855Z",
     "shell.execute_reply": "2022-06-06T18:19:59.498845Z",
     "shell.execute_reply.started": "2022-06-06T18:19:58.228185Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "# Target variable is MIS Status, a categorical variable\n",
    "\n",
    "print(sba['MIS_Status'].value_counts())\n",
    "sns.countplot(x='MIS_Status',data=sba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    This shows a skewed distribution, where this bias in the target can influence many machine learning algorithms, leading some to ignore the minority class entirely, in this case, CHGOFF.  Before oversampling the data, will try as is.<br><br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:59.501519Z",
     "iopub.status.busy": "2022-06-06T18:19:59.501230Z",
     "iopub.status.idle": "2022-06-06T18:19:59.790566Z",
     "shell.execute_reply": "2022-06-06T18:19:59.788457Z",
     "shell.execute_reply.started": "2022-06-06T18:19:59.501479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update column based on condition\n",
    "sba['MIS_Status'] = np.where((sba['MIS_Status'] == 'P I F'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:59.799399Z",
     "iopub.status.busy": "2022-06-06T18:19:59.796828Z",
     "iopub.status.idle": "2022-06-06T18:19:59.831015Z",
     "shell.execute_reply": "2022-06-06T18:19:59.829463Z",
     "shell.execute_reply.started": "2022-06-06T18:19:59.799369Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sba['MIS_Status'].dtype)\n",
    "sba.head(2)[['City','MIS_Status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>LowDoc</b><br>\n",
    "'Y' = 1<br>\n",
    "'N' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:19:59.833700Z",
     "iopub.status.busy": "2022-06-06T18:19:59.832891Z",
     "iopub.status.idle": "2022-06-06T18:20:00.318773Z",
     "shell.execute_reply": "2022-06-06T18:20:00.317868Z",
     "shell.execute_reply.started": "2022-06-06T18:19:59.833642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update column based on condition\n",
    "sba['LowDoc'] = np.where((sba['LowDoc'] == 'Y'), 1, 0)\n",
    "\n",
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Others</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:20:00.324375Z",
     "iopub.status.busy": "2022-06-06T18:20:00.323295Z",
     "iopub.status.idle": "2022-06-06T18:20:05.099886Z",
     "shell.execute_reply": "2022-06-06T18:20:05.098971Z",
     "shell.execute_reply.started": "2022-06-06T18:20:00.324334Z"
    }
   },
   "outputs": [],
   "source": [
    "# will not hash 'City' as it is already covered by 'CityState'\n",
    "\n",
    "def HashCol():\n",
    "    cols_to_drop = []\n",
    "    hash_constant = 900000   # fixed value so we can programmatically reproduce the hash when needed\n",
    "    len_data=len(sba)\n",
    "    for col in sba[['State','CityState']]:\n",
    "        if sba[col].dtype == 'object':\n",
    "            print(f'Column {col} has {sba[col].nunique()} values among {len_data}')\n",
    "\n",
    "        if sba[col].nunique() < 25:\n",
    "            print(f'One-hot encoding of {col}')\n",
    "            one_hot_cols = pd.get_dummies(sba[col])\n",
    "            for ohc in one_hot_cols.columns:\n",
    "                sba[col + '_' + ohc] = one_hot_cols[ohc]\n",
    "        else:\n",
    "            print(f'Hashing of {col}')\n",
    "            sba[col + '_hash'] = sba[col].apply(lambda row: int(hashlib.sha1((col + \"_\" + \\\n",
    "                                    str(row)).encode('utf-8')).hexdigest(), 16) % hash_constant)\n",
    "\n",
    "        cols_to_drop.append(col)\n",
    "    print(cols_to_drop)\n",
    "\n",
    "HashCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:20:05.107365Z",
     "iopub.status.busy": "2022-06-06T18:20:05.104761Z",
     "iopub.status.idle": "2022-06-06T18:20:05.138344Z",
     "shell.execute_reply": "2022-06-06T18:20:05.135926Z",
     "shell.execute_reply.started": "2022-06-06T18:20:05.107325Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.head(2)[['State','CityState','State_hash','CityState_hash']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:20:05.140104Z",
     "iopub.status.busy": "2022-06-06T18:20:05.139710Z",
     "iopub.status.idle": "2022-06-06T18:20:06.404122Z",
     "shell.execute_reply": "2022-06-06T18:20:06.402986Z",
     "shell.execute_reply.started": "2022-06-06T18:20:05.140044Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>TimeFrame</b><br>\n",
    "Create a dataset for later use where we restrict the time frame to loans by excluding those disbursed after 2010 due to the fact the term of a loan is frequently 5 or more years.\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:20:06.406303Z",
     "iopub.status.busy": "2022-06-06T18:20:06.405419Z",
     "iopub.status.idle": "2022-06-06T18:20:07.329058Z",
     "shell.execute_reply": "2022-06-06T18:20:07.328087Z",
     "shell.execute_reply.started": "2022-06-06T18:20:06.406262Z"
    }
   },
   "outputs": [],
   "source": [
    "sba_bef_2011 = sba[sba['DisbursementDate'] <= '2010-12-31'].copy()\n",
    "len(sba_bef_2011[sba_bef_2011['DisbursementDate'] > '2010-12-31'])\n",
    "len(sba_bef_2011[sba_bef_2011['DisbursementDate'] <= '2011-01-01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Drop columns that are no longer needed<b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:20:07.331318Z",
     "iopub.status.busy": "2022-06-06T18:20:07.330774Z",
     "iopub.status.idle": "2022-06-06T18:20:07.686072Z",
     "shell.execute_reply": "2022-06-06T18:20:07.685160Z",
     "shell.execute_reply.started": "2022-06-06T18:20:07.331275Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['LoanNr_ChkDgt', 'Bank', 'BankState', 'ApprovalDate',\n",
    "                        'ApprovalFY', 'ChgOffDate', 'BalanceGross', 'NAICS', 'ChgOffPrinGr',\n",
    "                        'Name', 'RevLineCr', 'DisbursementDate', 'City', 'State', 'CityState',\n",
    "                         'GrAppv','Zip']\n",
    "\n",
    "sba_bef_2011.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "sba_bef_2011 = mf.reduce_mem_usage(sba_bef_2011)\n",
    "\n",
    "print()\n",
    "print('Unneeded Columns Dropped')\n",
    "print(sba_bef_2011.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Check for Infinite Values<b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:20:07.688358Z",
     "iopub.status.busy": "2022-06-06T18:20:07.687399Z",
     "iopub.status.idle": "2022-06-06T18:20:07.733578Z",
     "shell.execute_reply": "2022-06-06T18:20:07.732646Z",
     "shell.execute_reply.started": "2022-06-06T18:20:07.688316Z"
    }
   },
   "outputs": [],
   "source": [
    "mf.check_infinity_nan(sba_bef_2011,'sba_bef_2011')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Check Correlations</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:20:07.735770Z",
     "iopub.status.busy": "2022-06-06T18:20:07.735199Z",
     "iopub.status.idle": "2022-06-06T18:20:14.374692Z",
     "shell.execute_reply": "2022-06-06T18:20:14.373867Z",
     "shell.execute_reply.started": "2022-06-06T18:20:07.735696Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "fig, ax = plt.subplots(figsize=(20,20), dpi=300)\n",
    "# Set tick font size\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(15)\n",
    "g = sns.heatmap(\n",
    "    sba_bef_2011.corr(),\n",
    "    annot=True,\n",
    "    ax=ax,\n",
    "    cmap='OrRd',\n",
    "    cbar=False,\n",
    "    linewidth=1\n",
    ")\n",
    "\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eda_check\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.6 EDA Check</h2><br>\n",
    "    Here we generate a SweetViz report for another EDA review\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:20:14.376571Z",
     "iopub.status.busy": "2022-06-06T18:20:14.376128Z",
     "iopub.status.idle": "2022-06-06T18:21:38.191015Z",
     "shell.execute_reply": "2022-06-06T18:21:38.189861Z",
     "shell.execute_reply.started": "2022-06-06T18:20:14.376535Z"
    }
   },
   "outputs": [],
   "source": [
    "htmlpath = f'{workdir}SBA_sweetviz_report_after.html'\n",
    "mf.GetSweetVizReport(sba_bef_2011,htmlpath,kaggle_flag)\n",
    "\n",
    "print()\n",
    "(kaggle_flag == 1) and mf.create_download_link('Open SweetViz Report in browser ---> ',\\\n",
    "                                            f'{htmlpath}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:PowderBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Save Final Dataset<b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:21:38.193490Z",
     "iopub.status.busy": "2022-06-06T18:21:38.192753Z",
     "iopub.status.idle": "2022-06-06T18:21:43.719619Z",
     "shell.execute_reply": "2022-06-06T18:21:43.718263Z",
     "shell.execute_reply.started": "2022-06-06T18:21:38.193444Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "FINAL Dataset: We will save sba_bef_2011 as our final dataset\n",
    "'''\n",
    "def SaveFinalDF():\n",
    "    # Save sba_bef_2011\n",
    "    sdf = sba_bef_2011.copy().reset_index(drop=True)\n",
    "    sdf.to_feather(f'{workdir}sba_bef_2011.csv.feather')\n",
    "    print(f\"saved to {workdir}sba_bef_2011.csv.feather\")\n",
    "    \n",
    "    #sdf = pd.read_csv(f'{workdir}sba_bef_2011.csv')\n",
    "    #sdf.to_csv(f'{workdir}sba_final.csv', index=False)\n",
    "    \n",
    "    # copy to feather\n",
    "    src_file=f'{workdir}sba_bef_2011.csv.feather'\n",
    "    dst_file=f'{workdir}sba_final.csv.feather'\n",
    "    shutil.copy2(src_file, dst_file)\n",
    "    \n",
    "    #save to a csv copy as well\n",
    "    sdf.to_csv(f'{workdir}sba_final.csv', index=False)\n",
    "\n",
    "    print(f'Final Dataset saved as {workdir}sba_final.csv.feather and {workdir}sba_final.csv')\n",
    "\n",
    "SaveFinalDF()\n",
    "(kaggle_flag == 1) and FileLink(r'sba_final.csv.feather');  # Kaggle only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:21:43.723100Z",
     "iopub.status.busy": "2022-06-06T18:21:43.721209Z",
     "iopub.status.idle": "2022-06-06T18:21:50.256983Z",
     "shell.execute_reply": "2022-06-06T18:21:50.256033Z",
     "shell.execute_reply.started": "2022-06-06T18:21:43.723051Z"
    }
   },
   "outputs": [],
   "source": [
    "del sba_bef_2011\n",
    "gc.collect()\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_model\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3. Build Model Using XGBoost</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Early Stopping Rounds<b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"<b>Overfitting</b> is a problem with sophisticated non-linear learning algorithms like gradient boosting.  Early stopping is an approach to training complex machine learning models to avoid overfitting.\n",
    "<br><br>\n",
    "<b>XGBoost supports early stopping after a fixed number of iterations.</b>  In addition to specifying a metric and test dataset for evaluation in each epoch, one must specify a window of the number of epochs over which no improvement is observed. This is specified in the early_stopping_rounds parameter.\n",
    "<br><br>\n",
    "It is generally a good idea to select the early_stopping_rounds as a reasonable function of the total number of training epochs (10% in this case) or attempt to correspond to the period of inflection points as might be observed on plots of learning curves.\n",
    "<br><br> - <a href = \"https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/\">Avoid Overfitting By Early Stopping With XGBoost In Python</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model1\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3.1 Model v1</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:21:50.258671Z",
     "iopub.status.busy": "2022-06-06T18:21:50.258381Z",
     "iopub.status.idle": "2022-06-06T18:22:22.329411Z",
     "shell.execute_reply": "2022-06-06T18:22:22.328407Z",
     "shell.execute_reply.started": "2022-06-06T18:21:50.258620Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv1():\n",
    "    # Select subset of predictors\n",
    "    X = pd.read_feather(f'{workdir}sba_final.csv.feather')\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model1 = process_model(X, y)   # Initiate class\n",
    "    model1.split_data(0.7)         # Split data into train (70%), valid (15%), and test (15%)\n",
    "    \n",
    "    params = {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6,\n",
    "                               'tree_method':tree_method, 'early_stopping_rounds':100,\n",
    "                               'eval_metric':['auc','error']}\n",
    "    model1_results = model1.prep_run_model( \"Metrics : Full SBA Not Oversampled\",hyperparams=params)\n",
    "    return model1_results\n",
    "    \n",
    "model1_results = RunModelv1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "    Due to the imbalanced target data, the <b>Accuracy</b> metric is not suitable as it will favor the majority.  Instead, we use the <b>f1_score</b> metric, a balance of <b>precision</b> and <b>recall</b>.</b><br><br>\n",
    "The f1_score here is good.  One technique for correcting imbalanced data is resampling.  Is there a benefit to resample our training data to fix the imbalance ?  Let's see when we get to the Model v3 section below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model2\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3.2 Model v2</h2><br>\n",
    "    With Undersampling.  Here we <b>undersample before splitting data</b>, as we are not adding any synthetic data. Since data will no longer imbalanced, we can use the <b>Accuracy metric</b>.\n",
    "       </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:22:22.337732Z",
     "iopub.status.busy": "2022-06-06T18:22:22.335041Z",
     "iopub.status.idle": "2022-06-06T18:22:37.817050Z",
     "shell.execute_reply": "2022-06-06T18:22:37.814085Z",
     "shell.execute_reply.started": "2022-06-06T18:22:22.337680Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv2():\n",
    "    X = pd.read_feather(f'{workdir}sba_final.csv.feather')\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    model2 = process_model(X, y)\n",
    "    model2.osample_Xy(os_class = 'rus')        #undersample\n",
    "    model2.split_data(0.7)\n",
    "    \n",
    "    model2.X, model2.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    model2_results = model2.prep_run_model(\"Metrics : SBA Undersampled\", prt_acc = True)\n",
    "    \n",
    "    # save to files for reuse later\n",
    "    model2_results['xg_model'].save_model(f'{workdir}modelv2_undersampling.json')\n",
    "    joblib.dump(model2_results, f\"{workdir}model2_results.dict\")      \n",
    "  \n",
    "RunModelv2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset after undersampling has <b>154451</b> rows. In theory, this is supposed to be a good size after undersampling - i.e. 10's of thousands, even over a hundred thousand.  The scores can be considered as very good too.<br><br>\n",
    "However, we will implement oversampling too, and <b>use the whole dataset</b> in case some important insights were not included in the undersampled data.  At any rate, <b>we have saved this model</b> and can be used as a <b>backup model</b>, as well as a confirmation test for the next models which will be training oversampled data, especially with regards to <b>predictions for the minority class</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model3\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3.3 Model v3</h2><br>\n",
    "    With Oversampling\n",
    "       </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:31:28.291003Z",
     "iopub.status.busy": "2022-06-06T18:31:28.290286Z",
     "iopub.status.idle": "2022-06-06T18:32:16.610815Z",
     "shell.execute_reply": "2022-06-06T18:32:16.609853Z",
     "shell.execute_reply.started": "2022-06-06T18:31:28.290968Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv3():\n",
    "    X = pd.read_feather(f'{workdir}sba_final.csv.feather')\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    model3 = process_model(X, y)\n",
    "    model3.split_data(0.7)\n",
    "    model3.osample(os_data=[1,0,0])\n",
    "    \n",
    "    model3.X, model3.y = None, None\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "  \n",
    "    model3_results = model3.prep_run_model(\"Metrics : SBA Oversampled\")\n",
    "    \n",
    "    # save to files for reuse later\n",
    "    model3_results['xg_model'].save_model(f'{workdir}modelv3.json')\n",
    "    joblib.dump(model3_results, f\"{workdir}model3_results.dict\")      \n",
    "    \n",
    "    return model3_results\n",
    "  \n",
    "model3_results = RunModelv3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "After oversampling, our f1_score is now lower than when not oversampled.  However, precision is now much higher, giving us <b>more confidence that the model is now better at predicting loans that will be approved</b>. This is what we want.  Even recall specificity, or True Negative Rate, is better.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next two cells are just comparing results of two different ways of loading a saved dictionary file.  Result should be the same.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:32:16.620022Z",
     "iopub.status.busy": "2022-06-06T18:32:16.617280Z",
     "iopub.status.idle": "2022-06-06T18:32:17.930758Z",
     "shell.execute_reply": "2022-06-06T18:32:17.928945Z",
     "shell.execute_reply.started": "2022-06-06T18:32:16.619924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "modelv3 = XGBClassifier()\n",
    "modelv3.load_model(f'{workdir}modelv3.json')\n",
    "print(f'{mf.color.bdblue}Hyperparameter values{mf.color.end}')\n",
    "display(modelv3.get_xgb_params())\n",
    "\n",
    "mf.plot_features(modelv3, (8,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Observation</b><br>\n",
    "    I was hoping to see <b>Industry</b> at a much higher position here, but apparently the incomplete data on industry had an effect.<br><br>\n",
    "Furthermore, <b>Recession</b> has to be at a very high position, but is at the bottom instead.  This could be due to <b>Recession</b> data being highly skewed towards 1 (Not Recession).<br><br>\n",
    "<b>Real Estate</b> should have good importance too, but it may be highly skewed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:32:17.933552Z",
     "iopub.status.busy": "2022-06-06T18:32:17.932531Z",
     "iopub.status.idle": "2022-06-06T18:32:18.806457Z",
     "shell.execute_reply": "2022-06-06T18:32:18.805010Z",
     "shell.execute_reply.started": "2022-06-06T18:32:17.933499Z"
    }
   },
   "outputs": [],
   "source": [
    "model3_results = joblib.load(f\"{workdir}model3_results.dict\")\n",
    "\n",
    "mf.plot_features(model3_results['xg_model'], (8,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T05:18:58.418572Z",
     "iopub.status.busy": "2022-03-12T05:18:58.418154Z",
     "iopub.status.idle": "2022-03-12T05:18:58.448155Z",
     "shell.execute_reply": "2022-03-12T05:18:58.447213Z",
     "shell.execute_reply.started": "2022-03-12T05:18:58.418473Z"
    }
   },
   "source": [
    "<a id=\"test_model\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4. Test Model</h2>\n",
    "    </div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_test_dataset\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4.1 Test Model with Test Dataset</h2>\n",
    "    Test Dataset was previously unseen by the model.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:32:18.810476Z",
     "iopub.status.busy": "2022-06-06T18:32:18.810171Z",
     "iopub.status.idle": "2022-06-06T18:32:53.079975Z",
     "shell.execute_reply": "2022-06-06T18:32:53.078999Z",
     "shell.execute_reply.started": "2022-06-06T18:32:18.810435Z"
    }
   },
   "outputs": [],
   "source": [
    "def Modelv3WithTestData():\n",
    "    X_test = model3_results['X_test']\n",
    "    y_test = model3_results['y_test']\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = modelv3.predict(X_test)\n",
    "    #mf.model_eval(y_test, predictions);\n",
    "    mf.model_eval2(modelv3,\n",
    "                   model3_results['X_train'], model3_results['y_train'],\n",
    "                   X_test, y_test,\n",
    "                   cmDisplay=True, prtstr = 'y_test')\n",
    "    \n",
    "Modelv3WithTestData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_user_input\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4.2 Test Model with User Input</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">So let's assume the following are <b>the entries of a user</b>, through a user interface, looking for a prediction from our model.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:32:53.082173Z",
     "iopub.status.busy": "2022-06-06T18:32:53.081676Z",
     "iopub.status.idle": "2022-06-06T18:32:53.108118Z",
     "shell.execute_reply": "2022-06-06T18:32:53.107031Z",
     "shell.execute_reply.started": "2022-06-06T18:32:53.082131Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def UserInputTest():\n",
    "    # 16 entries\n",
    "    user_input =   {'Term':50, \n",
    "                    'NoEmp':0,\n",
    "                    'NewExist':1,\n",
    "                    'CreateJob':0 ,          \n",
    "                    'RetainedJob':0,         \n",
    "                    'FranchiseCode':1,       \n",
    "                    'UrbanRural':0,           \n",
    "                    'LowDoc':0,               \n",
    "                    'DisbursementGross':50000,                 \n",
    "                    'SBA_Appv':25000,          \n",
    "                    'Industry':71, \n",
    "                    'Recession':0,\n",
    "                    'RealEstate':0,           \n",
    "                    'SBA_Portion':50,\n",
    "                    'City':'EVANSVILLE',\n",
    "                    'State':'IN'\n",
    "                   }\n",
    "\n",
    "    city = user_input['City']\n",
    "    state = user_input['State']\n",
    "    city_state = f'{city}_{state}'\n",
    "\n",
    "    state_hash = int(hashlib.sha1(('State' + \"_\" + \\\n",
    "                              str(state)).encode('utf-8')).hexdigest(), 16) % 900000\n",
    "    city_state_hash = int(hashlib.sha1(('CityState' + \"_\" + \\\n",
    "                              str(city_state)).encode('utf-8')).hexdigest(), 16) % 900000\n",
    "\n",
    "    print(f'State_hash = {state_hash}')\n",
    "    print(f'CityState_hash = {city_state_hash}')\n",
    "\n",
    "    user_input.pop('City')\n",
    "    user_input.pop('State')\n",
    "    user_input['State_hash'] = state_hash\n",
    "    user_input['CityState_hash'] = city_state_hash\n",
    "\n",
    "    user_input_list = list(user_input.values())\n",
    "    \n",
    "    return {'user_input':user_input, 'user_input_list':user_input_list}\n",
    "\n",
    "user_input_param = UserInputTest()\n",
    "\n",
    "print()\n",
    "print(f\"{mf.color.bold}User Entry:{mf.color.end}\")\n",
    "user_input_param['user_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:32:53.110203Z",
     "iopub.status.busy": "2022-06-06T18:32:53.109633Z",
     "iopub.status.idle": "2022-06-06T18:32:53.125024Z",
     "shell.execute_reply": "2022-06-06T18:32:53.124075Z",
     "shell.execute_reply.started": "2022-06-06T18:32:53.110154Z"
    }
   },
   "outputs": [],
   "source": [
    "# User Input test 1\n",
    "def UserInputTest1():\n",
    "    features = np.array([user_input_param['user_input_list']])   \n",
    "\n",
    "    # using inputs to predict the output\n",
    "    pred = modelv3.predict(features)\n",
    "    if pred[0] == 1:\n",
    "        print(f'{mf.color.bdblue}Prediction: Approve The Loan{mf.color.end}')\n",
    "    else:\n",
    "        print(f'{mf.color.bdred}Prediction: Do Not Approve The Loan{mf.color.end}')\n",
    "        \n",
    "UserInputTest1()\n",
    "print(f'Correct answer is: {mf.color.bold}Do Not Approve{mf.color.end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:32:53.127294Z",
     "iopub.status.busy": "2022-06-06T18:32:53.126714Z",
     "iopub.status.idle": "2022-06-06T18:32:53.141680Z",
     "shell.execute_reply": "2022-06-06T18:32:53.140672Z",
     "shell.execute_reply.started": "2022-06-06T18:32:53.127239Z"
    }
   },
   "outputs": [],
   "source": [
    "# User Input test 2\n",
    "def UserInputTest2():\n",
    "    '''\n",
    "    # if one wants to edit the list from the previous cell\n",
    "    user_input2_list = user_input_list[:]   # make a copy\n",
    "    user_input2_list[0] = 500          # change term \n",
    "    '''\n",
    "\n",
    "    user_input2 = copy.deepcopy(user_input_param['user_input'])\n",
    "    user_input2['Term'] = 500     # change term\n",
    "    user_input2_list = list(user_input2.values())\n",
    "\n",
    "    features = np.array([user_input2_list]) \n",
    "\n",
    "    # using inputs to predict the output\n",
    "    pred = modelv3.predict(features)\n",
    "    if pred[0] == 1:\n",
    "        print(f'{mf.color.bdblue}Prediction: Approve The Loan{mf.color.end}')\n",
    "    else:\n",
    "        print(f'{mf.color.bdred}Prediction: Do Not Approve The Loan{mf.color.end}')\n",
    "        \n",
    "UserInputTest2()\n",
    "print(f'Correct answer is: {mf.color.bold}Approve{mf.color.end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:HoneyDew;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;border: 5px solid CadetBlue;\"><b>Predictions:</b><br>\n",
    "    \n",
    "- 1 -> can approve<br>\n",
    "- 0 -> do not approve<br>\n",
    "\n",
    "Of course, in real life, will need to check further using other data (e.g. financial statements, kind of real estate, etc.) or other data's models if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:32:53.145741Z",
     "iopub.status.busy": "2022-06-06T18:32:53.145510Z",
     "iopub.status.idle": "2022-06-06T18:32:53.445685Z",
     "shell.execute_reply": "2022-06-06T18:32:53.444711Z",
     "shell.execute_reply.started": "2022-06-06T18:32:53.145712Z"
    }
   },
   "outputs": [],
   "source": [
    "del user_input_param\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_user_input\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4.3 Test Model with Full Dataset</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:32:53.447946Z",
     "iopub.status.busy": "2022-06-06T18:32:53.447580Z",
     "iopub.status.idle": "2022-06-06T18:34:10.091878Z",
     "shell.execute_reply": "2022-06-06T18:34:10.090949Z",
     "shell.execute_reply.started": "2022-06-06T18:32:53.447867Z"
    }
   },
   "outputs": [],
   "source": [
    "def Modelv3TestFull():\n",
    "    X = pd.read_feather(f'{workdir}sba_final.csv.feather')\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    fd = process_model(X, y)\n",
    "    #fd.osample_Xy()\n",
    "    \n",
    "    modelv3 = XGBClassifier()\n",
    "    modelv3.load_model(f'{workdir}modelv3.json')\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = modelv3.predict(fd.X)\n",
    "    #mf.model_eval(fd.y, predictions) \n",
    "    mf.model_eval2(modelv3,\n",
    "                   model3_results['X_train'], model3_results['y_train'],\n",
    "                   X, y,\n",
    "                   cmDisplay=True, prtstr = 'y_test')\n",
    "  \n",
    "Modelv3TestFull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:10:41.572492Z",
     "iopub.status.busy": "2022-03-13T19:10:41.572202Z",
     "iopub.status.idle": "2022-03-13T19:10:41.579958Z",
     "shell.execute_reply": "2022-03-13T19:10:41.578591Z",
     "shell.execute_reply.started": "2022-03-13T19:10:41.572462Z"
    }
   },
   "source": [
    "<a id=\"mutual_info\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>5. Mutual Information Scores</h2>\n",
    " \"A general-purpose metric, normally used before selecting and building a model, but used here in the end, for comparison.  Mutual information is a lot like correlation in that it measures a relationship between two quantities. The advantage of mutual information is that it can detect any kind of relationship, while correlation only detects linear relationships.\"\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:34:10.096824Z",
     "iopub.status.busy": "2022-06-06T18:34:10.096126Z",
     "iopub.status.idle": "2022-06-06T18:37:34.145652Z",
     "shell.execute_reply": "2022-06-06T18:37:34.144620Z",
     "shell.execute_reply.started": "2022-06-06T18:34:10.096774Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def GetMIScores():\n",
    "    X = pd.read_feather(f'{workdir}sba_final.csv.feather')\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model_mi = process_model(X, y)\n",
    "    model_mi.osample_Xy()\n",
    "    \n",
    "    del X,y\n",
    "    gc.collect()\n",
    "    sleep(3)\n",
    "    \n",
    "    mi_scores = mf.make_mi_scores(model_mi.X, model_mi.y)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = GetMIScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:37:34.147798Z",
     "iopub.status.busy": "2022-06-06T18:37:34.147165Z",
     "iopub.status.idle": "2022-06-06T18:37:34.723986Z",
     "shell.execute_reply": "2022-06-06T18:37:34.722970Z",
     "shell.execute_reply.started": "2022-06-06T18:37:34.147757Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=300, figsize=(8, 5))\n",
    "mf.plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:37:34.727071Z",
     "iopub.status.busy": "2022-06-06T18:37:34.725283Z",
     "iopub.status.idle": "2022-06-06T18:37:35.464651Z",
     "shell.execute_reply": "2022-06-06T18:37:35.463752Z",
     "shell.execute_reply.started": "2022-06-06T18:37:34.727025Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "\n",
    "mf.plot_features(modelv3, (8,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:37:35.467187Z",
     "iopub.status.busy": "2022-06-06T18:37:35.466197Z",
     "iopub.status.idle": "2022-06-06T18:37:35.782466Z",
     "shell.execute_reply": "2022-06-06T18:37:35.780982Z",
     "shell.execute_reply.started": "2022-06-06T18:37:35.467136Z"
    }
   },
   "outputs": [],
   "source": [
    "del mi_scores\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:37:35.785508Z",
     "iopub.status.busy": "2022-06-06T18:37:35.785014Z",
     "iopub.status.idle": "2022-06-06T18:37:35.796717Z",
     "shell.execute_reply": "2022-06-06T18:37:35.792765Z",
     "shell.execute_reply.started": "2022-06-06T18:37:35.785463Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"SBA Mutual Information completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The importance ranked by <b>Mutual Information</b> and <b>XGBoost Feature Importance</b> metrics are different.  Which ranking do you think is more reasonable ?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trim_dataset\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>6. Trim Dataset</h2><br>\n",
    "After the preprocessing and encoding steps, not all of the features may be useful in forecasting the loan default. Alternatively we can select the <b>top 5 or top 8 features</b>, based on the feature importance plot above, which had a major contribution in forecasting loan defaults.<br><br>\n",
    "\n",
    "If the model performance is similar in both the cases, that is – by using all the features and by using 5-8 features, then we should use only the top 8 features, in order to keep the model simpler and more efficient.\n",
    "\n",
    "The idea is to have a less complex model without compromising on the overall model performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T19:00:51.450614Z",
     "iopub.status.busy": "2022-06-06T19:00:51.450316Z",
     "iopub.status.idle": "2022-06-06T19:00:51.838940Z",
     "shell.execute_reply": "2022-06-06T19:00:51.838055Z",
     "shell.execute_reply.started": "2022-06-06T19:00:51.450582Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_feather(f'{workdir}sba_final.csv.feather')\n",
    "y = X.pop('MIS_Status')\n",
    "\n",
    "#Let's retain the top 8 from Mutual Information metric \n",
    "mi_features = ['Term', 'DisbursementGross', 'SBA_Appv', 'SBA_Portion',\n",
    "                'CityState_hash', 'FranchiseCode', 'RealEstate', 'UrbanRural']\n",
    "\n",
    "Xmi = X[mi_features]\n",
    "\n",
    "#Let's retain the top 8 from Feature Importance metric \n",
    "fi_features = ['Term', 'State_hash', 'SBA_Appv', 'DisbursementGross', 'CityState_hash',\n",
    "                'Industry', 'NoEmp', 'SBA_Portion']\n",
    "\n",
    "Xfi = X[fi_features]\n",
    "\n",
    "del X\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T19:00:55.987998Z",
     "iopub.status.busy": "2022-06-06T19:00:55.987714Z",
     "iopub.status.idle": "2022-06-06T19:01:40.873517Z",
     "shell.execute_reply": "2022-06-06T19:01:40.872462Z",
     "shell.execute_reply.started": "2022-06-06T19:00:55.987966Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def ModelMI():\n",
    "    model_mi = process_model(Xmi, y)\n",
    "    model_mi.split_data(0.7)\n",
    "    model_mi.osample(os_data=[1,0,0])\n",
    "  \n",
    "    model_mi_results = model_mi.prep_run_model(\"Mutual Information Metrics\")\n",
    "    \n",
    "    print()\n",
    "    return model_mi_results\n",
    "\n",
    "model_mi_results = ModelMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T19:01:47.504563Z",
     "iopub.status.busy": "2022-06-06T19:01:47.503752Z",
     "iopub.status.idle": "2022-06-06T19:01:48.467652Z",
     "shell.execute_reply": "2022-06-06T19:01:48.466798Z",
     "shell.execute_reply.started": "2022-06-06T19:01:47.504515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot mutual information\n",
    "my_model_mi = model_mi_results['xg_model']\n",
    "\n",
    "mf.plot_features(my_model_mi, (8,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T19:02:41.868645Z",
     "iopub.status.busy": "2022-06-06T19:02:41.867814Z",
     "iopub.status.idle": "2022-06-06T19:03:17.969113Z",
     "shell.execute_reply": "2022-06-06T19:03:17.967961Z",
     "shell.execute_reply.started": "2022-06-06T19:02:41.868607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test with Unseen test data\n",
    "def MI_Model_On_Test_Data():\n",
    "    X_test = model_mi_results['X_test']\n",
    "    X_test_mi = X_test[mi_features]\n",
    "\n",
    "    y_test = model_mi_results['y_test']\n",
    "\n",
    "    predictions_mi = my_model_mi.predict(X_test_mi)\n",
    "    #mf.model_eval(y_test, predictions_mi)\n",
    "    mf.model_eval2( model_mi_results['xg_model'],\n",
    "                    model_mi_results['X_train'], model_mi_results['y_train'],\n",
    "                    model_mi_results['X_test'], model_mi_results['y_test'],\n",
    "                    cmDisplay=True)\n",
    "    print()\n",
    "    \n",
    "MI_Model_On_Test_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:38:24.003984Z",
     "iopub.status.busy": "2022-06-06T18:38:24.003136Z",
     "iopub.status.idle": "2022-06-06T18:38:24.300210Z",
     "shell.execute_reply": "2022-06-06T18:38:24.299265Z",
     "shell.execute_reply.started": "2022-06-06T18:38:24.003942Z"
    }
   },
   "outputs": [],
   "source": [
    "del Xmi, mi_features, my_model_mi, model_mi_results\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T19:03:45.821719Z",
     "iopub.status.busy": "2022-06-06T19:03:45.821417Z",
     "iopub.status.idle": "2022-06-06T19:04:30.803829Z",
     "shell.execute_reply": "2022-06-06T19:04:30.802793Z",
     "shell.execute_reply.started": "2022-06-06T19:03:45.821682Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def ModelFI():\n",
    "    model_fi = process_model(Xfi, y)\n",
    "    model_fi.split_data(0.7)\n",
    "    model_fi.osample(os_data=[1,0,0])\n",
    "    \n",
    "    model_fi_results = model_fi.prep_run_model(\"Feature Importance Metrics\")\n",
    "\n",
    "    print()\n",
    "    return model_fi_results\n",
    "    \n",
    "model_fi_results = ModelFI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T19:04:30.806625Z",
     "iopub.status.busy": "2022-06-06T19:04:30.805671Z",
     "iopub.status.idle": "2022-06-06T19:04:31.448712Z",
     "shell.execute_reply": "2022-06-06T19:04:31.447855Z",
     "shell.execute_reply.started": "2022-06-06T19:04:30.806581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "my_model_fi = model_fi_results['xg_model']\n",
    "\n",
    "mf.plot_features(my_model_fi, (8,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T19:04:53.125512Z",
     "iopub.status.busy": "2022-06-06T19:04:53.125195Z",
     "iopub.status.idle": "2022-06-06T19:05:29.414252Z",
     "shell.execute_reply": "2022-06-06T19:05:29.413211Z",
     "shell.execute_reply.started": "2022-06-06T19:04:53.125482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test with Unseen test data\n",
    "def FI_Model_On_Test_Data():\n",
    "    X_test = model_fi_results['X_test']\n",
    "    X_test_fi = X_test[fi_features]\n",
    "\n",
    "    y_test = model_fi_results['y_test']\n",
    "\n",
    "    predictions_fi = my_model_fi.predict(X_test_fi)\n",
    "    mf.model_eval2( model_fi_results['xg_model'],\n",
    "                    model_fi_results['X_train'], model_fi_results['y_train'],\n",
    "                    model_fi_results['X_test'], model_fi_results['y_test'],\n",
    "                    cmDisplay=True)\n",
    "    print()\n",
    "    \n",
    "FI_Model_On_Test_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-06T18:39:12.795894Z",
     "iopub.status.busy": "2022-06-06T18:39:12.794882Z",
     "iopub.status.idle": "2022-06-06T18:39:13.092738Z",
     "shell.execute_reply": "2022-06-06T18:39:13.091836Z",
     "shell.execute_reply.started": "2022-06-06T18:39:12.795851Z"
    }
   },
   "outputs": [],
   "source": [
    "del Xfi, fi_features, my_model_fi, model_fi_results, y\n",
    "del model3_results, modelv3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"results1\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>7. Full or Trimmed Dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Do we select the full dataset, or the trimmed dataset ?</b><br><br>\n",
    "    We can <b>stick with the full features</b> for now; but the trimmed features are also good, with the <b>Manual Information trimmed dataset</b> very slightly favored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><a style=\"color:DarkSlateGrey\" href=\"#toc\">Back to Table Of Contents</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we <b>optimize</b> our XGBoost hyperparameters with <b>Optuna</b>.<br><br>\n",
    "<a style=\"color:DarkSlateGrey;font-size:20px\" href=\"https://www.kaggle.com/code/josephramon/sba-optuna-xgboost-random-forest\" target=\"_blank\"><b>Optuna Hyperparameter Tuning</b></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
