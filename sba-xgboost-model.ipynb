{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;a:link{color: white}\">\n",
    "    <h1 style='color:GhostWhite;'>Should This Loan be Approved or Denied ?</h1>\n",
    "\n",
    "An XGBoost data model to predict whether a loan can be approved or denied.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">  \n",
    "    <b>Dataset Source</b><br><br>\n",
    "    <a href=\"https://www.kaggle.com/mirbektoktogaraev/should-this-loan-be-approved-or-denied\">U.S. Small Business Administration (SBA) Dataset</a>\n",
    "<br><br>\n",
    "    All information about the dataset can be found at the <b>above link</b><br><br>    \n",
    "    *<i>Thanks to Hamza for his <a href=\"https://www.kaggle.com/code/hamzaghanmi/xgboost-hyperparameter-tuning-using-optuna/notebook\">Notebook on Optuna</a> which was used as a guide.</i> \n",
    "<br><br>\n",
    "    If interested, Data Exploratory Visualization in Tableau can also be seen at :<br>\n",
    "    <a href= \"https://public.tableau.com/app/profile/joseph8038/viz/SBADatasetVisualizationandAnalysis/SBADatasetVisualizationandAnalysis-StoryBoard\">SBA Data Exploratory Visualization in Tableau</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"color:DarkSlateBlue\">\n",
    "This notebook is divided into 4 main parts:<br>\n",
    "<ul>\n",
    "<li><a style=\"color:DarkSlateGrey;\" href=\"#part1\"><b>Part 1: Pipeline</b></a> - this is the end result encapsulated into a pipeline</li><br>\n",
    "<li><a style=\"color:DarkSlateGrey\" href=\"#part2\"><b>Part 2: Data Exploration (EDA) and Preparation, Modeling, Metrics</b></a> - from start to end, with some notes</li><br>\n",
    "<li><a style=\"color:DarkSlateGrey;\" href=\"#part3\"><b>Part 3: XGBoost HyperParameter Tuning using Optuna - Full and Incremental</b></a></li><br>\n",
    "<li><a style=\"color:DarkSlateGrey;\" href=\"#part4\"><b>Part 4: Miscellaneous</a></b>  - Early Stopping Rounds, Random Forest Classifier</li>\n",
    "</ul><br>\n",
    "\"Our model results are way more dependent on how well feature engineering is performed than on the model itself. Machine Learning models are like very skilled linguists that can decipher any text in any language. However, it will not be helpful if they are handed a bunch of scribbles or blurred out text. EDA should not be skipped, as a thorough EDA and feature engineering process accounts for 90% of the results of a good model.\"<br><br>\n",
    "One method of avoiding memory leaks is doing processing inside a function. It creates a new scope for the intermediate variables and removes them automatically when the interpreter exits the function; hence, most of the code below are encapsulated into functions for this purpose. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table Of Contents</h2>\n",
    "<ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#paths_and_flags\">Paths and Flags</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#libraries\">Libraries</a></li>   \n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#functions\">Custom Functions And Classes</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#metrics\">Metrics Function</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#xgboost_class\">XGBoost Class</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#other_models\">Other Models Class</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_class\">Optuna Class</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_class_batch\">Optuna Class - tuning by batches</a></li><br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part1\">Part 1. PipeLine</a></li>\n",
    "    <ul>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#pl_classes\">Pipeline Classes</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#load_pl_df\">Load Dataset for PipeLine</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#pl_run\">Run the pipeline</a></li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part2\">Part 2. Data Exploration and Preparation, Modeling, Metrics</a></li>\n",
    "    <ul>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#de_load_df\">Load Dataset</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#dep\">Data Exploration / Preparation</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#build_model\">Build Model Using XGBoost</a></li>\n",
    "        <ul>\n",
    "            <li><a style=\"color:DarkSlateGrey\" href=\"#model1\">Model v1</a></li>\n",
    "            <li><a style=\"color:DarkSlateGrey\" href=\"#oversample\">Oversample</a></li>\n",
    "            <ul>\n",
    "                <li><a style=\"color:DarkSlateGrey\" href=\"#model2\">Model v2</a></li>\n",
    "                <li><a style=\"color:DarkSlateGrey\" href=\"#model3\">Model v3</a></li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#test_model\">Test Model</a></li>\n",
    "        <ul>\n",
    "            <li><a style=\"color:DarkSlateGrey\" href=\"#test_test_dataset\">Test Model With Test Dataset</a></li>\n",
    "           <li><a style=\"color:DarkSlateGrey\" href=\"#test_user_input\">Test Model With User Input</a></li>\n",
    "        </ul>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#mutual_info\">Mutual Information Scores</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#trim_datasets\">Trim Datasets</a></li>\n",
    "        <li><a style=\"color:DarkSlateGrey\" href=\"#results1\">Full or Trimmed Dataset</a></li>\n",
    "    </ul>  \n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part3\">Part 3. XGBoost HyperParameter Tuning using Optuna - Full or Incremental</a></li>\n",
    "    <ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#find_best_hp\">Find The Best HyperParameter Combination</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#try_best_hp\">Model v4 : Try the Optuna Hyperparameters</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#optuna_results\">Optuna Tuning Results</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#cross_validation\">Cross Validation</a></li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#part4\">Part 4. Miscellaneous</a></li>\n",
    "    <ul>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#early_stopping_rounds\">Early Stopping Rounds</a></li>\n",
    "    <li><a style=\"color:DarkSlateGrey\" href=\"#random_forest_classifier\">Random Forest Classifier</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"paths_and_flags\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Paths and Flags</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:35.140717Z",
     "iopub.status.busy": "2022-03-26T06:49:35.140141Z",
     "iopub.status.idle": "2022-03-26T06:49:35.153238Z",
     "shell.execute_reply": "2022-03-26T06:49:35.152367Z",
     "shell.execute_reply.started": "2022-03-26T06:49:35.140613Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Change this kaggle_flag to :\n",
    "   0 - if running outside Kaggle (e.g. Jupyter Notebook), change filepath & savepath to your \n",
    "       own path\n",
    "   1 - if running as a Kaggle notebook\n",
    "'''\n",
    "kaggle_flag = 0\n",
    "\n",
    "# switch to 1 if using GPU.  If 1, tree method for XGBoost will be 'gpu_hist'\n",
    "gpu_flag = 0\n",
    "\n",
    "# alert_flag - change to 0 for no sound alert, 1 for sound alert after long running cells\n",
    "alert_flag = 0\n",
    "\n",
    "'''\n",
    "We have two options for running Optuna tuning on XGBoost:  \n",
    "   OptunaStudy() - run Optuna on the full dataset\n",
    "   OptunaStudyBatch() - run in batches, lighter on memory, but much slower\n",
    "\n",
    "Change flag below as needed:\n",
    "   1 to run OptunaStudy() only\n",
    "   2 to run OptunaStudyBatch() only\n",
    "   3 to run both\n",
    "'''\n",
    "optuna_flag = 2\n",
    "\n",
    "#---------------------------------------------------------------------------------------#\n",
    "\n",
    "if kaggle_flag == 1:\n",
    "    filepath = \"../input/should-this-loan-be-approved-or-denied/\"  # Kaggle\n",
    "    savepath = \"./\"   #Kaggle\n",
    "    final_ds = '../input/sba-final-csv-feather-20220402/sba_final.csv.feather' \n",
    "else:\n",
    "    filepath = \"C:\\\\Python\\\\Python_Data_Science_Exercises\\\\datasets\\\\\"\n",
    "    savepath = \"C:\\\\Python\\\\Python_Data_Science_Exercises\\\\datasets\\\\\"\n",
    "    final_ds = f'{savepath}sba_final.csv.feather'\n",
    "\n",
    "audio_path=\"https://www.soundjay.com/misc/sounds/tablet-bottle-1.mp3\" # for alert\n",
    "\n",
    "if gpu_flag == 0:\n",
    "    tree_method = 'hist'\n",
    "else:\n",
    "    tree_method = 'gpu_hist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"libraries\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Libraries</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:35.160495Z",
     "iopub.status.busy": "2022-03-26T06:49:35.158668Z",
     "iopub.status.idle": "2022-03-26T06:49:37.348730Z",
     "shell.execute_reply": "2022-03-26T06:49:37.347711Z",
     "shell.execute_reply.started": "2022-03-26T06:49:35.160464Z"
    }
   },
   "outputs": [],
   "source": [
    "def install_packages():\n",
    "    piplist = !pip list\n",
    "\n",
    "    # for text-to-speech\n",
    "    if not piplist.grep('pyttsx3'):\n",
    "        !pip3 install pyttsx3\n",
    "    \n",
    "    # for oversampling\n",
    "    if not piplist.grep('imbalanced-learn'):\n",
    "        !pip3 install imbalanced-learn\n",
    "\n",
    "    if not piplist.grep('xgboost'):\n",
    "        !pip3 install xgboost\n",
    "    \n",
    "    if not piplist.grep('optuna'):\n",
    "        !pip3 install optuna\n",
    "\n",
    "    # for saving file in feather format\n",
    "    if not piplist.grep('pyarrow'):\n",
    "        !pip3 install pyarrow\n",
    "    \n",
    "    # for EDA \n",
    "    if not piplist.grep('pandas-profiling'):\n",
    "        !pip3 install pandas-profiling\n",
    "    \n",
    "    if not piplist.grep('sweetviz'):\n",
    "        !pip3 install sweetviz\n",
    "    \n",
    "    if not piplist.grep('dataprep'):\n",
    "        !pip3 install dataprep\n",
    "    '''  \n",
    "    if not piplist.grep('modin'):\n",
    "        !pip3 install modin\n",
    "        !pip3 install modin[ray]\n",
    "    '''\n",
    "install_packages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:37.352654Z",
     "iopub.status.busy": "2022-03-26T06:49:37.352409Z",
     "iopub.status.idle": "2022-03-26T06:49:39.053576Z",
     "shell.execute_reply": "2022-03-26T06:49:39.052631Z",
     "shell.execute_reply.started": "2022-03-26T06:49:37.352624Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import modin.pandas as pd\n",
    "import ray\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pyttsx3\n",
    "from IPython.display import Audio, display\n",
    "from IPython.display import FileLink\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import HTML\n",
    "import hashlib\n",
    "import copy      # for deepcopy()\n",
    "import datetime as dt\n",
    "import optuna\n",
    "import gc\n",
    "from pandas_profiling import ProfileReport\n",
    "import sweetviz as sv\n",
    "import shutil\n",
    "import psutil\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use with modin.pandas\n",
    "#ray.shutdown()\n",
    "#ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"functions\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Custom Functions and Classes</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.068510Z",
     "iopub.status.busy": "2022-03-26T06:49:39.067808Z",
     "iopub.status.idle": "2022-03-26T06:49:39.074548Z",
     "shell.execute_reply": "2022-03-26T06:49:39.073617Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.068442Z"
    }
   },
   "outputs": [],
   "source": [
    "class color:\n",
    "    purple = '\\033[95m'\n",
    "    cyan = '\\033[96m'\n",
    "    darkcyan = '\\033[36m'\n",
    "    blue = '\\033[94m'\n",
    "    green = '\\033[92m'\n",
    "    yellow = '\\033[93m'\n",
    "    red = '\\033[91m'\n",
    "    bold = '\\033[1m'\n",
    "    underline = '\\033[4m'\n",
    "    end = '\\033[0m'\n",
    "    bdunl = '%s%s' % (bold, underline)\n",
    "    bdblue = '%s%s' % (bold, blue)\n",
    "    bdgreen = '%s%s' % (bold, green)\n",
    "    bdred = '%s%s' % (bold, red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.055357Z",
     "iopub.status.busy": "2022-03-26T06:49:39.055059Z",
     "iopub.status.idle": "2022-03-26T06:49:39.063894Z",
     "shell.execute_reply": "2022-03-26T06:49:39.062913Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.055318Z"
    }
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Set up voice object.  Used in different areas of notebook to indicate completion of long processes.\n",
    "'''\n",
    "if kaggle_flag == 0:   # not Kaggle\n",
    "    engine = pyttsx3.init()  # object creation\n",
    "\n",
    "    \"\"\" RATE\"\"\"\n",
    "    #rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "    #print (rate)                        #printing current voice rate\n",
    "    engine.setProperty('rate', 175)     # setting up new voice rate\n",
    "\n",
    "    \"\"\"VOLUME\"\"\"\n",
    "    #volume = engine.getProperty('volume')   #getting to know current volume level (min=0 and max=1)\n",
    "    #print (volume)                         #printing current volume level\n",
    "    engine.setProperty('volume',0.7)        # setting up volume level  between 0 and 1\n",
    "\n",
    "    \"\"\"VOICE\"\"\"\n",
    "    voices = engine.getProperty('voices')       #getting details of current voice\n",
    "    #engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "    engine.setProperty('voice', voices[1].id)   #changing index, changes voices. 1 for female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.076887Z",
     "iopub.status.busy": "2022-03-26T06:49:39.076283Z",
     "iopub.status.idle": "2022-03-26T06:49:39.096219Z",
     "shell.execute_reply": "2022-03-26T06:49:39.095320Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.076847Z"
    }
   },
   "outputs": [],
   "source": [
    "# copy from corochann (Kaggle Grandmaster) notebook \n",
    "# https://www.kaggle.com/code/corochann/ashrae-feather-format-for-fast-loading/notebook\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]):\n",
    "            # skip datetime type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min >= np.iinfo(np.uint8).min and c_max <= np.iinfo(np.uint8).max:\n",
    "                    df[col] = df[col].astype(np.uint8)\n",
    "                elif c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and \\\n",
    "                            c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print()\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.098436Z",
     "iopub.status.busy": "2022-03-26T06:49:39.098043Z",
     "iopub.status.idle": "2022-03-26T06:49:39.108891Z",
     "shell.execute_reply": "2022-03-26T06:49:39.108009Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.098394Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_cols_with_nulls(df):\n",
    "    cols_with_missing = [col for col in df.columns if df[col].isnull().any()]\n",
    "    if len(cols_with_missing) == 0:\n",
    "        print(\"No Missing Values\")\n",
    "    else:\n",
    "        print(cols_with_missing)\n",
    "    \n",
    "    sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DfSplitIntoChunks(df, n):\n",
    "    colnames = ['Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob',\n",
    "           'FranchiseCode', 'UrbanRural', 'LowDoc', 'DisbursementGross',\n",
    "           'MIS_Status', 'SBA_Appv', 'Industry', 'Recession', 'RealEstate',\n",
    "           'SBA_Portion', 'State_hash', 'CityState_hash']\n",
    "\n",
    "    # Split dataframe into chunks of n files...\n",
    "    chunks=[]\n",
    "    i, sz = 0, 0\n",
    "    for x in np.array_split(df, n, axis=0):\n",
    "        print(f'Processing df number: {i+1}')\n",
    "        chunks.append(pd.DataFrame(x, columns = colnames, index=None))\n",
    "        sz += len(chunks[i])\n",
    "        i += 1\n",
    "        \n",
    "    print()\n",
    "    print(f'Size of df = {len(df)}, Size of {n} Chunks = {sz}')\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.111441Z",
     "iopub.status.busy": "2022-03-26T06:49:39.111128Z",
     "iopub.status.idle": "2022-03-26T06:49:39.118775Z",
     "shell.execute_reply": "2022-03-26T06:49:39.117832Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.111406Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_infinity_nan(df,dfname):\n",
    "    print(\"checking for infinity\")\n",
    "  \n",
    "    #ds = sba.isin([np.inf, -np.inf])\n",
    "    #print(ds)\n",
    "  \n",
    "    # printing the count of infinity values\n",
    "    print()\n",
    "    print(\"printing the count of infinity values\")\n",
    "  \n",
    "    count = np.isinf(df).values.sum()\n",
    "    print(f\"{dfname} contains {str(count)} infinite values\")\n",
    "    print()\n",
    "    \n",
    "    has_nan = df.isnull().values.any()\n",
    "    print(f\"Does {dfname} have Nan or Null values ?  {has_nan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.121274Z",
     "iopub.status.busy": "2022-03-26T06:49:39.120923Z",
     "iopub.status.idle": "2022-03-26T06:49:39.128057Z",
     "shell.execute_reply": "2022-03-26T06:49:39.126915Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.121217Z"
    }
   },
   "outputs": [],
   "source": [
    "# used as a converter when loading csv\n",
    "def fixvals(val):\n",
    "    retval = val.replace('$','').replace(',','')\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.131117Z",
     "iopub.status.busy": "2022-03-26T06:49:39.129893Z",
     "iopub.status.idle": "2022-03-26T06:49:39.137508Z",
     "shell.execute_reply": "2022-03-26T06:49:39.136629Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.131006Z"
    }
   },
   "outputs": [],
   "source": [
    "## I could also use the jupyter notebook magic cell %%time\n",
    "def runtime(rt1,rt2):\n",
    "    tdiff=rt2 - rt1\n",
    "    # get seconds and convert to h:m:s\n",
    "    print()\n",
    "    print(f'Runtime : {str(dt.timedelta(seconds=tdiff.total_seconds()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_download_link(title = \"Download \", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title + filename,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Audio', 1064),\n",
      " ('FileLink', 1064),\n",
      " ('HTML', 1064),\n",
      " ('IFrame', 1064),\n",
      " ('ProfileReport', 1064),\n",
      " ('color', 1064),\n",
      " ('DfSplitIntoChunks', 136),\n",
      " ('check_cols_with_nulls', 136),\n",
      " ('check_infinity_nan', 136),\n",
      " ('create_download_link', 136),\n",
      " ('display', 136),\n",
      " ('fixvals', 136),\n",
      " ('install_packages', 136),\n",
      " ('is_datetime', 136),\n",
      " ('reduce_mem_usage', 136),\n",
      " ('runtime', 136),\n",
      " ('final_ds', 119),\n",
      " ('audio_path', 105),\n",
      " ('filepath', 98),\n",
      " ('savepath', 98),\n",
      " ('voices', 88),\n",
      " ('dt', 72),\n",
      " ('np', 72),\n",
      " ('pd', 72),\n",
      " ('plt', 72),\n",
      " ('sns', 72),\n",
      " ('sv', 72),\n",
      " ('tree_method', 53),\n",
      " ('engine', 48),\n",
      " ('i', 28),\n",
      " ('optuna_flag', 28),\n",
      " ('x', 28),\n",
      " ('alert_flag', 24),\n",
      " ('gpu_flag', 24),\n",
      " ('kaggle_flag', 24)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "mm = sorted([(x, sys.getsizeof(globals().get(x))) \\\n",
    "            for x in dir() if not x.startswith('_') and \\\n",
    "            x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "pprint(mm)\n",
    "\n",
    "del ipython_vars\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetRam():\n",
    "    # Getting % usage of virtual_memory ( 3rd field)\n",
    "    #print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "    return psutil.virtual_memory()[2]\n",
    "\n",
    "GetRam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T21:11:54.129432Z",
     "iopub.status.busy": "2022-03-14T21:11:54.129137Z",
     "iopub.status.idle": "2022-03-14T21:11:54.135955Z",
     "shell.execute_reply": "2022-03-14T21:11:54.134951Z",
     "shell.execute_reply.started": "2022-03-14T21:11:54.1294Z"
    }
   },
   "source": [
    "<a id=\"eda_tools\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>EDA Tools</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSweetVizReport(df):\n",
    "    print(f'{color.bold}Please wait, preparing SweetViz report{color.end}')\n",
    "    try:\n",
    "        my_report = sv.analyze(df)\n",
    "    \n",
    "        my_report.show_html(filepath=f'{savepath}SBA_sweetviz_report.html', \n",
    "                open_browser=True, \n",
    "                layout='vertical', \n",
    "                scale=None)\n",
    "        print()\n",
    "        (kaggle_flag == 0) and print(f'SweetViz Report has been downloaded to path {savepath}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T21:11:54.129432Z",
     "iopub.status.busy": "2022-03-14T21:11:54.129137Z",
     "iopub.status.idle": "2022-03-14T21:11:54.135955Z",
     "shell.execute_reply": "2022-03-14T21:11:54.134951Z",
     "shell.execute_reply.started": "2022-03-14T21:11:54.1294Z"
    }
   },
   "source": [
    "<a id=\"metrics\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Metrics Function</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.143732Z",
     "iopub.status.busy": "2022-03-26T06:49:39.143235Z",
     "iopub.status.idle": "2022-03-26T06:49:39.158796Z",
     "shell.execute_reply": "2022-03-26T06:49:39.157868Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.143687Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def model_eval(y_valid,predictions, cmDisplay='False'):\n",
    "    print('MAE:', metrics.mean_absolute_error(y_valid, predictions))\n",
    "    #print('MSE:', metrics.mean_squared_error(y_valid, predictions))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_valid, predictions)))\n",
    "    print()\n",
    "    \n",
    "    ClassificationReport = classification_report(y_valid,predictions.round(),output_dict=True)\n",
    "\n",
    "    print(f'{color.bold}Classification Report:{color.end}')\n",
    "    print(classification_report(y_valid,predictions.round()))\n",
    "    \n",
    "    print()\n",
    "    print(f\"{color.bold}Confusion Matrix:{color.end}\")\n",
    "\n",
    "    if cmDisplay == True:\n",
    "        cm = confusion_matrix(y_valid, predictions)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        fig, ax = plt.subplots(dpi=100,figsize=(5,5))\n",
    "        disp.plot(ax=ax,colorbar=False,values_format='d')\n",
    "    \n",
    "    cmv = confusion_matrix(y_valid, predictions)\n",
    "    \n",
    "    TrueNeg = cmv[0][0]\n",
    "    FalsePos = cmv[0][1]\n",
    "    FalseNeg = cmv[1][0]\n",
    "    TruePos = cmv[1][1]\n",
    "\n",
    "    TotalNeg = TrueNeg + FalseNeg\n",
    "    TotalPos = TruePos + FalsePos\n",
    "    \n",
    "    print()\n",
    "    print(f'True Negative : CHGOFF (0) was predicted {TrueNeg} times correctly \\\n",
    "  ({round((TrueNeg/TotalNeg)*100,2)} %)')\n",
    "    print(f'False Negative : CHGOFF (0) was predicted {FalseNeg} times incorrectly \\\n",
    "    ({round((FalseNeg/TotalNeg)*100,2)} %)')\n",
    "    print(f'True Positive : P I F (1) was predicted {TruePos} times correctly \\\n",
    "    ({round((TruePos/TotalPos)*100,2)} %)')\n",
    "    print(f'False Positive : P I F (1) was predicted {FalsePos} times incorrectly \\\n",
    "    ({round((FalsePos/TotalPos)*100,2)} %)')\n",
    "    \n",
    "    print()\n",
    "    asm = (accuracy_score(y_valid, predictions.round()) * 100)\n",
    "    print(f'{color.bdgreen}Accuracy for model: %.2f{color.end}' % asm)\n",
    "    print(f'{color.bdblue}f1-score: {color.end}')\n",
    "    print(f\"   CHGOFF (0) : {round(ClassificationReport['0']['f1-score']*100,2)}\")\n",
    "    print(f\"   P I F (1)  : {round(ClassificationReport['1']['f1-score']*100,2)}\")\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_valid, predictions)))\n",
    "    \n",
    "    return {'cmv':cmv, 'ClassificationReport':ClassificationReport, 'AccuracyScore':asm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.160831Z",
     "iopub.status.busy": "2022-03-26T06:49:39.160178Z",
     "iopub.status.idle": "2022-03-26T06:49:39.190490Z",
     "shell.execute_reply": "2022-03-26T06:49:39.189603Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.160622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "# Plot feature importance\n",
    "def plot_features(booster, figsize):    \n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize,dpi=600)\n",
    "    return plot_importance(booster=booster, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.192571Z",
     "iopub.status.busy": "2022-03-26T06:49:39.192295Z",
     "iopub.status.idle": "2022-03-26T06:49:39.207955Z",
     "shell.execute_reply": "2022-03-26T06:49:39.207207Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.192533Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    print()\n",
    "    print(\"Please wait, Mutual Information gathering can take time ...\")\n",
    "    X = X.copy()\n",
    "    #for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "    #    X[colname], _ = X[colname].factorize()\n",
    "    # All discrete features should now have integer dtypes\n",
    "    #discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    #mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = mutual_info_regression(X, y, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    print(\"Mutual Information gathering done ...\")\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xgboost_class\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>XGBoost Class</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.211021Z",
     "iopub.status.busy": "2022-03-26T06:49:39.210498Z",
     "iopub.status.idle": "2022-03-26T06:49:39.264543Z",
     "shell.execute_reply": "2022-03-26T06:49:39.263710Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.210977Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "class process_model():  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_valid, self.X_test = None, None\n",
    "        self.y_valid, self.y_test = None, None\n",
    "\n",
    "        print(f'MIS_Status Count ->  1 : {Counter(y)[1]}, 0 : {Counter(y)[0]}')\n",
    "    \n",
    "    # oversampling method\n",
    "    def osample(self):\n",
    "        # define oversampling strategy\n",
    "        oversample = RandomOverSampler(sampling_strategy='minority') \n",
    "        print('X size : ', len(self.X))\n",
    "        print('y size : ', len(self.y))\n",
    "        # fit and apply the transform\n",
    "        X_over, y_over = oversample.fit_resample(self.X, self.y)\n",
    "\n",
    "        # summarize class distribution\n",
    "        print(f'Before Oversampling -> 1 : {Counter(self.y)[1]}, 0 : {Counter(self.y)[0]}')\n",
    "        print(f'After Oversampling  -> 1 : {Counter(y_over)[1]}, 0 : {Counter(y_over)[0]}')\n",
    "        \n",
    "        # update X and y with the oversampled results \n",
    "        self.X = X_over\n",
    "        self.y = y_over\n",
    "        \n",
    "        # return the oversampled results in case they are needed in another module\n",
    "        return {'X_over':X_over, 'y_over':y_over}\n",
    "    \n",
    "    def split_data(self, X_size = 0.7):   \n",
    "        # Split Data into Train:Validate:Test\n",
    "        \n",
    "        # train_size=X_size\n",
    "        # In the first step, we will split the data in training and remaining dataset\n",
    "        self.X_train, X_rem, self.y_train, y_rem = train_test_split(self.X, self.y, \\\n",
    "                                                        train_size = X_size, random_state=48) \n",
    "\n",
    "        # Now since we want the valid and test size to be equal,\n",
    "        # we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "        # test_size = 0.5\n",
    "\n",
    "        self.X_valid, self.X_test, self.y_valid, self.y_test = train_test_split(X_rem,y_rem,\\\n",
    "                                                            test_size=0.5, random_state=48)\n",
    "    \n",
    "        print()\n",
    "        print(f'{color.bdunl}Shapes Before And After Splitting Dataset :{color.end}')\n",
    "        print('X',self.X.shape,end=''), print('   y', self.y.shape)\n",
    "        print('X_train',self.X_train.shape,end=''), print('   y_train', self.y_train.shape)\n",
    "        print('X_valid',self.X_valid.shape,end=''), print('   y_valid', self.y_valid.shape)\n",
    "        print('X_test', self.X_test.shape, end=''), print('   y_test', self.y_test.shape)\n",
    "        \n",
    "        return {'X_train':self.X_train, 'y_train':self.y_train, \\\n",
    "                'X_valid':self.X_valid, 'y_valid':self.y_valid, \\\n",
    "                'X_test':self.X_test, 'y_test':self.y_test}\n",
    "    \n",
    "    # Method to run model \n",
    "    # desc - description of metrics report\n",
    "    def prep_run_model(self, desc='Metrics', cmDisplay=False, PipeLine_flag = False,\\\n",
    "                hyperparams = {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6, \\\n",
    "                               'tree_method':tree_method}):\n",
    "        print()\n",
    "        print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")\n",
    "        \n",
    "        '''\n",
    "        XGBRegressor is for continuous target/outcome variables. These are often called \n",
    "        \"regression problems.\"\n",
    "\n",
    "        XGBClassifier is for categorical target/outcome variables. These are often called \n",
    "        \"classification problems.\"\n",
    "        \n",
    "        xg_model = XGBRegressor(n_estimators = self.mn_estimators, \\\n",
    "                                learning_rate = self.mlearning_rate, \\\n",
    "                                max_depth = self.mmax_depth,\\\n",
    "                                n_jobs=4)\n",
    "        \n",
    "        xg_model = XGBClassifier(n_estimators = self.mn_estimators, \\\n",
    "                                learning_rate = self.mlearning_rate, \\\n",
    "                                max_depth = self.mmax_depth,\\\n",
    "                                use_label_encoder =False,\\\n",
    "                                n_jobs=4)\n",
    "        '''\n",
    "        \n",
    "        if PipeLine_flag == True:\n",
    "            # hyperparams is a result of Optuna hyperparameter tuning (Part 3 of this notebook)\n",
    "             \n",
    "            '''\n",
    "            hyperparams = {'lambda': 0.0011260613527792323,\n",
    "                           'alpha': 0.18307583898121738,\n",
    "                           'colsample_bytree': 0.5,\n",
    "                           'subsample': 0.8,\n",
    "                           'learning_rate': 0.02,\n",
    "                           'max_depth': 11,\n",
    "                           'random_state': 48,\n",
    "                           'min_child_weight': 1,\n",
    "                           'n_estimators': 4000,\n",
    "                           'tree_method': tree_method}\n",
    "            '''\n",
    "            hyperparams = { 'alpha': 0.0046540057600720115,\n",
    "                            'colsample_bytree': 0.5,\n",
    "                            'lambda': 0.10810295148897421,\n",
    "                            'learning_rate': 0.05,\n",
    "                            'max_depth': 15,\n",
    "                            'min_child_weight': 1,\n",
    "                            'random_state': 48,\n",
    "                            'subsample': 0.8,\n",
    "                            'n_estimators': 4000,\n",
    "                            'tree_method': tree_method}\n",
    "\n",
    "        xg_model = XGBClassifier(**hyperparams,use_label_encoder =False, n_jobs=4)\n",
    "       \n",
    "        eval_setparam = [(self.X_train, self.y_train), (self.X_valid, self.y_valid)]\n",
    "        \n",
    "        xg_model.fit(self.X_train, self.y_train, \n",
    "                     early_stopping_rounds=400,             # 10% of n_estimators\n",
    "                     eval_metric=['error','logloss'],\n",
    "                     #eval_set=[(X_valid, y_valid)], \n",
    "                     eval_set = eval_setparam,\n",
    "                     verbose=False)\n",
    " \n",
    "        print(\"Fitting model completed.\")\n",
    "        print()\n",
    "        print('Preparing Predictions')\n",
    "    \n",
    "        # Get predictions\n",
    "        predictions = xg_model.predict(self.X_valid)\n",
    "    \n",
    "        print()\n",
    "        print(f'{color.underline}{desc}{color.end}')\n",
    "\n",
    "        eval_results = model_eval(self.y_valid, predictions, cmDisplay)\n",
    "            \n",
    "        # Return these values as they will be needed for further testing or metrics\n",
    "        # in dictionary form to remember easier \n",
    "        return {'xg_model':xg_model,'predictions':predictions, \\\n",
    "                    'X_train':self.X_train, 'y_train':self.y_train, \\\n",
    "                    'X_valid':self.X_valid, 'y_valid':self.y_valid, \\\n",
    "                    'X_test':self.X_test, 'y_test':self.y_test, 'eval_results':eval_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"other_models\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Other Models Class</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# inherit from XGBoost class (process_model)\n",
    "class other_models(process_model):  \n",
    "    #def __init__(self, X, y):\n",
    "    #    self.X = X\n",
    "    #    self.y = y\n",
    "\n",
    "    #    print(f'MIS_Status Count ->  1 : {Counter(y)[1]}, 0 : {Counter(y)[0]}')\n",
    "    \n",
    "    # Method to run model \n",
    "    # desc - description of metrics report\n",
    "    def prep_run_model(self, desc='Metrics', modelname = 'rfc',\\\n",
    "                       hparams = {'n_estimators':600, 'random_state':48, 'max_depth':10},\\\n",
    "                       cmDisplay=False):\n",
    "        print()\n",
    "        print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")  \n",
    "\n",
    "        if modelname == 'rfc':\n",
    "            model = RandomForestClassifier(**hparams) \n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            \n",
    "        print(\"Fitting model completed.\")\n",
    "        print()\n",
    "        print('Preparing Predictions')\n",
    "    \n",
    "        # Get predictions\n",
    "        predictions = model.predict(self.X_valid)\n",
    "    \n",
    "        print()\n",
    "        print(f'{color.underline}{desc}{color.end}')\n",
    "\n",
    "        eval_results = model_eval(self.y_valid, predictions, cmDisplay)\n",
    "            \n",
    "        # Return these values as they will be needed for further testing or metrics\n",
    "        # in dictionary form to remember easier \n",
    "        return {'model':model,'predictions':predictions, \\\n",
    "                    'X_train':self.X_train, 'y_train':self.y_train, \\\n",
    "                    'X_valid':self.X_valid, 'y_valid':self.y_valid, \\\n",
    "                    'X_test':self.X_test, 'y_test':self.y_test, 'eval_results':eval_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_class\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Optuna Class</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.268170Z",
     "iopub.status.busy": "2022-03-26T06:49:39.267940Z",
     "iopub.status.idle": "2022-03-26T06:49:39.284793Z",
     "shell.execute_reply": "2022-03-26T06:49:39.283935Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.268144Z"
    }
   },
   "outputs": [],
   "source": [
    "class optuna_tuning(process_model):  \n",
    "    #def __init__(self, X_train, y_train, X_valid, y_valid):\n",
    "    #    self.X_train, self.y_train = X_train, y_train\n",
    "    #    self.X_valid, self.y_valid = X_valid, y_valid\n",
    "\n",
    "    def objective(self, trial):\n",
    "        param = {\n",
    "            # tree_method would ideally be gpu_hist for faster speed\n",
    "            'tree_method':tree_method, \n",
    "            # L2 regularization weight, Increasing this value will make model more conservative\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            # L1 regularization weight, Increasing this value will make model more conservative\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            # sampling according to each tree\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree',\n",
    "                            [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "            # sampling ratio for training data\n",
    "            'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate',\n",
    "                            [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02,0.05]),\n",
    "            'n_estimators': 4000,\n",
    "            # maximum depth of the tree, signifies complexity of the tree\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [6,7,9,11,13,15,17,20]),\n",
    "            'random_state': trial.suggest_categorical('random_state', [48]),\n",
    "            # minimum child weight, larger the term more conservative the tree\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 300)\n",
    "        }\n",
    "        \n",
    "        if GetRam() >= 95:\n",
    "            raise MemoryError('Short On Memory')\n",
    "\n",
    "        print(f\"Ram Used Before Trial : {GetRam()} %\")\n",
    "        \n",
    "        # print(param)  # for debugging, comment out if desired\n",
    "        model_xgbc = XGBClassifier(**param,use_label_encoder =False)  \n",
    "    \n",
    "        # xgb_model paramter allows the continuation of model training.\n",
    "        # Model has to be saved by calling `model.get_booster().save_model(path)`\n",
    "        # model_xgbc.get_booster().save_model(f'{savepath}model_xgbc_saved')\n",
    "        \n",
    "        model_xgbc.save_model(f'{savepath}model_xgbc.model')\n",
    "        model_xgbc.fit(self.X_train, self.y_train, eval_set=[(self.X_valid, self.y_valid)],\n",
    "                    verbose=False, eval_metric = ['logloss'],\n",
    "                    early_stopping_rounds = 400)\n",
    "    \n",
    "        preds = model_xgbc.predict(self.X_valid)\n",
    "    \n",
    "        rmse = metrics.mean_squared_error(self.y_valid, preds,squared=False)\n",
    "    \n",
    "        print(f\"Ram Used After Last Trial: {GetRam()} %\")\n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse\n",
    "\n",
    "    def run_optuna_trials(self,n_trials=None,timeout=None):\n",
    "        print()\n",
    "        print(f\"{color.bold}Please wait, finding best trial ...{color.end}\")\n",
    "        \n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        try:\n",
    "            study.optimize(self.objective, n_trials, timeout,\n",
    "                            #callbacks=[lambda study, trial: gc.collect()],\\\n",
    "                            catch=(RuntimeWarning,ArithmeticError,))\n",
    "        except MemoryError as e:\n",
    "            print()\n",
    "            print(f'{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}')\n",
    "        \n",
    "        print('Number of completed trials:', len(study.trials))\n",
    "        print('Best trial:', study.best_trial.params)\n",
    "        \n",
    "        joblib.dump(x, f\"{savepath}optuna_study.pkl\")       # save study\n",
    "        # jl = joblib.load(f\"{savepath}optuna_study.pkl\")   # load study\n",
    "        \n",
    "        return study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_class_batch\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Optuna Class - tuning by batches</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.268170Z",
     "iopub.status.busy": "2022-03-26T06:49:39.267940Z",
     "iopub.status.idle": "2022-03-26T06:49:39.284793Z",
     "shell.execute_reply": "2022-03-26T06:49:39.283935Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.268144Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optuna Tuning by batches, much slower, but lighter on memory\n",
    "class optuna_tuning_batch(process_model): \n",
    "    def objective(self, trial):\n",
    "        param = {\n",
    "            # tree_method would ideally be gpu_hist for faster speed\n",
    "            'tree_method':tree_method, \n",
    "            # L2 regularization weight, Increasing this value will make model more conservative\n",
    "            'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "            # L1 regularization weight, Increasing this value will make model more conservative\n",
    "            'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "            # sampling according to each tree\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree',\n",
    "                            [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "            # sampling ratio for training data\n",
    "            'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate',\n",
    "                            [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02,0.05]),\n",
    "            'n_estimators': 4000,\n",
    "            # maximum depth of the tree, signifies complexity of the tree\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [6,7,9,11,13,15,17,20]),\n",
    "            'random_state': trial.suggest_categorical('random_state', [48]),\n",
    "            # minimum child weight, larger the term more conservative the tree\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 300)\n",
    "        }\n",
    "        if GetRam() >= 95:\n",
    "            raise MemoryError('Short On Memory')\n",
    "        print(f\"Ram Used Before Trial: %{GetRam()}\")\n",
    "        \n",
    "        model_xgbc = XGBClassifier(**param,use_label_encoder =False)  \n",
    "    \n",
    "        rt1=dt.datetime.now()\n",
    "        \n",
    "        '''\n",
    "        For batch, use xgb_model parameter in fit().  There are two ways :\n",
    "           1. save the model to a file, after 1st trial, then give the name to the next trials\n",
    "           2. just give the name of the model object, in this case model_xgbc\n",
    "        '''\n",
    "        # Fit Model\n",
    "        for i, (X_batch, y_batch) in enumerate(zip(self.X_train_batched, self.y_train_batched)):\n",
    "            print(f'Step: {i}',end = ' ')\n",
    "            if i == 0:\n",
    "                model_xgbc.fit(X_batch, y_batch, eval_set=[(self.X_valid, self.y_valid)],\n",
    "                        verbose=False, eval_metric = ['logloss'],\n",
    "                        early_stopping_rounds = 400)\n",
    "            else:\n",
    "                model_xgbc.fit(X_batch, y_batch, eval_set=[(self.X_valid, self.y_valid)],\n",
    "                        verbose=False, eval_metric = ['logloss'],\n",
    "                        early_stopping_rounds = 400, \n",
    "                        xgb_model = model_xgbc\n",
    "                        # uncomment below if you want to use a saved file\n",
    "                        #xgb_model = f'{savepath}model_xgbc.json'\n",
    "                        )\n",
    "            \n",
    "            # uncomment below if using a saved file\n",
    "            #model_xgbc.get_booster().save_model(f'{savepath}model_xgbc.json')\n",
    "            \n",
    "            preds = model_xgbc.predict(self.X_valid)\n",
    "    \n",
    "            rmse = metrics.mean_squared_error(self.y_valid, preds,squared=False)\n",
    "            trial.report(rmse, i+1)\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "        \n",
    "        rt2=dt.datetime.now()\n",
    "        runtime(rt1,rt2)\n",
    "            \n",
    "        print(f\"Ram Used After Last Trial: %{GetRam()}\")\n",
    "        gc.collect()\n",
    "        \n",
    "        return rmse\n",
    "\n",
    "    def run_optuna_trials(self,batch_size=1,n_trials=None,timeout=None):\n",
    "        self.X_train_batched, self.y_train_batched =    self.X_train.reshape(-1,batch_size,16), \\\n",
    "                                                        self.y_train.reshape(-1,batch_size) \n",
    "        print()\n",
    "        print(f'X_train_batched Shape: {self.X_train_batched.shape}')\n",
    "        print(f'y_train_batched Shape: {self.y_train_batched.shape}')\n",
    "        print()\n",
    "    \n",
    "        print(f\"{color.bold}Please wait, finding best trial ...{color.end}\")\n",
    "        \n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        try:\n",
    "            study.optimize(self.objective, n_trials, timeout,\n",
    "                            #callbacks=[lambda study, trial: gc.collect()],\\\n",
    "                            catch=(RuntimeWarning,ArithmeticError,))\n",
    "        except MemoryError as e:\n",
    "            print(f'{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}')\n",
    "            \n",
    "        print('Number of completed trials:', len(study.trials))\n",
    "        print('Best trial:', study.best_trial.params)\n",
    "        \n",
    "        joblib.dump(x, f\"{savepath}optuna_study.pkl\")       # save study\n",
    "        # jl = joblib.load(f\"{savepath}optuna_study.pkl\")   # load study\n",
    "        \n",
    "        return study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 id=\"part1\" style='color:GhostWhite;'>Part 1. Pipeline</h1>\n",
    "This pipeline handles both X and y\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pl_classes\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>PipeLine Classes</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.287321Z",
     "iopub.status.busy": "2022-03-26T06:49:39.287085Z",
     "iopub.status.idle": "2022-03-26T06:49:39.330845Z",
     "shell.execute_reply": "2022-03-26T06:49:39.330151Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.287294Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "  \n",
    "class PL_Object():\n",
    "    def __init__(self,X,y):\n",
    "        #store X and Y\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "\n",
    "class PreProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,operation= 'X'):\n",
    "        self.operation=operation\n",
    "    @staticmethod\n",
    "    def enabled(**kwargs):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # check the parameters and return X and y inside the object\n",
    "        X_data=X.X\n",
    "        y_data=X.y\n",
    "        \n",
    "        print()\n",
    "        print(f'{color.bdunl}PreProcessor initiated for {self.operation}{color.end}')\n",
    "        \n",
    "        #  do some work and assign it back to the X object which contains both X and y data\n",
    "        if self.operation=='X':\n",
    "            '''\n",
    "            # NOTE: 'MIS_Status' is the target (y), but still in X, as we need to drop rows\n",
    "                    with NaNs. We cannot do it separately, as there will be a mismatch in count \n",
    "                    of rows.  At the end of this procedure, we separate the new target data from X \n",
    "                    and update y.\n",
    "            '''\n",
    "            \n",
    "            # Drop Na from rows\n",
    "            #---------------------\n",
    "            print(f'{color.bdblue}Drop Na{color.end}')\n",
    "            X_data.dropna(subset=['DisbursementDate', 'NewExist', 'City', 'State',\\\n",
    "                        'LowDoc', 'Name', 'NAICS', 'CreateJob', 'RetainedJob', 'FranchiseCode',\\\n",
    "                        'UrbanRural', 'NoEmp', 'Term', 'MIS_Status'], how='any', inplace=True)\n",
    "            \n",
    "            # drop invalid classifications\n",
    "            print('   Drop invalid classifications')\n",
    "            X_data = X_data[(X_data['LowDoc'] == 'Y') | (X_data['LowDoc'] == 'N')]\n",
    "            \n",
    "            X_data = X_data[(X_data['NewExist'] == 1) | (X_data['NewExist'] == 2)]   \n",
    "            \n",
    "            # Trim leading and trailing spaces\n",
    "            #---------------------------------\n",
    "            print('   Trim leading and trailing spaces, if any')\n",
    "            X_data['City'] = X_data['City'].str.strip()\n",
    "            \n",
    "            # Change dtype for columns needed for calculation or string extraction \n",
    "            #------------------------------------------------------------------------\n",
    "            print(f'{color.bdgreen}Change dtype for columns needed for calculation or string extraction{color.end}')\n",
    "            X_data = X_data.astype({'DisbursementGross':np.float64,'SBA_Appv':np.float64,\\\n",
    "                              'GrAppv':np.float64, 'ChgOffPrinGr':np.float64,\\\n",
    "                              'NAICS':np.str_, 'NewExist':np.int8})\n",
    "            \n",
    "            # Drop Duplicate Rows\n",
    "            #------------------------------------------------------------------------\n",
    "            print(f'{color.bdblue}Drop Duplicate Rows{color.end}')\n",
    "            dupl_series = X_data.duplicated()\n",
    "            num_of_dupl = len(X_data[dupl_series == True])\n",
    "            if num_of_dupl > 0:\n",
    "                X_data.drop_duplicates(inplace=True)\n",
    "        \n",
    "            # Create New Features\n",
    "            #-----------------------\n",
    "            print(f'{color.bdblue}Create New Features{color.end}')\n",
    "            X_data['Industry'] = X_data['NAICS'].str[0:2]\n",
    "            X_data = X_data.astype({'Industry':np.int8})\n",
    "            \n",
    "            X_data['Recession'] = np.where((X_data['DisbursementDate'] >= '2007-09-01')\\\n",
    "                     & (X_data['DisbursementDate'] <= '2009-06-30'), 1, 0)\n",
    "            \n",
    "            X_data['RealEstate'] = np.where(X_data['Term'] >= 240, 1, 0)\n",
    "            \n",
    "            X_data['SBA_Portion']=(X_data['SBA_Appv']/X_data['GrAppv']) * 100\n",
    "            \n",
    "            X_data[\"CityState\"] = X_data[\"City\"] + \"_\" + X_data[\"State\"]\n",
    "            \n",
    "            print()\n",
    "            print(f\"X length = {len(X_data)}\")\n",
    "            print(f\"Y length = {len(X_data['MIS_Status'])}\")\n",
    "            \n",
    "            # Update X object\n",
    "            X.X = X_data                      # type DataFrame\n",
    "            X.y = X_data.pop('MIS_Status')    # type series\n",
    "            \n",
    "        elif self.operation=='y':\n",
    "            pass                      \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        #return modified X object\n",
    "        return X\n",
    "    \n",
    "\n",
    "class EncodeCategorical(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,operation= 'X'):\n",
    "        self.operation=operation\n",
    "    @staticmethod\n",
    "    def enabled(**kwargs):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # encode categorical features and return X and y inside the object\n",
    "        X_data=X.X\n",
    "        y_data=X.y\n",
    "        \n",
    "        print()\n",
    "        print(f'{color.bdunl}Encode Categorical Features initiated for {self.operation}{color.end}')\n",
    "        \n",
    "        #  do some work and assign it back to the X object\n",
    "        if self.operation=='X':         \n",
    "            X_data['LowDoc'] = np.where((X_data['LowDoc'] == 'Y'), 1, 0)\n",
    "            \n",
    "            len_data=len(X_data)\n",
    "            #cols_to_drop = []\n",
    "            hash_constant = 900000   # fixed value so we can programmatically reproduce the hash\n",
    "            #for col in X_data.columns:\n",
    "            for col in X_data[['State','CityState']]:\n",
    "                if X_data[col].dtype == 'object':\n",
    "                    print(f'Column {col} has {X_data[col].nunique()} values among {len_data}')\n",
    "\n",
    "                    if X_data[col].nunique() < 25:\n",
    "                        print(f'One-hot encoding of {col}')\n",
    "                        one_hot_cols = pd.get_dummies(X_data[col])\n",
    "                        for ohc in one_hot_cols.columns:\n",
    "                            X_data[col + '_' + ohc] = one_hot_cols[ohc]\n",
    "                    else:\n",
    "                      print(f'Hashing of {col}')\n",
    "                      X_data[col + '_hash'] = X_data[col].apply(lambda row: int(hashlib.sha1((col +\\\n",
    "                                \"_\" + str(row)).encode('utf-8')).hexdigest(), 16) % hash_constant)\n",
    "\n",
    "            X.X = X_data\n",
    "            \n",
    "        elif self.operation=='y':\n",
    "            y_data = np.where(y_data == 'P I F', 1, 0)\n",
    "            \n",
    "            y_data = y_data.astype(np.int8)\n",
    "            \n",
    "            # convert back to series\n",
    "            y_data = pd.Series(y_data)\n",
    "\n",
    "            X.y = y_data                      \n",
    "        else:\n",
    "            pass\n",
    "        #return modified X\n",
    "        return X    \n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,operation= 'X'):\n",
    "        self.operation=operation\n",
    "    @staticmethod\n",
    "    def enabled(**kwargs):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_data=X.X\n",
    "        \n",
    "        print()\n",
    "        print(f'{color.bdunl}Drop Columns initiated for {self.operation}{color.end}')\n",
    "        \n",
    "        #  do some work and assign it back to the X object\n",
    " \n",
    "        # Dropping 'City' as 'CityState_hash' is more ideal\n",
    "        # Zip code has invalid values like 1, 2.  If we pad 0000 to 1, it's still not correct,\n",
    "        # as state should be Alaska. Zip code 1 is different states in the dataset\n",
    "        cols_to_drop = ['LoanNr_ChkDgt', 'Zip', 'Bank', 'BankState', 'ApprovalDate', \\\n",
    "                        'ApprovalFY', 'ChgOffDate', 'BalanceGross', 'NAICS', 'ChgOffPrinGr', \\\n",
    "                        'Name', 'RevLineCr', 'DisbursementDate', 'City', 'State', 'CityState',\\\n",
    "                        'GrAppv']\n",
    "\n",
    "        X_data.drop(columns=cols_to_drop, inplace=True)\n",
    "            \n",
    "        print()\n",
    "        print('Unneeded Columns Dropped')\n",
    "        \n",
    "        # reduce mem usage of X_data as final step\n",
    "        X_data = reduce_mem_usage(X_data)\n",
    "        \n",
    "        print()\n",
    "        print(X_data.info())\n",
    "\n",
    "        X.X = X_data\n",
    "            \n",
    "        #return modified X\n",
    "        return X    \n",
    "\n",
    "class XGBoost(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,operation= 'X'):\n",
    "        self.operation=operation\n",
    "    @staticmethod\n",
    "    def enabled(**kwargs):\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_data=X.X\n",
    "        y_data=X.y\n",
    "        \n",
    "        print()\n",
    "        print(f'{color.bdunl}XGBoost initiated{color.end}')\n",
    "        #print(len(X_data))\n",
    "        #print(len(y_data))\n",
    "        \n",
    "        # Get predictions using training and validation data\n",
    "        xg_model_run = process_model(X_data, y_data)\n",
    "        xg_model_run.osample()\n",
    "        xg_model_run.split_data(0.7)\n",
    "        xg_model_run_results = xg_model_run.prep_run_model(\"Train/Valid Data Metrics\",\\\n",
    "                                                          cmDisplay=True, PipeLine_flag = True)   \n",
    "        \n",
    "        #Test with unseen data\n",
    "        print()\n",
    "        print(f'{color.bdunl}Test With Unseen Data X_test and y_test{color.end}')\n",
    "        \n",
    "        xg_model = xg_model_run_results['xg_model']\n",
    "        x_test = xg_model_run_results['X_test']\n",
    "        y_test = xg_model_run_results['y_test']\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = xg_model.predict(x_test)\n",
    "        cmv = model_eval(y_test, predictions)\n",
    "\n",
    "        X.X = X_data\n",
    "            \n",
    "        '''\n",
    "        A dictionary is returned, and its values can be used outside the pipeline if needed\n",
    "        \n",
    "        {'xg_model':xg_model,'predictions':predictions, \\\n",
    "                    'X_train':X_train, 'y_train':y_train, \\\n",
    "                    'X_valid':X_valid, 'y_valid':y_valid, \\\n",
    "                    'X_test':X_test, 'y_test':y_test, 'cmv':cmv}\n",
    "        '''\n",
    "        return xg_model_run_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_pl_df\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Load Dataset for PipeLine</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:39.332534Z",
     "iopub.status.busy": "2022-03-26T06:49:39.332300Z",
     "iopub.status.idle": "2022-03-26T06:49:47.416261Z",
     "shell.execute_reply": "2022-03-26T06:49:47.415540Z",
     "shell.execute_reply.started": "2022-03-26T06:49:39.332503Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(f'{filepath}SBAnational.csv',\\\n",
    "                 converters = {'DisbursementGross':fixvals,'SBA_Appv':fixvals,\\\n",
    "                              'GrAppv':fixvals, 'ChgOffPrinGr':fixvals}, \\\n",
    "                              parse_dates=['DisbursementDate'], low_memory=False)\n",
    "print(\"Shape of original SBA dataset : \", X.shape)\n",
    "print()\n",
    "print(X[['DisbursementGross','SBA_Appv','GrAppv','ChgOffPrinGr','DisbursementDate']].head(2))\n",
    "\n",
    "# Filter data to before 2011\n",
    "X = X[X['DisbursementDate'] <= '2010-12-31']\n",
    "\n",
    "print()\n",
    "print(f\"Size of data after 2010-12-31 : \\\n",
    "    {len(X[X['DisbursementDate'] > '2010-12-31'])}\")\n",
    "print()\n",
    "print(f\"Size of data before 2011 : \\\n",
    "    {len(X[X['DisbursementDate'] < '2011-01-01'])}\")\n",
    "\n",
    "'''\n",
    "X still contains the target 'MIS_Status', as we have to drop rows \n",
    "with NaNs in the pipeline. \"MIS_Status\" will be separated from X later in the pipeline\n",
    "\n",
    "Select target - y is initialized as it goes into the pipeline, but will be updated in the pipeline \n",
    "after preprocessing.  Others preprocess y outside the pipeline; here, y will be preprocessed in\n",
    "the pipeline.\n",
    "'''\n",
    "y = X['MIS_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:47.418389Z",
     "iopub.status.busy": "2022-03-26T06:49:47.417622Z",
     "iopub.status.idle": "2022-03-26T06:49:47.446508Z",
     "shell.execute_reply": "2022-03-26T06:49:47.445706Z",
     "shell.execute_reply.started": "2022-03-26T06:49:47.418346Z"
    }
   },
   "outputs": [],
   "source": [
    "#Assign X and y to the object\n",
    "My_Object=PL_Object(X,y)\n",
    "My_Object.X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pl_run\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Run the pipeline</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:49:47.448359Z",
     "iopub.status.busy": "2022-03-26T06:49:47.448074Z",
     "iopub.status.idle": "2022-03-26T06:56:05.632697Z",
     "shell.execute_reply": "2022-03-26T06:56:05.630602Z",
     "shell.execute_reply.started": "2022-03-26T06:49:47.448324Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunPipeLine():\n",
    "    rt1=dt.datetime.now()\n",
    "    #Assign X and y to the object\n",
    "    My_Object=PL_Object(X,y)\n",
    "\n",
    "    #Build a simple pipeline\n",
    "\n",
    "    My_Pipeline=Pipeline([('X Prep',PreProcessor('X')),\n",
    "                          ('X EnCat',EncodeCategorical('X')),\n",
    "                          ('y EnCat',EncodeCategorical('y')),\n",
    "                          ('DropCols',DropColumns()),\n",
    "                          ('XGBoost',XGBoost())\n",
    "                         ])\n",
    "\n",
    "    My_Object=My_Pipeline.transform(My_Object)\n",
    "\n",
    "    print()\n",
    "    print(f'{color.bdred}These results were obtained using Optuna tuning{color.end}')\n",
    "    \n",
    "    print()\n",
    "    print(f'{color.bold}Pipeline Process Completed.{color.end}')\n",
    "\n",
    "    rt2=dt.datetime.now()\n",
    "    runtime(rt1,rt2)\n",
    "    print()\n",
    "    \n",
    "    return My_Object        # for further usage below\n",
    "    \n",
    "MyObject = RunPipeLine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"color:DarkSlateBlue\">\n",
    "    <b>Just for informative reasons</b>, below shows how we can use data (dictionary) passed back by the pipeline to My_Object\n",
    "    </div>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:56:05.634821Z",
     "iopub.status.busy": "2022-03-26T06:56:05.634413Z",
     "iopub.status.idle": "2022-03-26T06:56:07.992201Z",
     "shell.execute_reply": "2022-03-26T06:56:07.991542Z",
     "shell.execute_reply.started": "2022-03-26T06:56:05.634780Z"
    }
   },
   "outputs": [],
   "source": [
    "def obj_sample_usage():\n",
    "    print(MyObject.keys())\n",
    "    pl_model = MyObject['xg_model']\n",
    "    x=plot_features(pl_model, (10,14))\n",
    "    print()\n",
    "    MyObject['X_train'].info()\n",
    "    \n",
    "obj_sample_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:56:07.993399Z",
     "iopub.status.busy": "2022-03-26T06:56:07.993153Z",
     "iopub.status.idle": "2022-03-26T06:56:08.197211Z",
     "shell.execute_reply": "2022-03-26T06:56:08.196492Z",
     "shell.execute_reply.started": "2022-03-26T06:56:07.993368Z"
    }
   },
   "outputs": [],
   "source": [
    "# clear some variables from memory\n",
    "del X, y, MyObject\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:56:08.198947Z",
     "iopub.status.busy": "2022-03-26T06:56:08.198546Z",
     "iopub.status.idle": "2022-03-26T06:56:08.205903Z",
     "shell.execute_reply": "2022-03-26T06:56:08.205088Z",
     "shell.execute_reply.started": "2022-03-26T06:56:08.198909Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"SBA Machine Learning PipeLine completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 style='color:GhostWhite;'>Part 2 : Data Exploration and Preparation, Modeling, Metrics</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"de_load_df\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h3 style='color:GhostWhite;'>1. Load Dataset</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:04.508190Z",
     "iopub.status.busy": "2022-03-26T07:00:04.507740Z",
     "iopub.status.idle": "2022-03-26T07:00:11.956929Z",
     "shell.execute_reply": "2022-03-26T07:00:11.956184Z",
     "shell.execute_reply.started": "2022-03-26T07:00:04.508150Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sba = pd.read_csv(f'{filepath}SBAnational.csv', low_memory=False)\n",
    "\n",
    "print(\"Shape of SBA : \", sba.shape)\n",
    "print(sba.info(memory_usage = 'deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dep\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2. Data Exploration / Preparation</h2><br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Reload dataset with some conversion</b><br>\n",
    "    After review, decided to reload dataset with conversion of some features that may be needed for calculation.  It could be done after loading, but this is for instructive purposes on how it's done.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:04.508190Z",
     "iopub.status.busy": "2022-03-26T07:00:04.507740Z",
     "iopub.status.idle": "2022-03-26T07:00:11.956929Z",
     "shell.execute_reply": "2022-03-26T07:00:11.956184Z",
     "shell.execute_reply.started": "2022-03-26T07:00:04.508150Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del sba\n",
    "gc.collect()\n",
    "sba = pd.read_csv(filepath + 'SBAnational.csv',\\\n",
    "                 converters = {'DisbursementGross':fixvals,'SBA_Appv':fixvals,\\\n",
    "                              'GrAppv':fixvals, 'ChgOffPrinGr':fixvals},\\\n",
    "                              parse_dates=['DisbursementDate'], \\\n",
    "                              low_memory=False)\n",
    "\n",
    "# Convert dtype of some columns that will be used in calculation or string extraction\n",
    "sba = sba.astype({'DisbursementGross':np.float64,'SBA_Appv':np.float64,\\\n",
    "                              'GrAppv':np.float64, 'ChgOffPrinGr':np.float64, 'NAICS':np.str_})\n",
    "\n",
    "print(\"Shape of SBA : \", sba.shape)\n",
    "print(sba.info(memory_usage = 'deep'))\n",
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conv_dtype\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.1 EDA Tools</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SweetViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetSweetVizReport(sba)\n",
    "\n",
    "print()\n",
    "(kaggle_flag == 1) and create_download_link('Open SweetViz Report in browser ---> ',\\\n",
    "                                            f'{savepath}SBA_sweetviz_report_before.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Profiler\n",
    "- this seems to be buggy as at Apr 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T06:56:13.293814Z",
     "iopub.status.busy": "2022-03-26T06:56:13.293144Z",
     "iopub.status.idle": "2022-03-26T07:00:04.506283Z",
     "shell.execute_reply": "2022-03-26T07:00:04.505438Z",
     "shell.execute_reply.started": "2022-03-26T06:56:13.293773Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For a better experience, the report is created as an html file that can be opened in a browser,\n",
    "and downloaded from there  (Save As ..., html)\n",
    "'''\n",
    "def GetPandasProfiling():\n",
    "    print(f'{color.bdblue}Please wait ... Profiling Report will take some time.{color.end}')\n",
    "\n",
    "    df = sba.copy()\n",
    "    # uncomment if one wants to see the report in a cell below\n",
    "    # df.profile_report(title='SBA Pandas Profiling Report')\n",
    "\n",
    "    try:\n",
    "        profile = df.profile_report(title='SBA Pandas Profiling Report', progress_bar=False,\\\n",
    "                                    correlations={\n",
    "                                        \"pearson\": {\"calculate\": True},\n",
    "                                        \"spearman\": {\"calculate\": True},\n",
    "                                        \"kendall\": {\"calculate\": False},\n",
    "                                        \"phi_k\": {\"calculate\": True}\n",
    "                                        })\n",
    "        profile.to_file(output_file = f'{savepath}SBA_Profiling_Report.html')\n",
    "        print(f'{color.bdblue}Profiling Report completed.{color.end}')\n",
    "        print()\n",
    "        (kaggle_flag == 0) and print(f'SBA Profiling Report has been downloaded to path {savepath}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "'''\n",
    "GetPandasProfiling()\n",
    "\n",
    "gc.collect()\n",
    "print()\n",
    "(kaggle_flag == 1) and create_download_link('Open SBA Profiling Report in browser ---> ', \\\n",
    "                           f'{savepath}SBA_Profiling_Report.html')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataPrep\n",
    "- this also seems buggy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.datasets import load_dataset\n",
    "from dataprep.eda import create_report\n",
    "\n",
    "def GetDataPrepReport():\n",
    "    print('Please wait, generating DataPrep report')\n",
    "    try:\n",
    "        df = sba.copy()\n",
    "        report = create_report(df, title='SBA DataPrep Report', progress = False);\n",
    "        report.save(f'{savepath}sba_dataprep_report')\n",
    "    \n",
    "        (kaggle_flag == 0) and report.show_browser()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        \n",
    "'''\n",
    "GetDataPrepReport()\n",
    "gc.collect()\n",
    "\n",
    "# open html in browser, and from there, one can download using Save As, html   \n",
    "(kaggle_flag == 1) and create_download_link('SBA DataPrep Report in browser ---> ',\\\n",
    "                                             f'{savepath}sba_dataprep_report.html');\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del conv_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"drop_rows_cols\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.2 Drop rows or columns if needed</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Check for na's in all columns, as well as invalid categories</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:13.463953Z",
     "iopub.status.busy": "2022-03-26T07:00:13.463668Z",
     "iopub.status.idle": "2022-03-26T07:00:42.850961Z",
     "shell.execute_reply": "2022-03-26T07:00:42.850202Z",
     "shell.execute_reply.started": "2022-03-26T07:00:13.463917Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_cols_with_nulls(sba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:42.853188Z",
     "iopub.status.busy": "2022-03-26T07:00:42.852659Z",
     "iopub.status.idle": "2022-03-26T07:00:43.912833Z",
     "shell.execute_reply": "2022-03-26T07:00:43.912130Z",
     "shell.execute_reply.started": "2022-03-26T07:00:42.853144Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'{color.bdunl}Features with NA values{color.end}')\n",
    "sba.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The number of Na's in rows for the following features, with respect to the size of the database, are not many and can be dropped.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:43.918630Z",
     "iopub.status.busy": "2022-03-26T07:00:43.918424Z",
     "iopub.status.idle": "2022-03-26T07:00:44.860861Z",
     "shell.execute_reply": "2022-03-26T07:00:44.859947Z",
     "shell.execute_reply.started": "2022-03-26T07:00:43.918604Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.dropna(subset=['DisbursementDate', 'NewExist', 'City', 'State',\\\n",
    "                        'LowDoc', 'Name', 'NAICS', 'CreateJob', 'RetainedJob', 'FranchiseCode',\\\n",
    "                        'UrbanRural', 'NoEmp', 'Term', 'MIS_Status'], how='any', inplace=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:44.862514Z",
     "iopub.status.busy": "2022-03-26T07:00:44.862205Z",
     "iopub.status.idle": "2022-03-26T07:00:45.926961Z",
     "shell.execute_reply": "2022-03-26T07:00:45.926201Z",
     "shell.execute_reply.started": "2022-03-26T07:00:44.862473Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>RevLineCr</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:45.928454Z",
     "iopub.status.busy": "2022-03-26T07:00:45.928149Z",
     "iopub.status.idle": "2022-03-26T07:00:46.235803Z",
     "shell.execute_reply": "2022-03-26T07:00:46.234924Z",
     "shell.execute_reply.started": "2022-03-26T07:00:45.928412Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba[(sba['RevLineCr'] != 'Y') & (sba['RevLineCr'] != 'N')])\n",
    "# too many unknowns, we will drop 'RevlineCr' later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>LowDoc</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:46.237590Z",
     "iopub.status.busy": "2022-03-26T07:00:46.237314Z",
     "iopub.status.idle": "2022-03-26T07:00:46.475646Z",
     "shell.execute_reply": "2022-03-26T07:00:46.474772Z",
     "shell.execute_reply.started": "2022-03-26T07:00:46.237552Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba[(sba['LowDoc'] != 'Y') & (sba['LowDoc'] != 'N')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:46.477309Z",
     "iopub.status.busy": "2022-03-26T07:00:46.477010Z",
     "iopub.status.idle": "2022-03-26T07:00:47.561923Z",
     "shell.execute_reply": "2022-03-26T07:00:47.561128Z",
     "shell.execute_reply.started": "2022-03-26T07:00:46.477270Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='LowDoc',data=sba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **LowDoc seems to have a bearing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:47.563329Z",
     "iopub.status.busy": "2022-03-26T07:00:47.563062Z",
     "iopub.status.idle": "2022-03-26T07:00:48.167696Z",
     "shell.execute_reply": "2022-03-26T07:00:48.166977Z",
     "shell.execute_reply.started": "2022-03-26T07:00:47.563291Z"
    }
   },
   "outputs": [],
   "source": [
    "# we can drop rows that are not 'Y' or 'N'\n",
    "sba = sba[(sba['LowDoc'] == 'Y') | (sba['LowDoc'] == 'N')]\n",
    "len(sba[(sba['LowDoc'] != 'Y') & (sba['LowDoc'] != 'N')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>NewExist</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:48.169430Z",
     "iopub.status.busy": "2022-03-26T07:00:48.169138Z",
     "iopub.status.idle": "2022-03-26T07:00:48.182602Z",
     "shell.execute_reply": "2022-03-26T07:00:48.181921Z",
     "shell.execute_reply.started": "2022-03-26T07:00:48.169393Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba[(sba['NewExist'] != 1) & (sba['NewExist'] != 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:48.184583Z",
     "iopub.status.busy": "2022-03-26T07:00:48.183966Z",
     "iopub.status.idle": "2022-03-26T07:00:48.422203Z",
     "shell.execute_reply": "2022-03-26T07:00:48.421328Z",
     "shell.execute_reply.started": "2022-03-26T07:00:48.184542Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='NewExist',data=sba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:48.426600Z",
     "iopub.status.busy": "2022-03-26T07:00:48.426103Z",
     "iopub.status.idle": "2022-03-26T07:00:48.586712Z",
     "shell.execute_reply": "2022-03-26T07:00:48.585846Z",
     "shell.execute_reply.started": "2022-03-26T07:00:48.426568Z"
    }
   },
   "outputs": [],
   "source": [
    "# records that are not 1 or 2, we can drop these rows as NewExist seems to have a bearing\n",
    "sba = sba[(sba['NewExist'] == 1) | (sba['NewExist'] == 2)]\n",
    "len(sba[(sba['NewExist'] != 1) & (sba['NewExist'] != 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sba = sba.astype({'NewExist':np.int8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>FranchiseCode</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:48.588426Z",
     "iopub.status.busy": "2022-03-26T07:00:48.588063Z",
     "iopub.status.idle": "2022-03-26T07:00:48.601481Z",
     "shell.execute_reply": "2022-03-26T07:00:48.600694Z",
     "shell.execute_reply.started": "2022-03-26T07:00:48.588385Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['FranchiseCode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>UrbanRural</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:48.603165Z",
     "iopub.status.busy": "2022-03-26T07:00:48.602908Z",
     "iopub.status.idle": "2022-03-26T07:00:48.614845Z",
     "shell.execute_reply": "2022-03-26T07:00:48.614138Z",
     "shell.execute_reply.started": "2022-03-26T07:00:48.603130Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['UrbanRural'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Term</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:48.616189Z",
     "iopub.status.busy": "2022-03-26T07:00:48.615875Z",
     "iopub.status.idle": "2022-03-26T07:00:48.630595Z",
     "shell.execute_reply": "2022-03-26T07:00:48.629914Z",
     "shell.execute_reply.started": "2022-03-26T07:00:48.616152Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sba[sba['Term'].isna()]))\n",
    "print(len(sba[sba['Term']==0]))\n",
    "print(len(sba[sba['Term']<0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:48.632063Z",
     "iopub.status.busy": "2022-03-26T07:00:48.631805Z",
     "iopub.status.idle": "2022-03-26T07:00:48.659318Z",
     "shell.execute_reply": "2022-03-26T07:00:48.658654Z",
     "shell.execute_reply.started": "2022-03-26T07:00:48.632028Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:48.660873Z",
     "iopub.status.busy": "2022-03-26T07:00:48.660624Z",
     "iopub.status.idle": "2022-03-26T07:00:49.030741Z",
     "shell.execute_reply": "2022-03-26T07:00:49.029930Z",
     "shell.execute_reply.started": "2022-03-26T07:00:48.660839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trim leading and trailing spaces\n",
    "sba['City'] = sba['City'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Check for na's in all columns</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:00:49.032515Z",
     "iopub.status.busy": "2022-03-26T07:00:49.032221Z",
     "iopub.status.idle": "2022-03-26T07:01:17.671227Z",
     "shell.execute_reply": "2022-03-26T07:01:17.670541Z",
     "shell.execute_reply.started": "2022-03-26T07:00:49.032477Z"
    }
   },
   "outputs": [],
   "source": [
    "check_cols_with_nulls(sba)\n",
    "\n",
    "# We can ignore these, features to be dropped later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:17.673417Z",
     "iopub.status.busy": "2022-03-26T07:01:17.672408Z",
     "iopub.status.idle": "2022-03-26T07:01:17.679020Z",
     "shell.execute_reply": "2022-03-26T07:01:17.678323Z",
     "shell.execute_reply.started": "2022-03-26T07:01:17.673374Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:17.681078Z",
     "iopub.status.busy": "2022-03-26T07:01:17.680592Z",
     "iopub.status.idle": "2022-03-26T07:01:18.923501Z",
     "shell.execute_reply": "2022-03-26T07:01:18.922726Z",
     "shell.execute_reply.started": "2022-03-26T07:01:17.681039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save 2\n",
    "def Save2():\n",
    "    # for feather format, reset_index(drop=True) to prevent \"Unnamed column\" being created\n",
    "    sdf = sba.copy().reset_index(drop=True)\n",
    "    sdf.to_feather(f'{savepath}sba_save2.csv.feather')\n",
    "\n",
    "    # index=False to prevent \"Unnamed Column\" being created\n",
    "    #sba.to_csv(f'{savepath}sba_save2.csv', index=False)\n",
    "    \n",
    "    print('Saved to sba_save2.csv.feather')\n",
    "\n",
    "Save2()\n",
    "\n",
    "# Short circuiting\n",
    "(kaggle_flag == 1) and FileLink(r'sba_save2.csv.feather')  # Kaggle only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"drop_duplicates\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.3 Drop Duplicate Rows</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropDuplicates():\n",
    "    dupl_series = sba.duplicated()\n",
    "    num_of_dupl = len(sba[dupl_series == True])\n",
    "    if num_of_dupl > 0:\n",
    "        print(f'Number of Duplicates : {color.bold}{num_of_dupl}{color.end}')\n",
    "        print()\n",
    "        print(sba[dupl_series].head(5))\n",
    "        sba.drop_duplicates(inplace=True)\n",
    "        print()\n",
    "        print(f'{color.bold}{num_of_dupl}{color.end} duplicate rows were dropped.')\n",
    "    else:\n",
    "        print(f'Duplicate rows found: {color.bold}None{color.end}')\n",
    "\n",
    "#DropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_new_features\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.4 Create New Features</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Industry</b> - The industry sector is the 1st 2 digits of NAICS\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:18.925104Z",
     "iopub.status.busy": "2022-03-26T07:01:18.924840Z",
     "iopub.status.idle": "2022-03-26T07:01:19.537538Z",
     "shell.execute_reply": "2022-03-26T07:01:19.536611Z",
     "shell.execute_reply.started": "2022-03-26T07:01:18.925068Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['Industry'] = sba['NAICS'].str[0:2]\n",
    "sba = sba.astype({'Industry':np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:19.539295Z",
     "iopub.status.busy": "2022-03-26T07:01:19.539029Z",
     "iopub.status.idle": "2022-03-26T07:01:19.548179Z",
     "shell.execute_reply": "2022-03-26T07:01:19.547312Z",
     "shell.execute_reply.started": "2022-03-26T07:01:19.539244Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['Industry'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:19.550327Z",
     "iopub.status.busy": "2022-03-26T07:01:19.550049Z",
     "iopub.status.idle": "2022-03-26T07:01:19.562812Z",
     "shell.execute_reply": "2022-03-26T07:01:19.562165Z",
     "shell.execute_reply.started": "2022-03-26T07:01:19.550291Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['Industry'].unique()\n",
    "# There is an invalid industry shown which is '0', caused by blank NAICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:19.565386Z",
     "iopub.status.busy": "2022-03-26T07:01:19.564972Z",
     "iopub.status.idle": "2022-03-26T07:01:19.832727Z",
     "shell.execute_reply": "2022-03-26T07:01:19.831780Z",
     "shell.execute_reply.started": "2022-03-26T07:01:19.565356Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sba[sba['Industry'] == 0])\n",
    "# This is a bummer, as industry sector has a big effect on a business, speaking as a business \n",
    "# domain expert.  Do we drop those with NAICS = 0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:19.834598Z",
     "iopub.status.busy": "2022-03-26T07:01:19.834225Z",
     "iopub.status.idle": "2022-03-26T07:01:19.862304Z",
     "shell.execute_reply": "2022-03-26T07:01:19.861316Z",
     "shell.execute_reply.started": "2022-03-26T07:01:19.834555Z"
    }
   },
   "outputs": [],
   "source": [
    "# At this stage, we leave it as is and treat it as unknown industry\n",
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:19.864167Z",
     "iopub.status.busy": "2022-03-26T07:01:19.863799Z",
     "iopub.status.idle": "2022-03-26T07:01:20.679546Z",
     "shell.execute_reply": "2022-03-26T07:01:20.678740Z",
     "shell.execute_reply.started": "2022-03-26T07:01:19.864124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if we can impute from the name.  For example, a bar (or similar) business\n",
    "sba[(sba['Name'].str.contains('bar',case=False)) & (sba['Industry'] == 0)]\\\n",
    "    [['Name','Industry']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's not feasible to impute missing Industry codes efficiently, so we abandon the idea.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Recession</b><br>\n",
    "We want to account for variation due to the Great Recession (December 2007 to June 2009). Should we separate the datasets into different time periods ? Before, During, and After ?  Let's check how large the sets are later.  In the meantime, we create a new feature, Recession, with 1 for 'Y' and 0 for 'N' depending on the DisbursementDate. \n",
    "<br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:20.681481Z",
     "iopub.status.busy": "2022-03-26T07:01:20.681165Z",
     "iopub.status.idle": "2022-03-26T07:01:20.686600Z",
     "shell.execute_reply": "2022-03-26T07:01:20.685660Z",
     "shell.execute_reply.started": "2022-03-26T07:01:20.681439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert \"DisbursementDate\" to datetime\n",
    "\n",
    "# sba['DisbursementDate'] = pd.to_datetime(sba['DisbursementDate'], format='%d-%b-%y')\n",
    "\n",
    "# sba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:20.688511Z",
     "iopub.status.busy": "2022-03-26T07:01:20.687897Z",
     "iopub.status.idle": "2022-03-26T07:01:20.706707Z",
     "shell.execute_reply": "2022-03-26T07:01:20.705899Z",
     "shell.execute_reply.started": "2022-03-26T07:01:20.688463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new column based on condition\n",
    "sba['Recession'] = np.where((sba['DisbursementDate'] >= '2007-09-01')\\\n",
    "                     & (sba['DisbursementDate'] <= '2009-06-30'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:20.708711Z",
     "iopub.status.busy": "2022-03-26T07:01:20.708043Z",
     "iopub.status.idle": "2022-03-26T07:01:20.921710Z",
     "shell.execute_reply": "2022-03-26T07:01:20.920741Z",
     "shell.execute_reply.started": "2022-03-26T07:01:20.708665Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Total - {len(sba)}')\n",
    "y = len(sba[sba['Recession'] == 1])\n",
    "n = len(sba[sba['Recession'] == 0])\n",
    "print(f'Recession - {y}')\n",
    "print(f'Not Recession - {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Real Estate</b><br>\n",
    "Loans backed by real estate will have terms 20 years or greater (240 months) and are the only loans granted for such a long term, whereas loans not backed by real estate will have terms less than 20 years ( < 240 months).<br><br>\n",
    "1 - Backed By Real Estate<br>\n",
    "0 - Not Backed By Real Estate<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:20.923721Z",
     "iopub.status.busy": "2022-03-26T07:01:20.923412Z",
     "iopub.status.idle": "2022-03-26T07:01:20.935631Z",
     "shell.execute_reply": "2022-03-26T07:01:20.934716Z",
     "shell.execute_reply.started": "2022-03-26T07:01:20.923670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new column based on condition\n",
    "sba['RealEstate'] = np.where(sba['Term'] >= 240, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:20.937445Z",
     "iopub.status.busy": "2022-03-26T07:01:20.937095Z",
     "iopub.status.idle": "2022-03-26T07:01:21.165305Z",
     "shell.execute_reply": "2022-03-26T07:01:21.164470Z",
     "shell.execute_reply.started": "2022-03-26T07:01:20.937404Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Total - {len(sba)}')\n",
    "y = len(sba[sba['RealEstate'] == 1])\n",
    "n = len(sba[sba['RealEstate'] == 0])\n",
    "print(f'Yes - {y}')\n",
    "print(f'No - {n}')\n",
    "print(f'Yes and No - {y+n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>SBA_Portion</b><br>\n",
    "The portion which is the percentage of the loan that is guaranteed by SBA. This is derived by calculating the ratio of the amount of the loan SBA guarantees and the gross amount approved by the bank (SBA_Appv/GrAppv) * 100.<br><br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:21.167110Z",
     "iopub.status.busy": "2022-03-26T07:01:21.166833Z",
     "iopub.status.idle": "2022-03-26T07:01:21.196950Z",
     "shell.execute_reply": "2022-03-26T07:01:21.196111Z",
     "shell.execute_reply.started": "2022-03-26T07:01:21.167072Z"
    }
   },
   "outputs": [],
   "source": [
    "sba['SBA_Portion']=(sba['SBA_Appv']/sba['GrAppv']) * 100\n",
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CityState**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:21.198825Z",
     "iopub.status.busy": "2022-03-26T07:01:21.198545Z",
     "iopub.status.idle": "2022-03-26T07:01:21.607024Z",
     "shell.execute_reply": "2022-03-26T07:01:21.606323Z",
     "shell.execute_reply.started": "2022-03-26T07:01:21.198788Z"
    }
   },
   "outputs": [],
   "source": [
    "sba[\"CityState\"] = sba[\"City\"] + \"_\" + sba[\"State\"]\n",
    "sba[[\"CityState\", \"City\", \"State\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:21.608703Z",
     "iopub.status.busy": "2022-03-26T07:01:21.608448Z",
     "iopub.status.idle": "2022-03-26T07:01:21.632165Z",
     "shell.execute_reply": "2022-03-26T07:01:21.631234Z",
     "shell.execute_reply.started": "2022-03-26T07:01:21.608668Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:21.634124Z",
     "iopub.status.busy": "2022-03-26T07:01:21.633841Z",
     "iopub.status.idle": "2022-03-26T07:01:23.267717Z",
     "shell.execute_reply": "2022-03-26T07:01:23.266939Z",
     "shell.execute_reply.started": "2022-03-26T07:01:21.634083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save 3\n",
    "def Save3():\n",
    "    sdf = sba.copy().reset_index(drop=True)\n",
    "    sdf.to_feather(f'{savepath}sba_save3.csv.feather')\n",
    "\n",
    "    print('Saved to sba_save3.csv.feather')\n",
    "    \n",
    "Save3()\n",
    "\n",
    "(kaggle_flag == 1) and FileLink(r'sba_save3.csv.feather')  # Kaggle only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"encode_cat\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.5 Encode Categorical Features</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:23.269499Z",
     "iopub.status.busy": "2022-03-26T07:01:23.268947Z",
     "iopub.status.idle": "2022-03-26T07:01:24.434503Z",
     "shell.execute_reply": "2022-03-26T07:01:24.433802Z",
     "shell.execute_reply.started": "2022-03-26T07:01:23.269458Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.select_dtypes([\"object\"]).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:Chocolate;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>MIS_Status</b><br>\n",
    "    This will be the <b>target</b> variable</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:24.436530Z",
     "iopub.status.busy": "2022-03-26T07:01:24.435657Z",
     "iopub.status.idle": "2022-03-26T07:01:25.553877Z",
     "shell.execute_reply": "2022-03-26T07:01:25.553125Z",
     "shell.execute_reply.started": "2022-03-26T07:01:24.436488Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "# Target variable is MIS Status, a categorical variable\n",
    "\n",
    "print(sba['MIS_Status'].value_counts())\n",
    "sns.countplot(x='MIS_Status',data=sba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    This shows a skewed distribution, where this bias in the target can influence many machine learning algorithms, leading some to ignore the minority class entirely, in this case, CHGOFF.  Before oversampling the data, will try as is.<br><br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:25.555353Z",
     "iopub.status.busy": "2022-03-26T07:01:25.555058Z",
     "iopub.status.idle": "2022-03-26T07:01:25.740193Z",
     "shell.execute_reply": "2022-03-26T07:01:25.739396Z",
     "shell.execute_reply.started": "2022-03-26T07:01:25.555313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update column based on condition\n",
    "sba['MIS_Status'] = np.where((sba['MIS_Status'] == 'P I F'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:25.742027Z",
     "iopub.status.busy": "2022-03-26T07:01:25.741738Z",
     "iopub.status.idle": "2022-03-26T07:01:25.753703Z",
     "shell.execute_reply": "2022-03-26T07:01:25.752831Z",
     "shell.execute_reply.started": "2022-03-26T07:01:25.741988Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sba['MIS_Status'].dtype)\n",
    "sba.head(2)[['City','MIS_Status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>LowDoc</b><br>\n",
    "'Y' = 1<br>\n",
    "'N' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:25.755553Z",
     "iopub.status.busy": "2022-03-26T07:01:25.755248Z",
     "iopub.status.idle": "2022-03-26T07:01:25.985306Z",
     "shell.execute_reply": "2022-03-26T07:01:25.984325Z",
     "shell.execute_reply.started": "2022-03-26T07:01:25.755513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update column based on condition\n",
    "sba['LowDoc'] = np.where((sba['LowDoc'] == 'Y'), 1, 0)\n",
    "\n",
    "sba.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Others</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:25.987108Z",
     "iopub.status.busy": "2022-03-26T07:01:25.986837Z",
     "iopub.status.idle": "2022-03-26T07:01:30.292797Z",
     "shell.execute_reply": "2022-03-26T07:01:30.292018Z",
     "shell.execute_reply.started": "2022-03-26T07:01:25.987071Z"
    }
   },
   "outputs": [],
   "source": [
    "# will not hash 'City' as it is already covered by 'CityState'\n",
    "\n",
    "def HashCol():\n",
    "    cols_to_drop = []\n",
    "    hash_constant = 900000   # fixed value so we can programmatically reproduce the hash when needed\n",
    "    len_data=len(sba)\n",
    "    for col in sba[['State','CityState']]:\n",
    "        if sba[col].dtype == 'object':\n",
    "            print(f'Column {col} has {sba[col].nunique()} values among {len_data}')\n",
    "\n",
    "        if sba[col].nunique() < 25:\n",
    "            print(f'One-hot encoding of {col}')\n",
    "            one_hot_cols = pd.get_dummies(sba[col])\n",
    "            for ohc in one_hot_cols.columns:\n",
    "                sba[col + '_' + ohc] = one_hot_cols[ohc]\n",
    "        else:\n",
    "            print(f'Hashing of {col}')\n",
    "            sba[col + '_hash'] = sba[col].apply(lambda row: int(hashlib.sha1((col + \"_\" + \\\n",
    "                                    str(row)).encode('utf-8')).hexdigest(), 16) % hash_constant)\n",
    "\n",
    "        cols_to_drop.append(col)\n",
    "    print(cols_to_drop)\n",
    "\n",
    "HashCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:30.295972Z",
     "iopub.status.busy": "2022-03-26T07:01:30.293977Z",
     "iopub.status.idle": "2022-03-26T07:01:30.306420Z",
     "shell.execute_reply": "2022-03-26T07:01:30.305706Z",
     "shell.execute_reply.started": "2022-03-26T07:01:30.295938Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.head(2)[['State','CityState','State_hash','CityState_hash']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:30.308415Z",
     "iopub.status.busy": "2022-03-26T07:01:30.307656Z",
     "iopub.status.idle": "2022-03-26T07:01:31.287787Z",
     "shell.execute_reply": "2022-03-26T07:01:31.286292Z",
     "shell.execute_reply.started": "2022-03-26T07:01:30.308375Z"
    }
   },
   "outputs": [],
   "source": [
    "sba.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>TimeFrame</b><br>\n",
    "Create a dataset for later use where we restrict the time frame to loans by excluding those disbursed after 2010 due to the fact the term of a loan is frequently 5 or more years.\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:31.289343Z",
     "iopub.status.busy": "2022-03-26T07:01:31.289080Z",
     "iopub.status.idle": "2022-03-26T07:01:31.738999Z",
     "shell.execute_reply": "2022-03-26T07:01:31.738137Z",
     "shell.execute_reply.started": "2022-03-26T07:01:31.289311Z"
    }
   },
   "outputs": [],
   "source": [
    "sba_bef_2011 = sba[sba['DisbursementDate'] <= '2010-12-31'].copy()\n",
    "len(sba_bef_2011[sba_bef_2011['DisbursementDate'] > '2010-12-31'])\n",
    "len(sba_bef_2011[sba_bef_2011['DisbursementDate'] <= '2011-01-01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Drop columns that are no longer needed<b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:31.741144Z",
     "iopub.status.busy": "2022-03-26T07:01:31.740510Z",
     "iopub.status.idle": "2022-03-26T07:01:33.159330Z",
     "shell.execute_reply": "2022-03-26T07:01:33.158537Z",
     "shell.execute_reply.started": "2022-03-26T07:01:31.741101Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save 4\n",
    "def Save4():\n",
    "    sdf = sba.copy().reset_index(drop=True)\n",
    "    sdf.to_feather(f'{savepath}sba_save4.csv.feather')\n",
    "\n",
    "    print('saved to sba_save4.csv.feather')\n",
    "\n",
    "Save4()\n",
    "\n",
    "(kaggle_flag == 1) and FileLink(r'sba_save4.csv.feather')  # Kaggle only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:33.161132Z",
     "iopub.status.busy": "2022-03-26T07:01:33.160711Z",
     "iopub.status.idle": "2022-03-26T07:01:33.721932Z",
     "shell.execute_reply": "2022-03-26T07:01:33.721180Z",
     "shell.execute_reply.started": "2022-03-26T07:01:33.161092Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['LoanNr_ChkDgt', 'Bank', 'BankState', 'ApprovalDate', \\\n",
    "                        'ApprovalFY', 'ChgOffDate', 'BalanceGross', 'NAICS', 'ChgOffPrinGr', \\\n",
    "                        'Name', 'RevLineCr', 'DisbursementDate', 'City', 'State', 'CityState',\\\n",
    "                         'GrAppv','Zip']\n",
    "\n",
    "sba_bef_2011.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "sba.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "sba_bef_2011 = reduce_mem_usage(sba_bef_2011)\n",
    "\n",
    "print()\n",
    "sba = reduce_mem_usage(sba)\n",
    "\n",
    "print()\n",
    "print('Unneeded Columns Dropped')\n",
    "print(sba.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:33.723952Z",
     "iopub.status.busy": "2022-03-26T07:01:33.723455Z",
     "iopub.status.idle": "2022-03-26T07:01:34.582278Z",
     "shell.execute_reply": "2022-03-26T07:01:34.581512Z",
     "shell.execute_reply.started": "2022-03-26T07:01:33.723912Z"
    }
   },
   "outputs": [],
   "source": [
    "def SaveBef2011():\n",
    "    # Save sba_bef_2011\n",
    "    ## save this dataset to working dir\n",
    "    sdf = sba_bef_2011.copy().reset_index(drop=True)\n",
    "    sdf.to_feather(f'{savepath}sba_bef_2011.csv.feather')\n",
    "\n",
    "    print(\"saved to sba_bef_2011.csv.feather\")\n",
    "    \n",
    "SaveBef2011()\n",
    "\n",
    "(kaggle_flag == 1) and FileLink(r'sba_bef_2011.csv.feather')  # Kaggle only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sba_bef_2011\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:34.584443Z",
     "iopub.status.busy": "2022-03-26T07:01:34.583633Z",
     "iopub.status.idle": "2022-03-26T07:01:34.736865Z",
     "shell.execute_reply": "2022-03-26T07:01:34.735963Z",
     "shell.execute_reply.started": "2022-03-26T07:01:34.584401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save 5\n",
    "def Save5():\n",
    "    sdf = sba.copy().reset_index(drop=True)\n",
    "    sdf.to_feather(f'{savepath}sba_save5.csv.feather')\n",
    "\n",
    "    print('saved to sba_save5.csv.feather')\n",
    "\n",
    "Save5()\n",
    "\n",
    "(kaggle_flag == 1) and FileLink(r'sba_save5.csv.feather')  # Kaggle only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Check for Infinite Values<b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:34.738784Z",
     "iopub.status.busy": "2022-03-26T07:01:34.738343Z",
     "iopub.status.idle": "2022-03-26T07:01:34.786065Z",
     "shell.execute_reply": "2022-03-26T07:01:34.785186Z",
     "shell.execute_reply.started": "2022-03-26T07:01:34.738743Z"
    }
   },
   "outputs": [],
   "source": [
    "check_infinity_nan(sba,'sba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Check Correlations</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:34.788452Z",
     "iopub.status.busy": "2022-03-26T07:01:34.787596Z",
     "iopub.status.idle": "2022-03-26T07:01:37.169046Z",
     "shell.execute_reply": "2022-03-26T07:01:37.168312Z",
     "shell.execute_reply.started": "2022-03-26T07:01:34.788402Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "g = sns.heatmap(\n",
    "    sba.corr(),\n",
    "    annot=True,\n",
    "    ax=ax,\n",
    "    cmap='OrRd',\n",
    "    cbar=False,\n",
    "    linewidth=1\n",
    ")\n",
    "\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eda_check\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>2.6 EDA Check</h2><br>\n",
    "    Here we generate a SweetViz report for another EDA review\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetSweetVizReport(sba)\n",
    "\n",
    "print()\n",
    "(kaggle_flag == 1) and create_download_link('Open SweetViz Report in browser ---> ',\\\n",
    "                                            f'{savepath}SBA_sweetviz_report_after.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:37.171190Z",
     "iopub.status.busy": "2022-03-26T07:01:37.170714Z",
     "iopub.status.idle": "2022-03-26T07:01:37.378722Z",
     "shell.execute_reply": "2022-03-26T07:01:37.377966Z",
     "shell.execute_reply.started": "2022-03-26T07:01:37.171150Z"
    }
   },
   "outputs": [],
   "source": [
    "del sba\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_model\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3. Build Model Using XGBoost</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 5px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Early Stopping Rounds<b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"<b>Overfitting</b> is a problem with sophisticated non-linear learning algorithms like gradient boosting.  Early stopping is an approach to training complex machine learning models to avoid overfitting.\n",
    "<br><br>\n",
    "<b>XGBoost supports early stopping after a fixed number of iterations.</b>  In addition to specifying a metric and test dataset for evaluation in each epoch, one must specify a window of the number of epochs over which no improvement is observed. This is specified in the early_stopping_rounds parameter.\n",
    "<br><br>\n",
    "It is generally a good idea to select the early_stopping_rounds as a reasonable function of the total number of training epochs (10% in this case) or attempt to correspond to the period of inflection points as might be observed on plots of learning curves.\n",
    "<br><br> - <a href = \"https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/\">Avoid Overfitting By Early Stopping With XGBoost In Python</a>\n",
    "<br><br>\n",
    "In the <a href=\"#xgboost_class\">XGBoost class</a> created earlier, n_estimators = 4000.  400 is used as the value for early_stopping_rounds during fitting, 10% of 4000. \n",
    "<br><br>\n",
    "We can also check by plotting, shown in the <a href = \"#early_stopping_rounds\">Early Stopping Rounds section</a> near the end of this notebook, for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model1\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3.1 Model v1</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:37.380705Z",
     "iopub.status.busy": "2022-03-26T07:01:37.380219Z",
     "iopub.status.idle": "2022-03-26T07:01:37.604899Z",
     "shell.execute_reply": "2022-03-26T07:01:37.604176Z",
     "shell.execute_reply.started": "2022-03-26T07:01:37.380653Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv1():\n",
    "    # Select subset of predictors\n",
    "    X = pd.read_feather(f'{savepath}sba_save5.csv.feather')\n",
    "\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model1 = process_model(X, y)\n",
    "    model1.split_data(0.7)\n",
    "    model1.prep_run_model( \"Metrics : Full SBA Not Oversampled\")\n",
    "    print()\n",
    "    \n",
    "RunModelv1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">  \n",
    "<b>Accuracy for model is good; but ...</b> Precision, Recall, and f1-score of minority class 0 (CHGOFF) is <b>much lower</b> than that of 1 (P I F). This is because MIS_Status is heavily skewed towards 1 (P I F).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "In such a scenario, <b>Accuracy is not a good metric</b>, as it favors the majority.  <b>The f1-score is the more ideal metric</b>, which correctly shows a poorer score by the minority class.<br><br>\n",
    "    To solve this, we try <b>Oversampling the data</b>, in the next section.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:37.606234Z",
     "iopub.status.busy": "2022-03-26T07:01:37.606027Z",
     "iopub.status.idle": "2022-03-26T07:01:37.612718Z",
     "shell.execute_reply": "2022-03-26T07:01:37.612057Z",
     "shell.execute_reply.started": "2022-03-26T07:01:37.606208Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"SBA Machine Learning Model 1 completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"oversample\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\"><h2 style='color:GhostWhite;'>3.2 OverSample</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model2\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\"><h2 style='color:GhostWhite;'>3.2.1 Model v2</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:37.614527Z",
     "iopub.status.busy": "2022-03-26T07:01:37.614049Z",
     "iopub.status.idle": "2022-03-26T07:01:52.255759Z",
     "shell.execute_reply": "2022-03-26T07:01:52.255014Z",
     "shell.execute_reply.started": "2022-03-26T07:01:37.614489Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv2():\n",
    "    # Select subset of predictors\n",
    "    X = pd.read_feather(f'{savepath}sba_save5.csv.feather')\n",
    "\n",
    "    # Select target\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model2 = process_model(X, y)\n",
    "    model2.osample()             # oversampling method\n",
    "    model2.split_data(0.7)\n",
    "    model2_results = model2.prep_run_model(\"Metrics : Full SBA Oversampled\")\n",
    "\n",
    "    return model2_results['xg_model']\n",
    "\n",
    "modelv2 = RunModelv2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    After oversampling of the minority class, class 0 (CHGOFF) <b>now has a similar </b> precision, recall, and f1-score as class 1 (P I F).\n",
    "<br><br>     \n",
    "    The <b>accuracy score</b> is slightly lower than when not oversampled, but much better f-scores.  This should be a good metric now as the target classification is no longer imbalanced.  <b>The model is now more accurate in predicting the target as f-scores are better now.</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:52.257499Z",
     "iopub.status.busy": "2022-03-26T07:01:52.257067Z",
     "iopub.status.idle": "2022-03-26T07:01:52.263980Z",
     "shell.execute_reply": "2022-03-26T07:01:52.263158Z",
     "shell.execute_reply.started": "2022-03-26T07:01:52.257458Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"SBA Machine Learning Model 2 completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:52.266288Z",
     "iopub.status.busy": "2022-03-26T07:01:52.265731Z",
     "iopub.status.idle": "2022-03-26T07:01:54.435985Z",
     "shell.execute_reply": "2022-03-26T07:01:54.435344Z",
     "shell.execute_reply.started": "2022-03-26T07:01:52.266241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "\n",
    "plot_features(modelv2, (10,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Observation</b><br>\n",
    "    I was hoping to see <b>Industry</b> at a much higher position here, but apparently the incomplete data on industry had an effect.<br><br>\n",
    "Furthermore, <b>Recession</b> has to be at a very high position, but is at the bottom instead.  This could be due to <b>Recession</b> data being highly skewed towards 1 (Not Recession).<br><br>\n",
    "<b>Real Estate</b> should have good importance too, but it may be highly skewed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:54.437401Z",
     "iopub.status.busy": "2022-03-26T07:01:54.437039Z",
     "iopub.status.idle": "2022-03-26T07:01:54.651370Z",
     "shell.execute_reply": "2022-03-26T07:01:54.650654Z",
     "shell.execute_reply.started": "2022-03-26T07:01:54.437368Z"
    }
   },
   "outputs": [],
   "source": [
    "del modelv2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model3\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3.2.2 Model v3</h2>\n",
    "    <b>Build a Model Dataset Excluding Year 2011 and Above</b>\n",
    "\n",
    "We restrict the time frame to loans by excluding those disbursed after 2010 due to the fact the term of a loan is frequently 5 or more years.\n",
    "       </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:01:54.659325Z",
     "iopub.status.busy": "2022-03-26T07:01:54.659095Z",
     "iopub.status.idle": "2022-03-26T07:02:08.590739Z",
     "shell.execute_reply": "2022-03-26T07:02:08.589892Z",
     "shell.execute_reply.started": "2022-03-26T07:01:54.659298Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv3():\n",
    "    X = pd.read_feather(f'{savepath}sba_bef_2011.csv.feather')\n",
    "\n",
    "    # Select target\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model3 = process_model(X, y)\n",
    "    model3.osample()\n",
    "    model3.split_data(0.7)\n",
    "    model3_results = model3.prep_run_model(\"Metrics : SBA Before 2011 Oversampled\")\n",
    "\n",
    "    return model3_results\n",
    "    \n",
    "model3_results = RunModelv3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>We get a similar score to Model 2.</b>  Will use this dataset as the last dataset, for now.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:10.935958Z",
     "iopub.status.busy": "2022-03-26T07:02:10.935609Z",
     "iopub.status.idle": "2022-03-26T07:02:11.120965Z",
     "shell.execute_reply": "2022-03-26T07:02:11.120116Z",
     "shell.execute_reply.started": "2022-03-26T07:02:10.935925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save 6 - final cleaned csv\n",
    "def SaveFinalCsv():\n",
    "    #sdf = pd.read_csv(f'{savepath}sba_bef_2011.csv')\n",
    "    #sdf.to_csv(f'{savepath}sba_final.csv', index=False)\n",
    "    \n",
    "    src_file=f'{savepath}sba_bef_2011.csv.feather'\n",
    "    dst_file=f'{savepath}sba_final.csv.feather'\n",
    "    shutil.copy2(src_file, dst_file)\n",
    "\n",
    "    print('saved to sba_final.csv.feather')\n",
    "\n",
    "SaveFinalCsv()\n",
    "(kaggle_flag == 1) and FileLink(r'sba_final.csv.feather')  # Kaggle only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:08.594187Z",
     "iopub.status.busy": "2022-03-26T07:02:08.593947Z",
     "iopub.status.idle": "2022-03-26T07:02:08.604336Z",
     "shell.execute_reply": "2022-03-26T07:02:08.603337Z",
     "shell.execute_reply.started": "2022-03-26T07:02:08.594157Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"SBA Machine Learning Model 3 completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:08.606556Z",
     "iopub.status.busy": "2022-03-26T07:02:08.606173Z",
     "iopub.status.idle": "2022-03-26T07:02:10.934548Z",
     "shell.execute_reply": "2022-03-26T07:02:10.933879Z",
     "shell.execute_reply.started": "2022-03-26T07:02:08.606512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "modelv3 = model3_results['xg_model']\n",
    "plot_features(modelv3, (10,14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T05:18:58.418572Z",
     "iopub.status.busy": "2022-03-12T05:18:58.418154Z",
     "iopub.status.idle": "2022-03-12T05:18:58.448155Z",
     "shell.execute_reply": "2022-03-12T05:18:58.447213Z",
     "shell.execute_reply.started": "2022-03-12T05:18:58.418473Z"
    }
   },
   "source": [
    "<a id=\"test_model\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4. Test Model</h2>\n",
    "    </div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_test_dataset\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4.1 Test Model with Test Dataset</h2>\n",
    "    Test Dataset was previously unseen by the model.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:11.123485Z",
     "iopub.status.busy": "2022-03-26T07:02:11.122709Z",
     "iopub.status.idle": "2022-03-26T07:02:11.127896Z",
     "shell.execute_reply": "2022-03-26T07:02:11.127068Z",
     "shell.execute_reply.started": "2022-03-26T07:02:11.123444Z"
    }
   },
   "outputs": [],
   "source": [
    "def Modelv3WithTestData():\n",
    "    X_test = model3_results['X_test']\n",
    "    y_test = model3_results['y_test']\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = modelv3.predict(X_test)\n",
    "    model_eval(y_test, predictions);\n",
    "    \n",
    "Modelv3WithTestData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_user_input\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4.2 Test Model with User Input</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">So let's assume the following are <b>the entries of a user</b>, through a user interface, looking for a prediction from our model.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:15.268223Z",
     "iopub.status.busy": "2022-03-26T07:02:15.267969Z",
     "iopub.status.idle": "2022-03-26T07:02:15.284708Z",
     "shell.execute_reply": "2022-03-26T07:02:15.283969Z",
     "shell.execute_reply.started": "2022-03-26T07:02:15.268184Z"
    }
   },
   "outputs": [],
   "source": [
    "def UserInputTest():\n",
    "    # 16 entries\n",
    "    user_input =   {'Term':50, \n",
    "                    'NoEmp':0,\n",
    "                    'NewExist':1,\n",
    "                    'CreateJob':0 ,          \n",
    "                    'RetainedJob':0,         \n",
    "                    'FranchiseCode':1,       \n",
    "                    'UrbanRural':0,           \n",
    "                    'LowDoc':0,               \n",
    "                    'DisbursementGross':50000,                 \n",
    "                    'SBA_Appv':25000,          \n",
    "                    'Industry':71, \n",
    "                    'Recession':0,\n",
    "                    'RealEstate':0,           \n",
    "                    'SBA_Portion':50,\n",
    "                    'City':'EVANSVILLE',\n",
    "                    'State':'IN'\n",
    "                   }\n",
    "\n",
    "    city = user_input['City']\n",
    "    state = user_input['State']\n",
    "    city_state = f'{city}_{state}'\n",
    "\n",
    "    state_hash = int(hashlib.sha1(('State' + \"_\" + \\\n",
    "                              str(state)).encode('utf-8')).hexdigest(), 16) % 900000\n",
    "    city_state_hash = int(hashlib.sha1(('CityState' + \"_\" + \\\n",
    "                              str(city_state)).encode('utf-8')).hexdigest(), 16) % 900000\n",
    "\n",
    "    print(f'State_hash = {state_hash}')\n",
    "    print(f'CityState_hash = {city_state_hash}')\n",
    "\n",
    "    user_input.pop('City')\n",
    "    user_input.pop('State')\n",
    "    user_input['State_hash'] = state_hash\n",
    "    user_input['CityState_hash'] = city_state_hash\n",
    "\n",
    "    user_input_list = list(user_input.values())\n",
    "    \n",
    "    return {'user_input':user_input, 'user_input_list':user_input_list}\n",
    "\n",
    "user_input_param = UserInputTest()\n",
    "\n",
    "print()\n",
    "print(f\"{color.bold}User Entry:{color.end}\")\n",
    "user_input_param['user_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:15.286586Z",
     "iopub.status.busy": "2022-03-26T07:02:15.286149Z",
     "iopub.status.idle": "2022-03-26T07:02:15.297666Z",
     "shell.execute_reply": "2022-03-26T07:02:15.296908Z",
     "shell.execute_reply.started": "2022-03-26T07:02:15.286547Z"
    }
   },
   "outputs": [],
   "source": [
    "# User Input test 1\n",
    "def UserInputTest1():\n",
    "    features = np.array([user_input_param['user_input_list']])   \n",
    "\n",
    "    # using inputs to predict the output\n",
    "    pred = modelv3.predict(features)\n",
    "    if pred[0] == 1:\n",
    "        print(f'{color.bdblue}Prediction: Approve The Loan{color.end}')\n",
    "    else:\n",
    "        print(f'{color.bdred}Prediction: Do Not Approve The Loan{color.end}')\n",
    "        \n",
    "UserInputTest1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:15.299514Z",
     "iopub.status.busy": "2022-03-26T07:02:15.299022Z",
     "iopub.status.idle": "2022-03-26T07:02:15.308340Z",
     "shell.execute_reply": "2022-03-26T07:02:15.307618Z",
     "shell.execute_reply.started": "2022-03-26T07:02:15.299476Z"
    }
   },
   "outputs": [],
   "source": [
    "# User Input test 2\n",
    "def UserInputTest2():\n",
    "    '''\n",
    "    # if one wants to edit the list from the previous cell\n",
    "    user_input2_list = user_input_list[:]   # make a copy\n",
    "    user_input2_list[0] = 500          # change term \n",
    "    '''\n",
    "\n",
    "    user_input2 = copy.deepcopy(user_input_param['user_input'])\n",
    "    user_input2['Term'] = 500     # change term\n",
    "    user_input2_list = list(user_input2.values())\n",
    "\n",
    "    features = np.array([user_input2_list]) \n",
    "\n",
    "    # using inputs to predict the output\n",
    "    pred = modelv3.predict(features)\n",
    "    if pred[0] == 1:\n",
    "        print(f'{color.bdblue}Prediction: Approve The Loan{color.end}')\n",
    "    else:\n",
    "        print(f'{color.bdred}Prediction: Do Not Approve The Loan{color.end}')\n",
    "        \n",
    "UserInputTest2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:HoneyDew;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;border: 5px solid CadetBlue;\"><b>Predictions:</b><br>\n",
    "    \n",
    "- 1 -> can approve<br>\n",
    "- 0 -> do not approve<br>\n",
    "\n",
    "Of course, in real life, will need to check further using other data (e.g. financial statements, kind of real estate, etc.) or other data's models if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:15.310486Z",
     "iopub.status.busy": "2022-03-26T07:02:15.309851Z",
     "iopub.status.idle": "2022-03-26T07:02:15.524185Z",
     "shell.execute_reply": "2022-03-26T07:02:15.523382Z",
     "shell.execute_reply.started": "2022-03-26T07:02:15.310450Z"
    }
   },
   "outputs": [],
   "source": [
    "del user_input_param\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T19:10:41.572492Z",
     "iopub.status.busy": "2022-03-13T19:10:41.572202Z",
     "iopub.status.idle": "2022-03-13T19:10:41.579958Z",
     "shell.execute_reply": "2022-03-13T19:10:41.578591Z",
     "shell.execute_reply.started": "2022-03-13T19:10:41.572462Z"
    }
   },
   "source": [
    "<a id=\"mutual_info\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>5. Mutual Information Scores</h2>\n",
    " \"A general-purpose metric, normally used before selecting and building a model, but used here in the end, for comparison.  Mutual information is a lot like correlation in that it measures a relationship between two quantities. The advantage of mutual information is that it can detect any kind of relationship, while correlation only detects linear relationships.\"\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:02:15.525781Z",
     "iopub.status.busy": "2022-03-26T07:02:15.525484Z",
     "iopub.status.idle": "2022-03-26T07:06:15.327558Z",
     "shell.execute_reply": "2022-03-26T07:06:15.326769Z",
     "shell.execute_reply.started": "2022-03-26T07:02:15.525717Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def GetMIScores():\n",
    "    X = pd.read_feather(f'{savepath}sba_final.csv.feather')\n",
    "\n",
    "    # Select target\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model_mi = process_model(X, y)\n",
    "    osample_xy = model_mi.osample()\n",
    "    mi_scores = make_mi_scores(osample_xy['X_over'], osample_xy['y_over'])\n",
    "\n",
    "    print()\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = GetMIScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:15.329509Z",
     "iopub.status.busy": "2022-03-26T07:06:15.329077Z",
     "iopub.status.idle": "2022-03-26T07:06:15.336736Z",
     "shell.execute_reply": "2022-03-26T07:06:15.335845Z",
     "shell.execute_reply.started": "2022-03-26T07:06:15.329469Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"SBA Mutual Information completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:15.338650Z",
     "iopub.status.busy": "2022-03-26T07:06:15.338387Z",
     "iopub.status.idle": "2022-03-26T07:06:18.480020Z",
     "shell.execute_reply": "2022-03-26T07:06:18.479241Z",
     "shell.execute_reply.started": "2022-03-26T07:06:15.338616Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=1200, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:18.481982Z",
     "iopub.status.busy": "2022-03-26T07:06:18.481390Z",
     "iopub.status.idle": "2022-03-26T07:06:21.058726Z",
     "shell.execute_reply": "2022-03-26T07:06:21.058102Z",
     "shell.execute_reply.started": "2022-03-26T07:06:18.481943Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plot_features(modelv3, (10,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:21.060593Z",
     "iopub.status.busy": "2022-03-26T07:06:21.060127Z",
     "iopub.status.idle": "2022-03-26T07:06:21.285334Z",
     "shell.execute_reply": "2022-03-26T07:06:21.284329Z",
     "shell.execute_reply.started": "2022-03-26T07:06:21.060556Z"
    }
   },
   "outputs": [],
   "source": [
    "del mi_scores\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The importance ranked by <b>Mutual Information</b> and <b>XGBoost Feature Importance</b> metrics are different.  Which ranking do you think is more reasonable ?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trim_dataset\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>6. Trim Dataset</h2><br>\n",
    "After the preprocessing and encoding steps, not all of the features may be useful in forecasting the loan default. Alternatively we can select the <b>top 5 or top 8 features</b>, based on the feature importance plot above, which had a major contribution in forecasting loan defaults.<br><br>\n",
    "\n",
    "If the model performance is similar in both the cases, that is  by using all the features and by using 5-8 features, then we should use only the top 8 features, in order to keep the model simpler and more efficient.\n",
    "\n",
    "The idea is to have a less complex model without compromising on the overall model performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:21.287401Z",
     "iopub.status.busy": "2022-03-26T07:06:21.286942Z",
     "iopub.status.idle": "2022-03-26T07:06:21.400433Z",
     "shell.execute_reply": "2022-03-26T07:06:21.399034Z",
     "shell.execute_reply.started": "2022-03-26T07:06:21.287364Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_feather(f'{savepath}sba_final.csv.feather')\n",
    "print(X.shape)\n",
    "\n",
    "# Select target\n",
    "y = X.pop('MIS_Status')\n",
    "\n",
    "#Let's retain the top 8 from Mutual Information metric \n",
    "mi_features = ['Term', 'DisbursementGross', 'SBA_Appv', 'SBA_Portion',\\\n",
    "                'CityState_hash', 'FranchiseCode', 'RealEstate', 'UrbanRural']\n",
    "\n",
    "Xmi = X[mi_features]\n",
    "\n",
    "#Let's retain the top 8 from Feature Importance metric \n",
    "fi_features = ['Term', 'SBA_Appv', 'DisbursementGross', 'CityState_hash', 'State_hash',\\\n",
    "                'SBA_Portion', 'Industry', 'NoEmp']\n",
    "\n",
    "Xfi = X[fi_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:21.402051Z",
     "iopub.status.busy": "2022-03-26T07:06:21.401789Z",
     "iopub.status.idle": "2022-03-26T07:06:33.194231Z",
     "shell.execute_reply": "2022-03-26T07:06:33.192685Z",
     "shell.execute_reply.started": "2022-03-26T07:06:21.402014Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def ModelMI():\n",
    "    model_mi = process_model(Xmi, y)\n",
    "    model_mi.osample()\n",
    "    model_mi.split_data(0.7)\n",
    "    model_mi_results = model_mi.prep_run_model(\"Mutual Information Metrics\")\n",
    "\n",
    "    print()\n",
    "    return model_mi_results\n",
    "\n",
    "model_mi_results = ModelMI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:33.195980Z",
     "iopub.status.busy": "2022-03-26T07:06:33.195723Z",
     "iopub.status.idle": "2022-03-26T07:06:33.203177Z",
     "shell.execute_reply": "2022-03-26T07:06:33.202404Z",
     "shell.execute_reply.started": "2022-03-26T07:06:33.195945Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"Trimmed Dataset by Mutual Information completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:33.204970Z",
     "iopub.status.busy": "2022-03-26T07:06:33.204271Z",
     "iopub.status.idle": "2022-03-26T07:06:34.312650Z",
     "shell.execute_reply": "2022-03-26T07:06:34.311320Z",
     "shell.execute_reply.started": "2022-03-26T07:06:33.204926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot mutual information\n",
    "my_model_mi = model_mi_results['xg_model']\n",
    "plot_features(my_model_mi, (10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:34.314652Z",
     "iopub.status.busy": "2022-03-26T07:06:34.314122Z",
     "iopub.status.idle": "2022-03-26T07:06:38.417663Z",
     "shell.execute_reply": "2022-03-26T07:06:38.416156Z",
     "shell.execute_reply.started": "2022-03-26T07:06:34.314613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test with Unseen test data\n",
    "def MI_Model_On_Test_Data():\n",
    "    X_test = model_mi_results['X_test']\n",
    "    X_test_mi = X_test[mi_features]\n",
    "\n",
    "    y_test = model_mi_results['y_test']\n",
    "\n",
    "    predictions_mi = my_model_mi.predict(X_test_mi)\n",
    "    model_eval(y_test, predictions_mi)\n",
    "    print()\n",
    "    \n",
    "MI_Model_On_Test_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:38.419313Z",
     "iopub.status.busy": "2022-03-26T07:06:38.418951Z",
     "iopub.status.idle": "2022-03-26T07:06:50.462169Z",
     "shell.execute_reply": "2022-03-26T07:06:50.460674Z",
     "shell.execute_reply.started": "2022-03-26T07:06:38.419272Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def ModelFI():\n",
    "    model_fi = process_model(Xfi, y)\n",
    "    model_fi.osample()\n",
    "    model_fi.split_data(0.7)\n",
    "    model_fi_results = model_fi.prep_run_model(\"Feature Importance Metrics\")\n",
    "\n",
    "    print()\n",
    "    return model_fi_results\n",
    "    \n",
    "model_fi_results = ModelFI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:50.463932Z",
     "iopub.status.busy": "2022-03-26T07:06:50.463661Z",
     "iopub.status.idle": "2022-03-26T07:06:50.472563Z",
     "shell.execute_reply": "2022-03-26T07:06:50.471647Z",
     "shell.execute_reply.started": "2022-03-26T07:06:50.463895Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"Trimmed Dataset by Feature Importance completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:50.474612Z",
     "iopub.status.busy": "2022-03-26T07:06:50.474288Z",
     "iopub.status.idle": "2022-03-26T07:06:51.615776Z",
     "shell.execute_reply": "2022-03-26T07:06:51.611590Z",
     "shell.execute_reply.started": "2022-03-26T07:06:50.474573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "my_model_fi = model_fi_results['xg_model']\n",
    "plot_features(my_model_fi, (10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:51.617713Z",
     "iopub.status.busy": "2022-03-26T07:06:51.617210Z",
     "iopub.status.idle": "2022-03-26T07:06:56.101199Z",
     "shell.execute_reply": "2022-03-26T07:06:56.100431Z",
     "shell.execute_reply.started": "2022-03-26T07:06:51.617662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test with Unseen test data\n",
    "def FI_Model_On_Test_Data():\n",
    "    X_test = model_fi_results['X_test']\n",
    "    X_test_fi = X_test[fi_features]\n",
    "\n",
    "    y_test = model_fi_results['y_test']\n",
    "\n",
    "    predictions_fi = my_model_fi.predict(X_test_fi)\n",
    "    model_eval(y_test, predictions_fi)\n",
    "    print()\n",
    "    \n",
    "FI_Model_On_Test_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:56.102906Z",
     "iopub.status.busy": "2022-03-26T07:06:56.102545Z",
     "iopub.status.idle": "2022-03-26T07:06:56.324830Z",
     "shell.execute_reply": "2022-03-26T07:06:56.324105Z",
     "shell.execute_reply.started": "2022-03-26T07:06:56.102862Z"
    }
   },
   "outputs": [],
   "source": [
    "del X, y, Xmi, Xfi, mi_features, fi_features, my_model_mi, my_model_fi\n",
    "del model_mi_results, model_fi_results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"results1\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>7. Full or Trimmed Dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Do we select the full dataset, or the trimmed dataset ?</b><br><br>\n",
    "    <b>Observation:</b><br>\n",
    "    <ul>\n",
    "        <li><b>Accuracy</b> - Approx 2 points less accuracy of trimmed versus the full features dataset.<br><br>\n",
    "        <li><b>f1-score</b> - Also approx 2 points less f1-score between full features dataset and Manual Information trimmed dataset.  Approx 1 point difference between full features dataset and Feature Importance trimmed dataset.<br><br>\n",
    "    </ul>\n",
    "    We can <b>stick with the full features</b> for now; but the trimmed features are also good, with the <b>Manual Information trimmed dataset</b> very slightly favored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:56.326527Z",
     "iopub.status.busy": "2022-03-26T07:06:56.326232Z",
     "iopub.status.idle": "2022-03-26T07:06:56.333560Z",
     "shell.execute_reply": "2022-03-26T07:06:56.332559Z",
     "shell.execute_reply.started": "2022-03-26T07:06:56.326488Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:\n",
    "        engine.say(\"SBA Machine Learning completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 style='color:GhostWhite;'>Part 3. XGBoost HyperParameter Tuning using Optuna</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"find_best_hp\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3.1 Find The Best HyperParameter Combination</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:56.335865Z",
     "iopub.status.busy": "2022-03-26T07:06:56.335510Z",
     "iopub.status.idle": "2022-03-26T08:03:41.820703Z",
     "shell.execute_reply": "2022-03-26T08:03:41.819946Z",
     "shell.execute_reply.started": "2022-03-26T07:06:56.335827Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# For running Optuna study on full dataset\n",
    "def OptunaStudy():\n",
    "\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    # instantiate the optuna_tuning class\n",
    "    ot = optuna_tuning(X, y)\n",
    "    ot.osample()\n",
    "    ot.split_data(0.7)\n",
    "    \n",
    "    del X, y\n",
    "    gc.collect()\n",
    "\n",
    "    ''' \n",
    "    Pass the number of trials or timeout in seconds to the run_optuna_trials method. \n",
    "    Example : \n",
    "        run_optuna_trials(n_trials = 50)          # number of trials\n",
    "      or\n",
    "        time_to_run = 60 * 60                     # 1 hour in seconds \n",
    "        run_optuna_trials(timeout = time_to_run)  # timeout, in seconds\n",
    "    '''\n",
    "\n",
    "    study_results = ot.run_optuna_trials(n_trials=2, batch_size=batch_size)\n",
    "\n",
    "    print()\n",
    "    return study_results\n",
    "\n",
    "if optuna_flag == 1 or optuna_flag == 3:\n",
    "    study_results = OptunaStudy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is to get the batch size if running optuna in batches \n",
    "def GetAllowedBatchSizes():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    # instantiate the optuna_tuning class\n",
    "    ot = optuna_tuning(X, y)\n",
    "    ot.osample()\n",
    "    ot_df = ot.split_data(0.7)\n",
    "    \n",
    "    size = len(ot_df['X_train'])\n",
    "    print()\n",
    "    print(f'Size of X_train: {size}')\n",
    "    \n",
    "    print()\n",
    "    batch_size = 1\n",
    "    #for i in range(1, int(size/2)):        # split into 4, for this dataset only as it varies\n",
    "    for i in range(1, size):                # split into 2, for this dataset only as it varies\n",
    "        if (size % i) == 0:\n",
    "            batch_size = i\n",
    "            print(f'{color.bdblue}{i}', end=' ')\n",
    "    print()\n",
    "    print(f'Suggested Batch Size = {batch_size}')\n",
    "    return batch_size\n",
    "\n",
    "if optuna_flag == 2 or optuna_flag == 3:\n",
    "    sugg_batch_size = GetAllowedBatchSizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T07:06:56.335865Z",
     "iopub.status.busy": "2022-03-26T07:06:56.335510Z",
     "iopub.status.idle": "2022-03-26T08:03:41.820703Z",
     "shell.execute_reply": "2022-03-26T08:03:41.819946Z",
     "shell.execute_reply.started": "2022-03-26T07:06:56.335827Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# For running Optuna tuning incrementally in batches, much slower, but lighter on memory\n",
    "def OptunaStudyBatch():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    X = X.values   # convert to numpy array\n",
    "    y = y.values   # convert to numpy array\n",
    "    \n",
    "    # instantiate the optuna_tuning class\n",
    "    otb = optuna_tuning_batch(X, y)\n",
    "    otb.osample()\n",
    "    otb.split_data(0.7)\n",
    "    \n",
    "    del X, y\n",
    "    gc.collect()\n",
    "\n",
    "    ''' \n",
    "    Pass the number of trials or timeout in seconds to the run_optuna_trials method. \n",
    "    Example : \n",
    "        run_optuna_trials(n_trials = 50)          # number of trials\n",
    "      or\n",
    "        time_to_run = 60 * 60                     # 1 hour in seconds \n",
    "        run_optuna_trials(timeout = time_to_run)  # timeout, in seconds\n",
    "    '''\n",
    "\n",
    "    study_results = otb.run_optuna_trials(n_trials=50, batch_size = sugg_batch_size)\n",
    "\n",
    "    print()\n",
    "    return study_results\n",
    "\n",
    "if optuna_flag == 2 or optuna_flag == 3:\n",
    "    study_results = OptunaStudyBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.822297Z",
     "iopub.status.busy": "2022-03-26T08:03:41.822021Z",
     "iopub.status.idle": "2022-03-26T08:03:41.832229Z",
     "shell.execute_reply": "2022-03-26T08:03:41.831237Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.822262Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_trial = study_results.best_trial.params\n",
    "best_trial.update({'n_estimators': 4000, 'tree_method':tree_method})\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.834515Z",
     "iopub.status.busy": "2022-03-26T08:03:41.834060Z",
     "iopub.status.idle": "2022-03-26T08:03:41.859859Z",
     "shell.execute_reply": "2022-03-26T08:03:41.859192Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.834477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trial results dataframe sorted from best value (RMSE) ascending\n",
    "def ViewResultsAsDf():\n",
    "    stdf = study_results.trials_dataframe()\n",
    "    stdf = stdf.sort_values('value',ascending=True)\n",
    "\n",
    "    return stdf.head(2)    # return here is only used for printing output\n",
    "\n",
    "ViewResultsAsDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.861308Z",
     "iopub.status.busy": "2022-03-26T08:03:41.860969Z",
     "iopub.status.idle": "2022-03-26T08:03:44.062901Z",
     "shell.execute_reply": "2022-03-26T08:03:44.062232Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.861270Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualize parameter importance\n",
    "optuna.visualization.plot_param_importances(study_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sugg_batch_size\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:44.064544Z",
     "iopub.status.busy": "2022-03-26T08:03:44.064101Z",
     "iopub.status.idle": "2022-03-26T08:03:44.071602Z",
     "shell.execute_reply": "2022-03-26T08:03:44.070934Z",
     "shell.execute_reply.started": "2022-03-26T08:03:44.064505Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"Optuna run completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"try_best_hp\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3.2 Model v4 : Try the Optuna Hyperparameters</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:44.073183Z",
     "iopub.status.busy": "2022-03-26T08:03:44.072800Z",
     "iopub.status.idle": "2022-03-26T08:07:48.555184Z",
     "shell.execute_reply": "2022-03-26T08:07:48.554423Z",
     "shell.execute_reply.started": "2022-03-26T08:03:44.073143Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelv4():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model4 = process_model(X, y)\n",
    "    model4.osample()\n",
    "    model4.split_data(0.7)\n",
    "    model4_results = model4.prep_run_model(\"Metrics : After Optuna Tuning\", \\\n",
    "                                       hyperparams = best_trial)\n",
    "    return model4_results\n",
    "\n",
    "model4_results = RunModelv4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:07:48.556949Z",
     "iopub.status.busy": "2022-03-26T08:07:48.556435Z",
     "iopub.status.idle": "2022-03-26T08:07:48.563964Z",
     "shell.execute_reply": "2022-03-26T08:07:48.563172Z",
     "shell.execute_reply.started": "2022-03-26T08:07:48.556902Z"
    }
   },
   "outputs": [],
   "source": [
    "if alert_flag == 1:\n",
    "    if kaggle_flag == 0:   # not Kaggle\n",
    "        engine.say(\"Model Test with Optuna completed.\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        display(Audio(url=audio_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optuna_results\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>3.3 Optuna Tuning Results</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:07:48.566044Z",
     "iopub.status.busy": "2022-03-26T08:07:48.565194Z",
     "iopub.status.idle": "2022-03-26T08:07:48.583368Z",
     "shell.execute_reply": "2022-03-26T08:07:48.582657Z",
     "shell.execute_reply.started": "2022-03-26T08:07:48.565947Z"
    }
   },
   "outputs": [],
   "source": [
    "def CompareResults():\n",
    "    m3_clf_report = model3_results['eval_results']['ClassificationReport']\n",
    "\n",
    "    m3_0_f1_score = round(m3_clf_report['0']['f1-score'] * 100, 2)\n",
    "    m3_1_f1_score = round(m3_clf_report['1']['f1-score'] * 100, 2)\n",
    "    m3_accuracy   = round(m3_clf_report['accuracy'] * 100, 2)\n",
    "\n",
    "\n",
    "    m4_clf_report = model4_results['eval_results']['ClassificationReport']\n",
    "\n",
    "    m4_0_f1_score = round(m4_clf_report['0']['f1-score'] * 100, 2)\n",
    "    m4_1_f1_score = round(m4_clf_report['1']['f1-score'] * 100, 2)\n",
    "    m4_accuracy   = round(m4_clf_report['accuracy'] * 100, 2)\n",
    "\n",
    "\n",
    "    data = {'Model v3 : No Optuna':[m3_0_f1_score, m3_1_f1_score, m3_accuracy],\n",
    "            'Model v4 : With Optuna':[m4_0_f1_score, m4_1_f1_score, m4_accuracy]}\n",
    " \n",
    "    # Creates pandas DataFrame.\n",
    "    df = pd.DataFrame(data, index =['0 : f1_score',\n",
    "                                    '1 : f1_score',\n",
    "                                    'Accuracy'])\n",
    "    print(f'{color.bdgreen}\\\n",
    "    Accuracy Improvement Using Optuna Suggested Parameters: {round(m4_accuracy - m3_accuracy,2)}\\\n",
    "    {color.end}')\n",
    "    return df\n",
    "\n",
    "CompareResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:07:48.585169Z",
     "iopub.status.busy": "2022-03-26T08:07:48.584709Z",
     "iopub.status.idle": "2022-03-26T08:07:48.818069Z",
     "shell.execute_reply": "2022-03-26T08:07:48.817400Z",
     "shell.execute_reply.started": "2022-03-26T08:07:48.585132Z"
    }
   },
   "outputs": [],
   "source": [
    "# do not run this if you still want to do more work with model 3 and model 4 information\n",
    "del modelv3, model3_results, model4_results, best_trial, study_results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Observation:</b><br><br>\n",
    "    <b>The Accuracy and F1 scores after Optuna tuning are improved compared to before tuning;</b> but it all depends on what hyperparameters/values are given.  A few trial sessions may be needed.<br><br>\n",
    "    We have a bigger score in our <a style=\"color:DarkSlateGrey\" href=\"#pl_run\">Pipeline</a> as we used an Optuna hyperparameter set that was obtained from another Optuna run.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross_validation\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>Cross Validation</h2><br>\n",
    "Measure our model's quality, in RMSE.  Ideally for small datasets, but included here for reference.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def CrossVal():\n",
    "    print(f'{color.bold}Please wait, this will take some time{color.end}')\n",
    "    print()\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    model_cv = process_model(X, y)   # create object from XGBoost class\n",
    "    model_cv.osample()  # oversample\n",
    "    model_cv_df = model_cv.split_data(0.7)\n",
    "\n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    \n",
    "    print()\n",
    "    X_train, y_train = model_cv_df['X_train'], model_cv_df['y_train']\n",
    "    X_valid, X_test = model_cv_df['X_valid'], model_cv_df['X_test']\n",
    "    y_valid, y_test = model_cv_df['y_valid'], model_cv_df['y_test']\n",
    "    \n",
    "    # these hyperparameters came from the PipeLine, a result from Optuna tuning\n",
    "    hyperparams = { 'alpha': 0.0046540057600720115,\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'lambda': 0.10810295148897421,\n",
    "                    'learning_rate': 0.05,\n",
    "                    'max_depth': 15,\n",
    "                    'min_child_weight': 1,\n",
    "                    'random_state': 48,\n",
    "                    'subsample': 0.8,\n",
    "                    'n_estimators': 4000,\n",
    "                    'tree_method': tree_method}\n",
    "\n",
    "    xgb_model = XGBClassifier(**hyperparams, use_label_encoder = False)\n",
    "\n",
    "    # If we pass a pipeline instead of a model to cross_val_score, fit_params won't be \n",
    "    # recognized\n",
    "    fit_params={'early_stopping_rounds': 400, \n",
    "                'eval_metric': ['logloss'],\n",
    "                'verbose': False,\n",
    "                'eval_set': [(X_valid, y_valid)]\n",
    "               }\n",
    "\n",
    "    # Multiply by -1 since sklearn calculates *negative* RMSE\n",
    "    print()\n",
    "    scores = -1 * cross_val_score(xgb_model, X_train, y_train,\n",
    "                                  cv=5,\n",
    "                                  scoring='neg_root_mean_squared_error',\n",
    "                                  fit_params = fit_params,\n",
    "                                  verbose=15)\n",
    "    print()\n",
    "    print(f\"{color.bdblue}Scores: {scores}{color.end}\")\n",
    "    print()\n",
    "    print(f\"{color.bdgreen}Root Mean Squared Error (Mean): {scores.mean()}\")\n",
    "    print()\n",
    "    \n",
    "CrossVal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part4\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkRed;color:AliceBlue;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "<h1 id=\"part1\" style='color:GhostWhite;'>Part 4. Miscellaneous</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"early_stopping_rounds\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4.1 Early Stopping Rounds</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Below is a reference on using plots to get an insight on the value to use for XGBoost's early_ stopping_rounds during fitting.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def PlotEarlyStoppingRounds():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    model_esr = process_model(X, y)\n",
    "    model_esr.osample()     # oversample\n",
    "    model_esr_df = model_esr.split_data(0.7)\n",
    "    \n",
    "    del X, y\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"{color.bold}Please wait, Fitting model can take time ...{color.end}\")\n",
    "            \n",
    "    hyperparams = { 'alpha': 0.0046540057600720115,\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'lambda': 0.10810295148897421,\n",
    "                    'learning_rate': 0.05,\n",
    "                    'max_depth': 15,\n",
    "                    'min_child_weight': 1,\n",
    "                    'random_state': 48,\n",
    "                    'subsample': 0.8,\n",
    "                    'n_estimators': 4000,\n",
    "                    'tree_method': tree_method}\n",
    "\n",
    "    xg_model = XGBClassifier(**hyperparams,use_label_encoder =False)\n",
    "       \n",
    "    eval_setparam = [(model_esr_df['X_train'], model_esr_df['y_train']),\\\n",
    "                     (model_esr_df['X_valid'], model_esr_df['y_valid'])]\n",
    "       \n",
    "    # fit the model without specifying early_stopping_rounds\n",
    "    xg_model.fit(model_esr_df['X_train'], model_esr_df['y_train'], \n",
    "                eval_metric=['error','logloss'],\n",
    "                eval_set = eval_setparam,\n",
    "                verbose=False)\n",
    " \n",
    "    print(\"Fitting model completed.\")\n",
    "    print()\n",
    "    print('Preparing Predictions')\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = xg_model.predict(model_esr_df['X_valid'])\n",
    "    \n",
    "    print()\n",
    "    print(f'{color.underline}Metrics:{color.end}')\n",
    "\n",
    "    eval_results = model_eval(model_esr_df['y_valid'], predictions)\n",
    "\n",
    "    # retrieve performance metrics\n",
    "    results = xg_model.evals_result()\n",
    "    epochs = len(results['validation_0']['error'])\n",
    "    x_axis = range(0, epochs)\n",
    "\n",
    "    # what we will be looking for are the bottom areas of the plots\n",
    "    \n",
    "    # plot log loss\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Log Loss')\n",
    "    pyplot.title('XGBoost Log Loss')\n",
    "    pyplot.show()\n",
    "\n",
    "    # plot classification error\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Classification Error')\n",
    "    pyplot.title('XGBoost Classification Error')\n",
    "    pyplot.show()\n",
    "    \n",
    "PlotEarlyStoppingRounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    From both plots, we can see that 10% of 4000 n_estimator, 400, is a good candidate as the early_stopping_rounds parameter.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random_forest_classifier\"></a>\n",
    "<div style=\"font-family: Trebuchet MS;background-color:DarkCyan;color:Azure;text-align: left;padding-top: 5px;padding-bottom: 20px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <h2 style='color:GhostWhite;'>4.2 Random Forest Classifier</h2><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    This is just a reference on using a Random Forest Classifier.\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status Count ->  1 : 714212, 0 : 154451\n",
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n",
      "\n",
      "\u001b[1m\u001b[4mShapes Before And After Splitting Dataset :\u001b[0m\n",
      "X (1428424, 16)   y (1428424,)\n",
      "X_train (999896, 16)   y_train (999896,)\n",
      "X_valid (214264, 16)   y_valid (214264,)\n",
      "X_test (214264, 16)   y_test (214264,)\n",
      "\n",
      "\u001b[1mPlease wait, Fitting model can take time ...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32m<timed exec>:9\u001b[0m, in \u001b[0;36mRunModelrf\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mother_models.prep_run_model\u001b[1;34m(self, desc, modelname, hparams, cmDisplay)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modelname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrfc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     20\u001b[0m     model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhparams) \n\u001b[1;32m---> 21\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting model completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run before tuning\n",
    "def RunModelrf():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    modelrf = other_models(X, y)\n",
    "    modelrf.osample()\n",
    "    modelrf.split_data(0.7)\n",
    "    modelrf.prep_run_model(\"Metrics : Random Forest Classifier\", modelname='rfc')\n",
    "\n",
    "RunModelrf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Optuna Tuning for Random Forest</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">  \n",
    "    This is just a sample implementation, for reference.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 868663 entries, 0 to 868662\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Term               868663 non-null  int16  \n",
      " 1   NoEmp              868663 non-null  int16  \n",
      " 2   NewExist           868663 non-null  int8   \n",
      " 3   CreateJob          868663 non-null  int16  \n",
      " 4   RetainedJob        868663 non-null  int16  \n",
      " 5   FranchiseCode      868663 non-null  int32  \n",
      " 6   UrbanRural         868663 non-null  int8   \n",
      " 7   LowDoc             868663 non-null  int8   \n",
      " 8   DisbursementGross  868663 non-null  float32\n",
      " 9   SBA_Appv           868663 non-null  float32\n",
      " 10  Industry           868663 non-null  int8   \n",
      " 11  Recession          868663 non-null  int8   \n",
      " 12  RealEstate         868663 non-null  int8   \n",
      " 13  SBA_Portion        868663 non-null  float32\n",
      " 14  State_hash         868663 non-null  int32  \n",
      " 15  CityState_hash     868663 non-null  int32  \n",
      "dtypes: float32(3), int16(4), int32(3), int8(6)\n",
      "memory usage: 31.5 MB\n",
      "None\n",
      "MIS_Status Count ->  1 : 714212, 0 : 154451\n",
      "X size :  868663\n",
      "y size :  868663\n",
      "Before Oversampling -> 1 : 714212, 0 : 154451\n",
      "After Oversampling  -> 1 : 714212, 0 : 714212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-06 22:27:42,651]\u001b[0m A new study created in memory with name: no-name-5660a0dd-a8ee-49ac-bfbb-b510a8a5f256\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[4mShapes Before And After Splitting Dataset :\u001b[0m\n",
      "X (1428424, 16)   y (1428424,)\n",
      "X_train (999896, 16)   y_train (999896,)\n",
      "X_valid (214264, 16)   y_valid (214264,)\n",
      "X_test (214264, 16)   y_test (214264,)\n",
      "\n",
      "\u001b[1mPlease wait, this will take time\u001b[0m\n",
      "Ram Used Before Trial : 47.7 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-06 22:36:43,703]\u001b[0m Trial 0 finished with value: 0.8877832953739312 and parameters: {'max_depth': 10, 'n_estimators': 500}. Best is trial 0 with value: 0.8877832953739312.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ram Used After Trial : 45.9 %\n",
      "Ram Used Before Trial : 45.7 %\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define an objective function to be maximized.\n",
    "def objective_rf(trial, X_train, y_train, X_valid, y_valid):\n",
    "    nn_max_depth = trial.suggest_categorical(\"max_depth\", [5,10,15])\n",
    "    nn_estimators = trial.suggest_categorical('n_estimators', [100,250,500,750,1000])\n",
    "    \n",
    "    rf_obj = RandomForestClassifier(max_depth = nn_max_depth,\n",
    "                                    n_estimators = nn_estimators,\n",
    "                                    warm_start = True)\n",
    "    \n",
    "    if GetRam() >= 95:\n",
    "            raise MemoryError('Short On Memory')\n",
    "    print(f\"Ram Used Before Trial : {GetRam()} %\")\n",
    "            \n",
    "    ## Fit Model\n",
    "    rf_obj.fit(X_train, y_train)\n",
    "\n",
    "    # Report intermediate objective value\n",
    "    intermediate_value = rf_obj.score(X_valid, y_valid)\n",
    "    trial.report(intermediate_value, i+1)\n",
    "    \n",
    "    gc.collect()\n",
    "        \n",
    "    # Handle pruning based on the intermediate value.\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "    \n",
    "    print(f\"Ram Used After Trial : {GetRam()} %\")\n",
    "    return intermediate_value\n",
    "\n",
    "def RandomForestOptunaTuning():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "    print(X.info())\n",
    "\n",
    "    rfo = process_model(X, y)\n",
    "    rfo.osample()  # oversample\n",
    "    rfo_df = rfo.split_data(0.7)\n",
    "    \n",
    "    X_train, y_train = rfo_df['X_train'], rfo_df['y_train']\n",
    "    X_valid, y_valid = rfo_df['X_valid'], rfo_df['y_valid']\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    del X, y, rfo_df\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f'{color.bold}Please wait, this will take time{color.end}')\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    try:\n",
    "        study.optimize(lambda trial: objective_rf(trial,\n",
    "                        X_train, y_train,\n",
    "                        X_valid, y_valid),\n",
    "                        n_trials = 20,\n",
    "                        catch = (RuntimeWarning,ArithmeticError,))\n",
    "    except MemoryError as e:\n",
    "        print(f'{color.bdblue}{e} : Memory was getting low, Trial ended early{color.end}')\n",
    "            \n",
    "    # Calculating the pruned and completed trials\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "    \n",
    "    return study\n",
    "\n",
    "study_results = RandomForestOptunaTuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15}\n",
      "\n",
      "0.9121877683605272\n",
      "\n",
      "FrozenTrial(number=1, values=[0.9121877683605272], datetime_start=datetime.datetime(2022, 4, 6, 20, 44, 38, 756559), datetime_complete=datetime.datetime(2022, 4, 6, 20, 47, 37, 815340), params={'max_depth': 15}, distributions={'max_depth': CategoricalDistribution(choices=(5, 10, 15))}, user_attrs={}, system_attrs={}, intermediate_values={1: 0.9117817272150245, 2: 0.9121877683605272}, trial_id=1, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "pprint(study_results.best_params) # Get best parameters for the objective function.\n",
    "print()\n",
    "pprint(study_results.best_value)  # Get best objective value.\n",
    "print()\n",
    "pprint(study_results.best_trial)  # Get best trial's information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.822297Z",
     "iopub.status.busy": "2022-03-26T08:03:41.822021Z",
     "iopub.status.idle": "2022-03-26T08:03:41.832229Z",
     "shell.execute_reply": "2022-03-26T08:03:41.831237Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.822262Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_trial = study_results.best_trial.params\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.834515Z",
     "iopub.status.busy": "2022-03-26T08:03:41.834060Z",
     "iopub.status.idle": "2022-03-26T08:03:41.859859Z",
     "shell.execute_reply": "2022-03-26T08:03:41.859192Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.834477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trial results dataframe sorted from best value ascending\n",
    "ViewResultsAsDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-26T08:03:41.861308Z",
     "iopub.status.busy": "2022-03-26T08:03:41.860969Z",
     "iopub.status.idle": "2022-03-26T08:03:44.062901Z",
     "shell.execute_reply": "2022-03-26T08:03:44.062232Z",
     "shell.execute_reply.started": "2022-03-26T08:03:41.861270Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualize parameter importance\n",
    "optuna.visualization.plot_param_importances(study_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>Random Forest Score With Optuna Hyperparameters</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RunModelrf2():\n",
    "    X = pd.read_feather(final_ds)\n",
    "    y = X.pop('MIS_Status')\n",
    "\n",
    "    modelrf = other_models(X, y)\n",
    "    modelrf.osample()\n",
    "    modelrf.split_data(0.7)\n",
    "    modelrf.prep_run_model(\"Metrics : Random Forest Classifier\", \\\n",
    "                            modelname='rfc', hparams = best_trial)\n",
    "\n",
    "RunModelrf2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del study_results, best_trial\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Trebuchet MS;background-color:LightSteelBlue;color:Black;text-align: left;padding-top: 5px;padding-bottom: 15px;padding-left: 20px;padding-right: 10px;border-radius: 15px 50px;letter-spacing: 2px;\">\n",
    "    <b>RandomizedSearchCV</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Below is a reference on using a <b>RandomizedSearchCV</b> first for Random Forest hyperparameter tuning.<br><br>\n",
    "  Once done, one would have randomly narrowed down some parameters which we can base our inputs for a full <b>GridSearchCV</b> (not shown here).\n",
    "    <br><br>\n",
    "    Both approaches take an <b>extremely long time to run</b> using our SBA dataset, and the line to run the task is commented out.  Uncomment if you want to try.  Otherwise, <b>Optuna</b> is a much faster method.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ViewDefaultRFCParams():\n",
    "    rf = RandomForestClassifier(random_state = 48)\n",
    "    # Look at parameters used by our current forest\n",
    "    print('Default parameters in use:\\n')\n",
    "    pprint(rf.get_params())\n",
    "\n",
    "ViewDefaultRFCParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def SuggestRFCParams():\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 500, stop = 2000, num = 3)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(6, 15, num = 4)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    pprint(random_grid)\n",
    "    return random_grid\n",
    "\n",
    "random_grid = SuggestRFCParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def RandomSearchCV(random_grid):\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \\\n",
    "                                   n_iter = 5, cv = 3, verbose=10, random_state=48)\n",
    "\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(modelrf_results['X_train'], modelrf_results['y_train'])\n",
    "    \n",
    "    return rf_random.best_params_\n",
    "\n",
    "#rf_best_params = RandomSearchCV(random_grid)\n",
    "#rf_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del random_grid #,rf_best_params \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
